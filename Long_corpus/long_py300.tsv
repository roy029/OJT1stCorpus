text	label
a = a[-1:] + a[:-1]datetimevariable.strftime('%Y-%m-%d')mixed.replace('\r\n', '\n').replace('\r', '\n')os.path.expanduser('~user')T = [L[i] for i in Idx]words = open('myfile').read().split()[[sum([x[1] for x in i])] for i in data][sum([x[1] for x in i]) for i in data]Article.objects.annotate(like_count=Count('likes')).order_by('-like_count')today = datetime.datetime.utcnow().date()[(a * b) for a, b in zip(lista, listb)]re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', s)re.match('[:;][)(](?![)(])', str)json_string = json.dumps([ob.__dict__ for ob in list_name])listofzeros = [0] * n	4
"requests.get('https://www.reporo.com/', verify=False)a[a != 0]new_dict = {k: v for k, v in zip(keys, values)}dict((k, v) for k, v in zip(keys, values))dict([(k, v) for k, v in zip(keys, values)])m = re.search('\\[(\\w+)\\]', s)s.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1)list3 = [(a + b) for a, b in zip(list1, list2)][ord(c) for c in s.decode('hex')]print(sorted(student_tuples, key=lambda t: (-t[2], t[0])))[y for x in range(3) for y in [x, x]]txt = open('file.txt').read()myList[:] = [(x / myInt) for x in myList]""""""Name: {0[person.name]}"""""".format({'person.name': 'Joe'})df.replace(' ', '_', regex=True)"	4
"[{'A': 1, 'C': 4, 'B': 2, 'D': 4}, {'A': 1, 'C': 4, 'B': 1, 'D': 5}][{'A': 1, 'C': 4, 'B': 2, 'D': 4}, {'A': 1, 'C': 4, 'B': 1, 'D': 5}]list(itertools.product(*a))df.groupby(['Country', 'Item_Code'])[['Y1961', 'Y1962', 'Y1963']].sum()done = [(el, x) for el in [a, b, c, d]]x = x[numpy.logical_not(numpy.isnan(x))]os.path.join(*x.split(os.path.sep)[2:])line = line.replace(';', ':')subprocess.call('tar c my_dir | md5sum', shell=True)""""""437c2123"""""".decode('hex')[k for k, v in User._fields.items() if v.required]df = df.ix[:, 0:2]x = map(int, x.split())x = [int(i) for i in x.split()]driver.find_element_by_css_selector(""input[onclick*='1 Bedroom Deluxe']"")"	4
urllib.parse.quote(s.encode('utf-8'))urllib.parse.quote_plus('a b')np.array(map(int, '100110'))print(np.array(list(mystr), dtype=int))img = cv2.imread('messi5.jpg', 0)lst.sort(key=lambda x: x[2], reverse=True)indices = [i for i, x in enumerate(my_list) if x == 'whatever']subprocess.call('grep -r PASSED *.log | sort -u | wc -l', shell=True)len(my_text) - len(my_text.rstrip('?'))df[df.columns[1:]].replace('[\\$,]', '', regex=True).astype(float)df1.merge(df2, how='left', on='word')print(''.join(''.join(i) for i in zip(a2, a1)) + a[-1] if len(a) % 2 else '')root.attributes('-topmost', True)root.lift()hex(int(''.join([str(int(b)) for b in walls]), 2))	4
('c' in d)if ('key1' in dict):<nl><tab>passif (key in d):<nl><tab>passBlog.objects.filter(pk__in=[1, 4, 7])f = open('test/test.pdf', 'rb')format(12345678.46, ',').replace(',', ' ').replace('.', ',')pd.merge(frame_1, frame_2, left_on='county_ID', right_on='countyid')np.isnan(a).sum() / np.prod(a.shape)sorted(iter(cityPopulation.items()), key=lambda k_v: k_v[1][2], reverse=True)sorted(list(u.items()), key=lambda v: v[1])sorted(list(d.items()), key=lambda k_v: k_v[1], reverse=True)sorted(list(d.items()), key=lambda k_v: k_v[1])f = open(os.path.join(__location__, 'bundled-resource.jpg'))f = open('words.txt', 'rU'){k: (float(d2[k]) / d1[k]) for k in d2}	4
numpy.array([(x in a) for x in b])networkx.draw_networkx_labels(G, pos, labels)y = [row[:] for row in x]X = numpy.loadtxt('somefile.csv', delimiter=',')matching = [s for s in some_list if 'abc' in s]df.to_csv('mydf.tsv', sep='\t')random.sample(list(range(100)), 10)s.rsplit(',', 1)all(isinstance(x, int) for x in lst)all(isinstance(x, int) for x in lst)line.strip()driver.execute_script('window.scrollTo(0, Y)')driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')datetime.datetime.combine(dateobject, datetime.time())print(any(x in a for x in b))	4
re.sub('(?m)^\\s+', '', 'a\n b\n c')a, b, c = [1, 2, 3][list(v) for k, v in itertools.groupby(mylist, key=lambda x: x[:5])]line = re.sub('\\(+as .*?\\) ', '', line)print(line.rstrip('\n'))df.index.values.tolist()if (not a):<nl><tab>passif (not seq):<nl><tab>passif (len(li) == 0):<nl><tab>pass[i for i, v in enumerate(a) if v > 4]sorted(yourdata, reverse=True)sorted(yourdata, key=lambda d: d.get('key', {}).get('subkey'), reverse=True)yourdata.sort(key=lambda e: e['key']['subkey'], reverse=True)df.round()gca().get_lines()[n].get_xydata()	4
yourdata.sort(key=lambda e: e['key']['subkey'], reverse=True)df.round()gca().get_lines()[n].get_xydata()A[:, -2:]request.GET.get('username', '')pprint(dict(list(o.items())))url('^$', include('sms.urls')),url('^', include('sms.urls')),max_item = max(a_list, key=operator.itemgetter(1))max(a_list, key=operator.itemgetter(1))s.resample('3M', how='sum')[a[i] for i in (1, 2, 5)][line for line in open('textfile') if 'apple' in line]datetime.datetime.strptime(s, '%Y-%m-%dT%H:%M:%SZ')pandas.read_csv(filename, sep='\t', lineterminator='\r')	4
"re.findall('[-+]?\\d*\\.\\d+|\\d+', 'Current Level: -13.2 db or 14.2 or 3')zip(it, it, it)df['x'].str.lower()jsobj['a']['b']['e'].append({'f': var6, 'g': var7, 'h': var8})"""""""""""".join(lst)sum(v for v in list(d.values()) if v > 0)app.run(debug=True)df.drop(df.index[[1, 3]], inplace=True)df.apply(lambda x: x.fillna(x.mean()), axis=0)[o.my_attr for o in my_list]time.strftime('%m/%d/%Y', time.gmtime(os.path.getmtime(file)))all(item in list(superset.items()) for item in list(subset.items()))[str(wi) for wi in wordids]df2 = df.reset_index()dt.strftime('%m/%d/%Y')"	4
[o.my_attr for o in my_list]time.strftime('%m/%d/%Y', time.gmtime(os.path.getmtime(file)))all(item in list(superset.items()) for item in list(subset.items()))[str(wi) for wi in wordids]df2 = df.reset_index()dt.strftime('%m/%d/%Y')print('Total cost is: ${:,.2f}'.format(TotalAmount))df.groupby(np.arange(len(df.columns)) // 2 + 1, axis=1).sum().add_prefix('s')randomList = [random.random() for _ in range(10)]print(soup.find('a', href=re.compile('.*follow\\?page.*')))sys.stdout.flush()country, capital = random.choice(list(d.items()))list('Word to Split')[w for w in open('file.txt') if not re.search('[aeiou]{2}', w)]pat = re.compile('^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$')	4
"word = re.sub('([aeiou]):(([aeiou][^aeiou]*){3})$', '\\1\\2', word)json.loads('{""foo"": 42, ""bar"": ""baz""}')['bar']data = json.loads(array)data = json.loads(array)re.findall('#(\\w+)', 'http://example.org/#comments')any(e in lestring for e in lelist)df.plot(x='col_name_1', y='col_name_2', style='o')parsed_html = BeautifulSoup(html)<nl>print(parsed_html.body.find('div', attrs={'class': 'container', }).text)page = urllib.request.urlopen('http://www.google.com/')<nl>soup = BeautifulSoup(page)plt.figure(figsize=(3, 4))s.translate(None, string.punctuation)base64.urlsafe_b64decode(uenc.encode('ascii'))len(dict_test) + sum(len(v) for v in dict_test.values())hex(d).split('x')[1]list(str(123))"	4
sys.setdefaultencoding('utf8')datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')print(re.findall('[\\u0600-\\u06FF]+', my_string))df.groupby(df.index.map(lambda t: t.minute))dict['Apple']['American']df2.dropna(subset=['three', 'four', 'five'], how='all')a.insert(0, k)a = a[:n] + k + a[n:]np.flatnonzero(x).mean()df['just_date'] = df['dates'].dt.date[x for x in a if x not in b][''.join(x) for x in a]list(map(''.join, a))re.split('\n\\s*\n', s)from functools import reduce<nl>reduce(lambda x, y: 10 * x + y, [1, 2, 3, 4, 5])	4
[int(x) for x in str(num)]br.select_form(nr=0)json.load(codecs.open('sample.json', 'r', 'utf-8-sig'))json.loads(open('sample.json').read().decode('utf-8-sig'))server = smtplib.SMTP('smtp.gmail.com', 587)int('{:08b}'.format(n)[::-1], 2)df.set_index(['d'], append=True)for (key, value) in d.items():<nl><tab>passfor (key, value) in list(d.items()):<nl><tab>passfor (letter, number) in list(d.items()):<nl><tab>passfor (k, v) in list(d.items()):<nl><tab>passlist(d.items())list(d.items())for (k, v) in list(d.items()):<nl><tab>passfor (letter, number) in list(d.items()):<nl><tab>pass	4
ftp.retrbinary('RETR %s' % filename, file.write)urlfetch.fetch(url, deadline=10 * 60)print(my_string[0:100])legend(numpoints=1)dict((x, set(y) & set(d1.get(x, ()))) for x, y in d2.items())numpy.loadtxt(open('test.csv', 'rb'), delimiter=',', skiprows=1)Sample.objects.filter(date__range=['2011-01-01', '2011-01-31'])Sample.objects.filter(date__year='2011', date__month='01')d['dict3'] = {'spam': 5, 'ham': 6}numpy.apply_along_axis(numpy.linalg.norm, 1, a)dict((k, v) for d in dicts for k, v in list(d.items()))print('your string'.decode('string_escape'))sum([True, True, False, False, False, True])fig.set_size_inches(w, h, forward=True)'hello there %(5)s' % {'5': 'you'}	4
od = collections.OrderedDict(sorted(d.items()))OrderedDict(sorted(list(d.items()), key=(lambda t: t[0])))response = requests.put(url, data=json.dumps(data), headers=headers)re.sub('[\\W_]+', '', s)[(x + y) for x in l2 for y in l1]dict([x.split('=') for x in s.split()])my_list.pop(2)s = s.replace('M', '')newstr = oldstr.replace('M', '')sum(x * y for x, y in zip(a, b))list(x * y for x, y in list(zip(a, b)))sum(i * j for i, j in zip(a, b))sum(x * y for x, y in list(zip(a, b)))f.write(open('xxx.mp4', 'rb').read())new_list = [(x + 1) for x in my_list]	4
data.rename(columns={'gdp': 'log(gdp)'}, inplace=True)print(soup.get_text())sorted(li, key=operator.itemgetter(1), reverse=True)data['sex'].replace([0, 1], ['Female', 'Male'], inplace=True)re.split('\\W+', 'Words, words, words.')re.match('(.*?[.?!](?:\\s+.*?[.?!]){0,1})', phrase).group(1)print([a for a, b in re.findall('((\\w)\\2*)', s)])print(' '.join(OrderedDict.fromkeys(s)))print(' '.join(set(s)))[x for x in file.namelist() if x.endswith('/')]input_string.count('Hello')print('.'.join([item[0] for item in data]))fh1.seek(2)print(zip(my_list[0::2], my_list[1::2]))my_new_list = zip(my_list[0::2], my_list[1::2])	4
list(range(11, 17))data_df['grade'] = data_df['grade'].astype(float).astype(int)max(alkaline_earth_values, key=lambda x: x[1])your_string.strip('0')list(permutations(list(range(9)), 2))re.compile('^(.+)(?:\\n|\\r\\n?)((?:(?:\\n|\\r\\n?).+)+)', re.MULTILINE)re.compile('^(.+)\\n((?:\\n.+)+)', re.MULTILINE)call(['path/to/python', 'test2.py', 'neededArgumetGoHere'])a.sort(key=operator.itemgetter(2, 3))final_choices = ((another_choice,) + my_choices)final_choices = ((another_choice,) + my_choices)os.getcwd()os.path.realpath(__file__)os.path.dirname(path)os.path.realpath(path)	4
np.where(a == 1)df.columns = df.columns.get_level_values(0)x = scipy.matrix([1, 2, 3]).transpose()text = re.sub('(\\bget\\b)', '\\1@', text)np.array([np.arange(3), np.arange(2, -1, -1), np.ones((3,))]).min(axis=0)df['new_col'] = list(range(1, len(df) + 1))os.environ['DEBUSSY'] = '1'print(os.environ['DEBUSSY'])os.environ['DEBUSSY'] = '1'b.update(d)df['b']ebar = plt.errorbar(x, y, yerr=err, ecolor='y')results += [each for each in os.listdir(folder) if each.endswith('.c')]print('\xc2\xa3'.decode('utf8') + '1')re.sub('(?<=[a-z])([A-Z])', '-\\1', s).lower()	4
os.path.realpath(__file__)os.path.dirname(path)os.path.realpath(path)dir_path = os.path.dirname(os.path.realpath(__file__))cwd = os.getcwd()full_path = os.path.realpath(__file__)arr[arr[:, (2)].argsort()]numpy.sort(arr, axis=0)re.split('[ .]', 'a b.c')shutil.copy('file.txt', 'file2.txt')print(''.join(choice(ascii_uppercase) for i in range(12)))[''.join(seq) for seq in zip(lst, lst[1:])]data.rename(columns={'gdp': 'log(gdp)'}, inplace=True)print(soup.get_text())sorted(li, key=operator.itemgetter(1), reverse=True)	4
"sum(d * 10 ** i for i, d in enumerate(x[::-1]))r = int(''.join(map(str, x)))datetime.strptime('2010-11-13 10:33:54.227806', '%Y-%m-%d %H:%M:%S.%f')[(i, sum(j) / len(j)) for i, j in list(d.items())]zip([1, 2], [3, 4])['hello{0}'.format(i) for i in a]re.sub('(?<!\\S)((\\S+)(?:\\s+\\2))(?:\\s+\\2)+(?!\\S)', '\\1', s)df.div(df.sum(axis=1), axis=0)map(lambda t: (t[1], t[0]), mylist)[(t[1], t[0]) for t in mylist]driver.find_element_by_xpath(""//p[@id, 'one']/following-sibling::p"")re.findall('\\[[^\\]]*\\]|\\([^\\)]*\\)|""[^""]*""|\\S+', strs)print(list(itertools.combinations({1, 2, 3, 4}, 3)))df[['hour', 'weekday', 'weeknum']] = df.apply(lambdafunc, axis=1)soup.find_all('a', string='Elsie')"	4
time.sleep(60)sleep(0.1)time.sleep(60)time.sleep(0.1)[x for x in my_list if not any(c.isdigit() for c in x)]df['state'].apply(lambda x: x[len(x) / 2 - 1:len(x) / 2 + 1])plt.grid(True)sorted(lst, key=lambda x: (-1 * c[x], lst.index(x)))[max(len(str(x)) for x in line) for line in zip(*foo)]df.Country.value_counts().reset_index(name='Sum of Accidents')data.set_index('Date').diff()a.update([3, 4])a[1::2] = -1df.groupby('group')['value'].rank(ascending=False)datetime.strptime('Tue, 22 Nov 2011 06:00:00 GMT', '%a, %d %b %Y %H:%M:%S %Z')	4
"[(x1 - x2) for x1, x2 in zip(List1, List2)]string[0].isdigit()strg.startswith(('0', '1', '2', '3', '4', '5', '6', '7', '8', '9'))print(os.path.dirname(os.path.realpath(__file__)))re.split('(?<=\\?|!|\\.)\\s{0,2}(?=[A-Z]|$)', text)plt.scatter(*zip(*li))tuple(zip(*t))df.groupby(np.arange(len(df.columns)) // 3, axis=1).mean()"""""""""""".join(chr(i) for i in L)sum(x == chosen_value for x in list(d.values()))sum(1 for x in list(d.values()) if some_condition(x))struct.unpack('f', struct.pack('f', 0.00582811585976))timestamp = (dt - datetime(1970, 1, 1)).total_seconds()df.sort('m')a = sorted(a, key=lambda x: x.modified, reverse=True)"	4
[i for i, v in enumerate(a) if v > 4]sorted(yourdata, reverse=True)sorted(yourdata, key=lambda d: d.get('key', {}).get('subkey'), reverse=True)yourdata.sort(key=lambda e: e['key']['subkey'], reverse=True)df.round()gca().get_lines()[n].get_xydata()A[:, -2:]request.GET.get('username', '')pprint(dict(list(o.items())))url('^$', include('sms.urls')),url('^', include('sms.urls')),max_item = max(a_list, key=operator.itemgetter(1))max(a_list, key=operator.itemgetter(1))s.resample('3M', how='sum')[a[i] for i in (1, 2, 5)]	4
[value for key, value in list(programs.items()) if 'new york' in key.lower()]sys.path.append('/path/to/main_folder')re.findall('\\d+(?=[^[]+$)', s)pickle.load(open('afile', 'rb'))driver.find_element_by_xpath('xpath').click()ex.groupby(level='A').agg(lambda x: x.index.get_level_values(1).nunique())pd.concat(map(pd.DataFrame, iter(d.values())), keys=list(d.keys())).stack().unstack(0)sum(1 for i, j in zip(a, b) if i != j)d = {(a.lower(), b): v for (a, b), v in list(d.items())}list_.sort(key=lambda x: [x[0], len(x[1]), x[1]])s.strip()s = s.lstrip()s = s.rstrip()s = s.strip(' \t\n\r')print(re.sub('[\\s+]', '', s))	4
my_list.pop(2)s = s.replace('M', '')newstr = oldstr.replace('M', '')sum(x * y for x, y in zip(a, b))list(x * y for x, y in list(zip(a, b)))sum(i * j for i, j in zip(a, b))sum(x * y for x, y in list(zip(a, b)))f.write(open('xxx.mp4', 'rb').read())new_list = [(x + 1) for x in my_list][x for x in j if x >= 5]plt.plot(list(range(10)), '--bo')plt.plot(list(range(10)), linestyle='--', marker='o', color='b')[i.split('\t', 1)[0] for i in l]myList = [i.split('\t')[0] for i in myList]sum(your_list)	4
"sorted(a, key=lambda x: (sum(x[1:3]), x[0]), reverse=True)sorted(lst, key=lambda x: (sum(x[1:]), x[0]))sorted(lst, key=lambda x: (sum(x[1:]), x[0]), reverse=True)response.headers['WWW-Authenticate'] = 'Basic realm=""test""'del request.session['mykey']datetime.datetime.strptime('24052010', '%d%m%Y').date()re.sub('[^\\x00-\\x7F]+', ' ', text)numpy.array([[1, 2], [3, 4]])myList = [i for i in range(10)][m[0] for m in re.compile('((.+?)\\2+)').findall('44442(2)2(2)44')][i[0] for i in re.findall('((\\d)(?:[()]*\\2*[()]*)*)', s)]fig.subplots_adjust(wspace=0, hspace=0)x[::-1]json.dumps({'apple': 'cat', 'banana': 'dog', 'pear': 'fish'})csvwriter.writerow(row)"	4
df.groupby('dummy').agg({'returns': [np.mean, np.sum]})s.lower()s.decode('utf-8').lower()ftp.retrbinary('RETR %s' % filename, file.write)urlfetch.fetch(url, deadline=10 * 60)print(my_string[0:100])legend(numpoints=1)dict((x, set(y) & set(d1.get(x, ()))) for x, y in d2.items())numpy.loadtxt(open('test.csv', 'rb'), delimiter=',', skiprows=1)Sample.objects.filter(date__range=['2011-01-01', '2011-01-31'])Sample.objects.filter(date__year='2011', date__month='01')d['dict3'] = {'spam': 5, 'ham': 6}numpy.apply_along_axis(numpy.linalg.norm, 1, a)dict((k, v) for d in dicts for k, v in list(d.items()))print('your string'.decode('string_escape'))	4
sum(x * y for x, y in list(zip(a, b)))f.write(open('xxx.mp4', 'rb').read())new_list = [(x + 1) for x in my_list][x for x in j if x >= 5]plt.plot(list(range(10)), '--bo')plt.plot(list(range(10)), linestyle='--', marker='o', color='b')[i.split('\t', 1)[0] for i in l]myList = [i.split('\t')[0] for i in myList]sum(your_list)ForkedPdb().set_trace()result = {k: d2.get(v) for k, v in list(d1.items())}datetime.datetime.now() + datetime.timedelta(days=1, hours=3)[int(s[i:i + 3], 2) for i in range(0, len(s), 3)]dict((v, k) for k, v in my_dict.items())print(sorted(L, key=lambda x: int(x.split('.')[2])))	4
"print('0x%X' % value)cleaned = [x for x in your_list if x]slice(*[(int(i.strip()) if i else None) for i in string_slice.split(':')])soup.find_all(['a', 'div'])print(func.__name__)"""""""""""".join('{}{}'.format(key, val) for key, val in sorted(adict.items()))"""""""""""".join('{}{}'.format(key, val) for key, val in list(adict.items()))new_list = old_list[:]new_list = list(old_list)new_list = copy.copy(old_list)new_list = copy.deepcopy(old_list)[i for i in old_list]plt.legend(frameon=False)""""""\\ud83d\\ude4f"""""".encode('utf-16', 'surrogatepass').decode('utf-16')globals()['myfunction']()"	4
pattern = re.compile('\\s+')<nl>sentence = re.sub(pattern, '', sentence)sentence.strip()sentence = re.sub('\\s+', '', sentence, flags=re.UNICODE)sentence = ''.join(sentence.split())sum(my_counter.values())np.sqrt(((A - B) ** 2).sum(-1))levels = [{}, {}, {}]weekly = [sum(visitors[x:x + 7]) for x in range(0, len(daily), 7)]del d[key]{i: a[i] for i in a if (i != 0)}lol.pop('hello')del r[key]np.linalg.solve(np.dot(a.T, a), np.dot(a.T, b))pd.concat([df.drop('b', axis=1), pd.DataFrame(df['b'].tolist())], axis=1)for i in range(0, 10, 2):<nl><tab>pass	4
"os.chdir('c:\\Users\\uname\\desktop\\python')os.chdir(path)no_integers = [x for x in mylist if not isinstance(x, int)]tree.xpath("".//a[text()='Example']"")[0].tag"""""", """""".join([(str(k) + ' ' + str(v)) for k, v in list(a.items())])print(set(re.sub('[\x00-\x7f]', '', '\xa3\u20ac\xa3\u20ac')))print(re.sub('[\x00-\x7f]', '', '\xa3100 is worth more than \u20ac100'))ast.literal_eval(""{'muffin' : 'lolz', 'foo' : 'kitty'}"")print(t.decode('unicode_escape'))print(str.encode('cp1252').decode('utf-8').encode('cp1252').decode('utf-8'))zip(list_a, list_b)list(zip(a, b))df.set_index('id').to_dict()df.set_index('id')['value'].to_dict()sorted(list(mydict.items()), key=lambda a: map(int, a[0].split('.')))"	4
[x for y, x in sorted(zip(Y, X))]datetime.date(2010, 6, 16).isocalendar()[1]df.iloc[:, (np.r_[1:10, (15), (17), 50:100])]df.groupby('dummy').agg({'returns': [np.mean, np.sum]})s.lower()s.decode('utf-8').lower()ftp.retrbinary('RETR %s' % filename, file.write)urlfetch.fetch(url, deadline=10 * 60)print(my_string[0:100])legend(numpoints=1)dict((x, set(y) & set(d1.get(x, ()))) for x, y in d2.items())numpy.loadtxt(open('test.csv', 'rb'), delimiter=',', skiprows=1)Sample.objects.filter(date__range=['2011-01-01', '2011-01-31'])Sample.objects.filter(date__year='2011', date__month='01')d['dict3'] = {'spam': 5, 'ham': 6}	4
"for i in mylist[::2]:<nl><tab>pass[{'content': x['content'].lower()} for x in messages]"""""" """""".join(my_list)re.sub('(http://\\S+|\\S*[^\\w\\s]\\S*)', '', a)str(n) == str(n)[::-1]ftp.storbinary('STOR myfile.txt', open('myfile.txt', 'rb'))re.sub('.*I', 'I', stri)int('1,000,000'.replace(',', ''))pd.merge(df1, df2, left_index=True, right_index=True, how='outer')pandas.concat([df1, df2], axis=1)all(dict.values())df.c_contofficeID.str.replace('^12(?=.{4}$)', '')L[::(-1)]reversed(array)L.reverse()"	4
sum(x * y for x, y in zip(a, b))list(x * y for x, y in list(zip(a, b)))sum(i * j for i, j in zip(a, b))sum(x * y for x, y in list(zip(a, b)))f.write(open('xxx.mp4', 'rb').read())new_list = [(x + 1) for x in my_list][x for x in j if x >= 5]plt.plot(list(range(10)), '--bo')plt.plot(list(range(10)), linestyle='--', marker='o', color='b')[i.split('\t', 1)[0] for i in l]myList = [i.split('\t')[0] for i in myList]sum(your_list)ForkedPdb().set_trace()result = {k: d2.get(v) for k, v in list(d1.items())}datetime.datetime.now() + datetime.timedelta(days=1, hours=3)	4
arr[arr[:, (2)].argsort()]numpy.sort(arr, axis=0)re.split('[ .]', 'a b.c')shutil.copy('file.txt', 'file2.txt')print(''.join(choice(ascii_uppercase) for i in range(12)))[''.join(seq) for seq in zip(lst, lst[1:])]data.rename(columns={'gdp': 'log(gdp)'}, inplace=True)print(soup.get_text())sorted(li, key=operator.itemgetter(1), reverse=True)data['sex'].replace([0, 1], ['Female', 'Male'], inplace=True)re.split('\\W+', 'Words, words, words.')re.match('(.*?[.?!](?:\\s+.*?[.?!]){0,1})', phrase).group(1)print([a for a, b in re.findall('((\\w)\\2*)', s)])print(' '.join(OrderedDict.fromkeys(s)))print(' '.join(set(s)))	4
"urllib.parse.unquote(url).decode('utf8')del lst[:]del lst1[:]lst[:] = []alist[:] = []s.reset_index(0).reset_index(drop=True)elems[0].getText().encode('utf-8')[(y - x) for x, y in zip(L, L[1:])]print(re.search('\\bLOG_ADDR\\s+(\\S+)', line).group(1))globals().update(importlib.import_module('some.package').__dict__)"""""""""""".join(['a', 'b', 'c', 'd'])url.split('&')od = collections.OrderedDict(sorted(d.items()))OrderedDict(sorted(list(d.items()), key=(lambda t: t[0])))response = requests.put(url, data=json.dumps(data), headers=headers)"	4
[len(x) for x in s.split()]soup.findAll('div', style='width=300px;')cursor.execute(sql, list(myDict.values()))df.to_csv('Result.csv', index=False, sep=' ')globals().update(vars(args))re.findall('\\[(.*?)\\]', mystring)print('%.2f kg = %.2f lb = %.2f gal = %.2f l' % (var1, var2, var3, var4))d = dict((k, v) for k, v in d.items() if v > 0)d = {k: v for k, v in list(d.items()) if v > 0}pd.to_datetime(pd.Series(date_stngs))df.iloc[2, 0]matplotlib.rcParams.update({'font.size': 22})pd.DataFrame(list(d.items()), columns=['Date', 'DateValue'])pd.DataFrame(df.values * df2.values, columns=df.columns, index=df.index)re.findall('\\d+\\.\\d+', 'Current Level: 13.4 db.')	4
"my_datetime.strftime('%B %d, %Y')int(''.join(c for c in s if c.isdigit()))dic['Test'].update({'class': {'section': 5}})dict(map(int, x.split(':')) for x in s.split(','))driver.find_element_by_xpath(""//div[@id='a']//a[@class='click']"")np.where((vals == (0, 1)).all(axis=1))SomeModel.objects.filter(id=id).delete()dict([['two', 2], ['one', 1]])dict(zip(l[::2], l[1::2]))GRAVITY = 9.8re.findall('(([0-9]+)([A-Z]))', '20M10000N80M')re.findall('([0-9]+|[A-Z])', '20M10000N80M')re.findall('([0-9]+)([A-Z])', '20M10000N80M')re.compile('\\w+').findall('Hello world, my name is...James the 2nd!')datetime.datetime.strptime('03:55', '%H:%M').time()"	4
"df.round({'Alabama_exp': 2, 'Credit_exp': 3})p.setopt(pycurl.WRITEFUNCTION, lambda x: None)print(random.choice(words))max(d, key=lambda x: d[x]['count'])[(int(x) if x else 0) for x in data.split(',')]"""""","""""".join(x or '0' for x in s.split(','))re.compile('$^')re.compile('.\\A|.\\A*|.\\A+')re.compile('a^')df.columns[df.max() > 0]yourdatetime.date() == datetime.today().date()print('\x1b[1m' + 'Hello')re.sub('.{20}(.mkv)', '\\1', 'unique12345678901234567890.mkv')['a', 'c', 'b', 'obj']"""""" """""".join(mystring.split())"	4
"print(urllib.request.urlopen('http://www.stackoverflow.com').getcode())driver.find_element_by_css_selector(""a[href^='javascript']"").click()df.to_pickle(file_name)df.groupby(by=df.columns, axis=1).mean()bar.sort(key=lambda x: (x.attrb1, x.attrb2), reverse=True)alpha = img.split()[-1][len(x) for x in s.split()]soup.findAll('div', style='width=300px;')cursor.execute(sql, list(myDict.values()))df.to_csv('Result.csv', index=False, sep=' ')globals().update(vars(args))re.findall('\\[(.*?)\\]', mystring)print('%.2f kg = %.2f lb = %.2f gal = %.2f l' % (var1, var2, var3, var4))d = dict((k, v) for k, v in d.items() if v > 0)d = {k: v for k, v in list(d.items()) if v > 0}"	4
"dict((i, i * 2) for i in range(10))plt.cla()total = sum(float(item) for item in s.split(','))bin(ord('P'))print(my_string.split(', ', 1)[1])print(data['places'][0]['post code'])word = re.sub('([aeiou]):(([aeiou][^aeiou]*){3})$', '\\1\\2', word)json.loads('{""foo"": 42, ""bar"": ""baz""}')['bar']data = json.loads(array)data = json.loads(array)re.findall('#(\\w+)', 'http://example.org/#comments')any(e in lestring for e in lelist)df.plot(x='col_name_1', y='col_name_2', style='o')parsed_html = BeautifulSoup(html)<nl>print(parsed_html.body.find('div', attrs={'class': 'container', }).text)page = urllib.request.urlopen('http://www.google.com/')<nl>soup = BeautifulSoup(page)"	4
df.sort(['a', 'b'], ascending=[True, False])redirect('Home.views.index')[x for x in a if x not in [2, 3, 7]]out = ''.join(c for c in asking if c not in ('!', '.', ':'))soup.find('meta', {'name': 'City'})['content']urllib.parse.unquote('%0a')urllib.parse.unquote(url).decode('utf8')del lst[:]del lst1[:]lst[:] = []alist[:] = []s.reset_index(0).reset_index(drop=True)elems[0].getText().encode('utf-8')[(y - x) for x, y in zip(L, L[1:])]print(re.search('\\bLOG_ADDR\\s+(\\S+)', line).group(1))	4
[dict((k, v) for k, v in d.items() if k != 'mykey1') for d in mylist]numpy.random.random((3, 3))df['C'] = df['A'] + df['B'][value for key, value in list(programs.items()) if 'new york' in key.lower()]sys.path.append('/path/to/main_folder')re.findall('\\d+(?=[^[]+$)', s)pickle.load(open('afile', 'rb'))driver.find_element_by_xpath('xpath').click()ex.groupby(level='A').agg(lambda x: x.index.get_level_values(1).nunique())pd.concat(map(pd.DataFrame, iter(d.values())), keys=list(d.keys())).stack().unstack(0)sum(1 for i, j in zip(a, b) if i != j)d = {(a.lower(), b): v for (a, b), v in list(d.items())}list_.sort(key=lambda x: [x[0], len(x[1]), x[1]])s.strip()s = s.lstrip()	4
"max(list(MyCount.keys()), key=int)os.system('source .bashrc; shopt -s expand_aliases; nuke -x scriptPath')my_function.__name__my_function.__name__np.all(a == a[(0), :], axis=0)sorted(a, key=lambda x: (sum(x[1:3]), x[0]))sorted(a, key=lambda x: (sum(x[1:3]), x[0]), reverse=True)sorted(lst, key=lambda x: (sum(x[1:]), x[0]))sorted(lst, key=lambda x: (sum(x[1:]), x[0]), reverse=True)response.headers['WWW-Authenticate'] = 'Basic realm=""test""'del request.session['mykey']datetime.datetime.strptime('24052010', '%d%m%Y').date()re.sub('[^\\x00-\\x7F]+', ' ', text)numpy.array([[1, 2], [3, 4]])myList = [i for i in range(10)]"	4
"driver.find_element_by_name('<check_box_name>').is_selected()driver.find_element_by_id('<check_box_id>').is_selected()[(a if a else 2) for a in [0, 1, 0, 3]]'M\\N{AMPERSAND}M\\N{APOSTROPHE}s'.encode().decode('unicode-escape')'M\\N{AMPERSAND}M\\N{APOSTROPHE}s'.decode('unicode-escape')chr(int('fd9b', 16)).encode('utf-8')print('0x%X' % value)cleaned = [x for x in your_list if x]slice(*[(int(i.strip()) if i else None) for i in string_slice.split(':')])soup.find_all(['a', 'div'])print(func.__name__)"""""""""""".join('{}{}'.format(key, val) for key, val in sorted(adict.items()))"""""""""""".join('{}{}'.format(key, val) for key, val in list(adict.items()))new_list = old_list[:]new_list = list(old_list)"	4
"'longlongTESTstringTEST'.replace('TEST', '?', 1)archive.write(pdffile, os.path.basename(pdffile))dict(x[1:] for x in reversed(myListOfTuples))[(x1 - x2) for x1, x2 in zip(List1, List2)]string[0].isdigit()strg.startswith(('0', '1', '2', '3', '4', '5', '6', '7', '8', '9'))print(os.path.dirname(os.path.realpath(__file__)))re.split('(?<=\\?|!|\\.)\\s{0,2}(?=[A-Z]|$)', text)plt.scatter(*zip(*li))tuple(zip(*t))df.groupby(np.arange(len(df.columns)) // 3, axis=1).mean()"""""""""""".join(chr(i) for i in L)sum(x == chosen_value for x in list(d.values()))sum(1 for x in list(d.values()) if some_condition(x))struct.unpack('f', struct.pack('f', 0.00582811585976))"	4
"{k: (d2[k] / d1[k]) for k in list(d1.keys()) & d2}dict((k, float(d2[k]) / d1[k]) for k in d2)df.to_csv(filename, date_format='%Y%m%d')my_dict.pop('key', None)b = np.where(np.isnan(a), 0, a)subprocess.call('start command -flags arguments', shell=True)subprocess.call('command -flags arguments &', shell=True)f = urllib.request.urlopen(url, urllib.parse.unquote(urllib.parse.urlencode(params)))""""""<tab>xyz<tab> """""".rstrip()urllib.parse.quote(s.encode('utf-8'))urllib.parse.quote_plus('a b')np.array(map(int, '100110'))print(np.array(list(mystr), dtype=int))img = cv2.imread('messi5.jpg', 0)lst.sort(key=lambda x: x[2], reverse=True)"	4
"re.sub('.{20}(.mkv)', '\\1', 'unique12345678901234567890.mkv')['a', 'c', 'b', 'obj']"""""" """""".join(mystring.split())print('{:.100f}'.format(2.345e-67))('key1' in dict)('a' in d)('c' in d)if ('key1' in dict):<nl><tab>passif (key in d):<nl><tab>passBlog.objects.filter(pk__in=[1, 4, 7])f = open('test/test.pdf', 'rb')format(12345678.46, ',').replace(',', ' ').replace('.', ',')pd.merge(frame_1, frame_2, left_on='county_ID', right_on='countyid')np.isnan(a).sum() / np.prod(a.shape)sorted(iter(cityPopulation.items()), key=lambda k_v: k_v[1][2], reverse=True)"	4
stringnamehere.decode('utf-8', 'ignore')re.findall('((?:A|B|C)D)', 'BDE')dic.setdefault(key, []).append(value)a[np.argmin(a[:, (1)])]a.update(b)[{k: v for k, v in d.items() if k != 'mykey1'} for d in mylist][dict((k, v) for k, v in d.items() if k != 'mykey1') for d in mylist]numpy.random.random((3, 3))df['C'] = df['A'] + df['B'][value for key, value in list(programs.items()) if 'new york' in key.lower()]sys.path.append('/path/to/main_folder')re.findall('\\d+(?=[^[]+$)', s)pickle.load(open('afile', 'rb'))driver.find_element_by_xpath('xpath').click()ex.groupby(level='A').agg(lambda x: x.index.get_level_values(1).nunique())	4
{p.id: {'id': p.id, 'position': ind} for ind, p in enumerate(p_list)}[dict(y) for y in set(tuple(x.items()) for x in d)]exec(compile(open('file.py').read(), 'file.py', 'exec'))rows = session.query(Congress).count()subprocess.call(['test.sh', str(domid)])dfs = pd.read_excel(file_name, sheetname=None)struct.unpack('d', binascii.unhexlify('4081637ef7d0424a'))a[tuple(b)]map(list, permutations([2, 3, 4]))sorted(unsorted_list, key=presorted_list.index)datetime.datetime.now() - datetime.timedelta(days=1)d = pd.DataFrame(0, index=np.arange(len(data)), columns=feature_list)x.find('World')x.find('Aloha')'sdfasdf'.index('cc')	4
"cursor.execute('INSERT INTO table (`column1`) VALUES (%s)', (value,))if url.endswith('.com'):<nl><tab>url = url[:(-4)]url = re.sub('\\.com$', '', url)print(url.replace('.com', ''))if (not text.endswith(suffix)):<nl><tab>return text<nl>return text[:(len(text) - len(suffix))]print(', ,'.join([str(i[0]) for i in mytuple]))max(min(my_value, max_value), min_value)re.findall('\\w+|[^\\w\\s]', text, re.UNICODE)result = db.engine.execute('<sql here>')sys.exit(0)"""""""""""".join(c for c in my_string if c.isdigit())re.split(' +', str1)re.findall('\\S+', str1)getattr(getattr(myobject, 'id', None), 'number', None){i: (i * 2) for i in range(10)}"	4
set([i for s in [list(d.keys()) for d in LoD] for i in s])[i for s in [list(d.keys()) for d in LoD] for i in s]keys, values = zip(*list(d.items()))int(Decimal(s))int(s.split('.')[0])numpy.in1d(b, a).all()numpy.array([(x in a) for x in b])networkx.draw_networkx_labels(G, pos, labels)y = [row[:] for row in x]X = numpy.loadtxt('somefile.csv', delimiter=',')matching = [s for s in some_list if 'abc' in s]df.to_csv('mydf.tsv', sep='\t')random.sample(list(range(100)), 10)s.rsplit(',', 1)all(isinstance(x, int) for x in lst)	4
if (not a):<nl><tab>passif (not seq):<nl><tab>passif (len(li) == 0):<nl><tab>pass[i for i, v in enumerate(a) if v > 4]sorted(yourdata, reverse=True)sorted(yourdata, key=lambda d: d.get('key', {}).get('subkey'), reverse=True)yourdata.sort(key=lambda e: e['key']['subkey'], reverse=True)df.round()gca().get_lines()[n].get_xydata()A[:, -2:]request.GET.get('username', '')pprint(dict(list(o.items())))url('^$', include('sms.urls')),url('^', include('sms.urls')),max_item = max(a_list, key=operator.itemgetter(1))	4
"ForkedPdb().set_trace()result = {k: d2.get(v) for k, v in list(d1.items())}datetime.datetime.now() + datetime.timedelta(days=1, hours=3)[int(s[i:i + 3], 2) for i in range(0, len(s), 3)]dict((v, k) for k, v in my_dict.items())print(sorted(L, key=lambda x: int(x.split('.')[2])))any(d['name'] == 'Test' for d in label)a[:] = [x for x in a if x != [1, 1]][x for x in a if x != [1, 1]]b = {a[i]: a[i + 1] for i in range(0, len(a), 2)}len(set(a)) == len(a)print(hashlib.md5(open(full_path, 'rb').read()).hexdigest())sorted(list(data.items()), key=lambda x: x[1][0])"""""""""""".join(x.upper() if random.randint(0, 1) else x for x in s)os.system('GREPDB=""echo 123""; /bin/bash -c ""$GREPDB""')"	4
"print(url.replace('.com', ''))if (not text.endswith(suffix)):<nl><tab>return text<nl>return text[:(len(text) - len(suffix))]print(', ,'.join([str(i[0]) for i in mytuple]))max(min(my_value, max_value), min_value)re.findall('\\w+|[^\\w\\s]', text, re.UNICODE)result = db.engine.execute('<sql here>')sys.exit(0)"""""""""""".join(c for c in my_string if c.isdigit())re.split(' +', str1)re.findall('\\S+', str1)getattr(getattr(myobject, 'id', None), 'number', None){i: (i * 2) for i in range(10)}dict((i, i * 2) for i in range(10))plt.cla()total = sum(float(item) for item in s.split(','))"	4
df[df.columns[1:]].replace('[\\$,]', '', regex=True).astype(float)df1.merge(df2, how='left', on='word')print(''.join(''.join(i) for i in zip(a2, a1)) + a[-1] if len(a) % 2 else '')root.attributes('-topmost', True)root.lift()hex(int(''.join([str(int(b)) for b in walls]), 2))hex(sum(b << i for i, b in enumerate(reversed(walls))))print(('Total score for', name, 'is', score))print('Total score for {} is {}'.format(name, score))print('Total score for %s is %s  ' % (name, score))print(('Total score for', name, 'is', score))url('^$', TemplateView.as_view(template_name='your_template.html'))df[df['A'].isin([3, 6])]instance.__class__.__name__system('/path/to/my/venv/bin/python myscript.py')	4
"os.system('ulimit -s unlimited; some_executable')""""""{0:.3g}"""""".format(num)numpy.append(a, a[0])df.ix[:, (df.loc[0] == 38.15)].columnsdf2['revenue'] = df2.CET.map(df1.set_index('date')['revenue'])json_data = json.loads(json_string)math.cos(math.radians(1))sum(isinstance(x, int) for x in a)'used\u200b'.replace('\u200b', '*')threading.Thread(target=SudsMove).start()sum(i * i for i in l)sum(map(lambda x: x * x, l))d = dict(((key, value) for (key, value) in iterable))d = {key: value for (key, value) in iterable}d = {k: v for (k, v) in iterable}"	4
int('0xff', 16)int('FFFF', 16)ast.literal_eval('0xdeadbeef')int('deadbeef', 16)os.system('screencapture screen.png')driver.set_window_size(1400, 1000)unicodedata.normalize('NFKD', 'm\xfasica').encode('ascii', 'ignore')pandas.concat([df1, df2]).drop_duplicates().reset_index(drop=True)a = numpy.fromfile('filename', dtype=numpy.float32)subprocess.call('mv /home/somedir/subdir/* somedir/', shell=True)subprocess.call('mv /home/somedir/subdir/* somedir/', shell=True)print('\u25b2'.encode('utf-8'))difflib.SequenceMatcher(None, file1.read(), file2.read())dict((k, int(v)) for k, v in (e.split(' - ') for e in s.split(',')))all(i in (1, 2, 3, 4, 5) for i in (1, 6))	4
"elems[0].getText().encode('utf-8')[(y - x) for x, y in zip(L, L[1:])]print(re.search('\\bLOG_ADDR\\s+(\\S+)', line).group(1))globals().update(importlib.import_module('some.package').__dict__)"""""""""""".join(['a', 'b', 'c', 'd'])url.split('&')od = collections.OrderedDict(sorted(d.items()))OrderedDict(sorted(list(d.items()), key=(lambda t: t[0])))response = requests.put(url, data=json.dumps(data), headers=headers)re.sub('[\\W_]+', '', s)[(x + y) for x in l2 for y in l1]dict([x.split('=') for x in s.split()])my_list.pop(2)s = s.replace('M', '')newstr = oldstr.replace('M', '')"	4
Task.objects.exclude(prerequisites__status__in=['A', 'P', 'F'])root.configure(background='black')numpy.array([(key, val) for key, val in result.items()], dtype)pd.concat([df_1, df_2.sort_values('y')])re.sub('(.*)</div>', '\\1</bad>', s)print(max(d, key=lambda x: (d[x]['salary'], d[x]['bonus'])))Book.objects.filter(author__id=1).filter(author__id=2)re.compile('XYZ', re.IGNORECASE).split('fooxyzbar')[sum(map(int, s)) for s in example.split()][i for i in y if y[i] == 1]c.decode('unicode_escape')pd.melt(x, id_vars=['farm', 'fruit'], var_name='year', value_name='value')default_data['item3'] = 3default_data.update({'item3': 3, })default_data.update({'item4': 4, 'item5': 5, })	4
[x for x in j if x >= 5]plt.plot(list(range(10)), '--bo')plt.plot(list(range(10)), linestyle='--', marker='o', color='b')[i.split('\t', 1)[0] for i in l]myList = [i.split('\t')[0] for i in myList]sum(your_list)ForkedPdb().set_trace()result = {k: d2.get(v) for k, v in list(d1.items())}datetime.datetime.now() + datetime.timedelta(days=1, hours=3)[int(s[i:i + 3], 2) for i in range(0, len(s), 3)]dict((v, k) for k, v in my_dict.items())print(sorted(L, key=lambda x: int(x.split('.')[2])))any(d['name'] == 'Test' for d in label)a[:] = [x for x in a if x != [1, 1]][x for x in a if x != [1, 1]]	4
all(x.count(1) == 3 for x in L)[x[0] for x in l1 if any(x[0] == y[0] for y in l2)]tex.delete('1.0', END)datetime.datetime.fromtimestamp(myNumber).strftime('%Y-%m-%d %H:%M:%S')system('python myscript.py')your_list.sort(key=operator.attrgetter('anniversary_score'))your_list.sort(key=lambda x: x.anniversary_score)print(type(tf.Session().run(tf.constant([1, 2, 3]))))list(itertools.chain(*a))count.setdefault('a', 0)df.groupby(['cluster']).mean()min(myList, key=lambda x: abs(x - myNumber))any(x in string for x in search)print(pattern.search(url).group(1))(s.factorize()[0] + 1).astype('float')	4
print([''.join(a) for a in combinations(['hel', 'lo', 'bye'], 2)])[x for x in li if 'ar' in x[2]]unsorted_list.sort(key=lambda x: x[3])logging.info('test')fig.add_subplot(1, 1, 1)sorted(list(x.items()), key=operator.itemgetter(1))sorted(dict1, key=dict1.get)sorted(d, key=d.get, reverse=True)sorted(list(d.items()), key=(lambda x: x[1]))np.einsum('ijk,ikl->ijl', A, B)print('I have: {0.price}'.format(card))f.write('# Data for Class A\n')a = a[-1:] + a[:-1]datetimevariable.strftime('%Y-%m-%d')mixed.replace('\r\n', '\n').replace('\r', '\n')	4
a.shape[i for i, v in enumerate(L) if v[0] == 53]struct.unpack('<L', 'y\xcc\xa6\xbb')[0]arr[[0, 1, 1], [1, 0, 2]]list(powerset('abcd'))s in ['true', '1', 't', 'y', 'yes', 'yeah', 'yup', 'certainly', 'uh-huh']urllib.parse.quote('http://spam.com/go/')plt.savefig('test.svg')len(myArray)sys.path.insert(0, './path/to/your/modules/')ax.xaxis.set_ticks_position('top')cursor.execute('INSERT OR REPLACE INTO master.table1 SELECT * FROM table1')re.match('[a-zA-Z][\\w-]*\\Z', 'A\n')re.match('[a-zA-Z][\\w-]*$', '!A_B')int('deadbeef', 16)	4
url('^$', include('sms.urls')),url('^', include('sms.urls')),max_item = max(a_list, key=operator.itemgetter(1))max(a_list, key=operator.itemgetter(1))s.resample('3M', how='sum')[a[i] for i in (1, 2, 5)][line for line in open('textfile') if 'apple' in line]datetime.datetime.strptime(s, '%Y-%m-%dT%H:%M:%SZ')pandas.read_csv(filename, sep='\t', lineterminator='\r')'longlongTESTstringTEST'.replace('TEST', '?', 1)archive.write(pdffile, os.path.basename(pdffile))dict(x[1:] for x in reversed(myListOfTuples))[(x1 - x2) for x1, x2 in zip(List1, List2)]string[0].isdigit()strg.startswith(('0', '1', '2', '3', '4', '5', '6', '7', '8', '9'))	4
"results += [each for each in os.listdir(folder) if each.endswith('.c')]print('\xc2\xa3'.decode('utf8') + '1')re.sub('(?<=[a-z])([A-Z])', '-\\1', s).lower()os.system('ulimit -s unlimited; some_executable')""""""{0:.3g}"""""".format(num)numpy.append(a, a[0])df.ix[:, (df.loc[0] == 38.15)].columnsdf2['revenue'] = df2.CET.map(df1.set_index('date')['revenue'])json_data = json.loads(json_string)math.cos(math.radians(1))sum(isinstance(x, int) for x in a)'used\u200b'.replace('\u200b', '*')threading.Thread(target=SudsMove).start()sum(i * i for i in l)sum(map(lambda x: x * x, l))"	4
"myList[:] = [(x / myInt) for x in myList]""""""Name: {0[person.name]}"""""".format({'person.name': 'Joe'})df.replace(' ', '_', regex=True)datetime.datetime.combine(my_date, datetime.time.min)tst2 = str(tst)time.ctime(os.path.getmtime(file))time.ctime(os.path.getctime(file))t = os.path.getmtime(filename)os.path.getmtime(path)print(('last modified: %s' % time.ctime(os.path.getmtime(file))))print(('created: %s' % time.ctime(os.path.getctime(file))))return os.path.getctime(path_to_file)os.system('TASKKILL /F /IM firefox.exe')return (x.group(0) for x in re.finditer(""[A-Za-z']+"", string))"""""", """""".join(['%.2f'] * len(x))"	4
y = map(operator.itemgetter(0), x)y = [i[0] for i in x]results = [item['value'] for item in test_data]datetime.datetime.now().isoformat()datetime.datetime.utcnow().isoformat()df.apply(' '.join, axis=0)pd.DataFrame(df.values - df2.values, columns=df.columns)print(open('myfile.txt', 'U').read())print(line.decode('utf-16-le').split())file = io.open('data.txt', 'r', encoding='utf-16-le')s1 = pd.merge(df1, df2, how='inner', on=['user_id'])foo.decode('utf8').encode('utf8')a.shapeN.shape(a)N.shape(a)	4
"pd.to_datetime(pd.Series(date_stngs))df.iloc[2, 0]matplotlib.rcParams.update({'font.size': 22})pd.DataFrame(list(d.items()), columns=['Date', 'DateValue'])pd.DataFrame(df.values * df2.values, columns=df.columns, index=df.index)re.findall('\\d+\\.\\d+', 'Current Level: 13.4 db.')re.findall('[-+]?\\d*\\.\\d+|\\d+', 'Current Level: -13.2 db or 14.2 or 3')zip(it, it, it)df['x'].str.lower()jsobj['a']['b']['e'].append({'f': var6, 'g': var7, 'h': var8})"""""""""""".join(lst)sum(v for v in list(d.values()) if v > 0)app.run(debug=True)df.drop(df.index[[1, 3]], inplace=True)df.apply(lambda x: x.fillna(x.mean()), axis=0)"	4
"(date(2010, 12, 31) + relativedelta(months=(+ 2)))print((datetime.date.today() + datetime.timedelta(((6 * 365) / 12))).isoformat())sorted(list(things.keys()), key=lambda x: things[x]['weight'], reverse=True)a[np.arange(len(a)) != 3][x for x in lst if fn(x) != 0]df.set_index('month')arr = [line.split(',') for line in open('./urls-eu.csv')][i for i in range(100) if i > 10 if i < 20]"""""""""""".join([c for c in strs if c.isdigit()])re.split('\\t+', yas.rstrip('\t'))(a.T * b).T'test string\n'.rstrip()'test string \n\n'.rstrip('\n')s.strip()s.rstrip()"	4
"threading.Thread(target=SudsMove).start()sum(i * i for i in l)sum(map(lambda x: x * x, l))d = dict(((key, value) for (key, value) in iterable))d = {key: value for (key, value) in iterable}d = {k: v for (k, v) in iterable}df.round({'Alabama_exp': 2, 'Credit_exp': 3})p.setopt(pycurl.WRITEFUNCTION, lambda x: None)print(random.choice(words))max(d, key=lambda x: d[x]['count'])[(int(x) if x else 0) for x in data.split(',')]"""""","""""".join(x or '0' for x in s.split(','))re.compile('$^')re.compile('.\\A|.\\A*|.\\A+')re.compile('a^')"	4
"time.ctime(os.path.getctime(file))t = os.path.getmtime(filename)os.path.getmtime(path)print(('last modified: %s' % time.ctime(os.path.getmtime(file))))print(('created: %s' % time.ctime(os.path.getctime(file))))return os.path.getctime(path_to_file)os.system('TASKKILL /F /IM firefox.exe')return (x.group(0) for x in re.finditer(""[A-Za-z']+"", string))"""""", """""".join(['%.2f'] * len(x))print(re.match('(\\d+(\\.\\d+)?)', '3434.35353').group(1))df['name'].str.replace('\\(.*\\)', '')result = [x for x in list_a if x[0] in list_b]print([''.join(a) for a in combinations(['hel', 'lo', 'bye'], 2)])[x for x in li if 'ar' in x[2]]unsorted_list.sort(key=lambda x: x[3])"	4
today = datetime.datetime.utcnow().date()[(a * b) for a, b in zip(lista, listb)]re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', s)re.match('[:;][)(](?![)(])', str)json_string = json.dumps([ob.__dict__ for ob in list_name])listofzeros = [0] * nstringnamehere.decode('utf-8', 'ignore')re.findall('((?:A|B|C)D)', 'BDE')dic.setdefault(key, []).append(value)a[np.argmin(a[:, (1)])]a.update(b)[{k: v for k, v in d.items() if k != 'mykey1'} for d in mylist][dict((k, v) for k, v in d.items() if k != 'mykey1') for d in mylist]numpy.random.random((3, 3))df['C'] = df['A'] + df['B']	4
"pd.DataFrame(list(d.items()), columns=['Date', 'DateValue'])pd.DataFrame(df.values * df2.values, columns=df.columns, index=df.index)re.findall('\\d+\\.\\d+', 'Current Level: 13.4 db.')re.findall('[-+]?\\d*\\.\\d+|\\d+', 'Current Level: -13.2 db or 14.2 or 3')zip(it, it, it)df['x'].str.lower()jsobj['a']['b']['e'].append({'f': var6, 'g': var7, 'h': var8})"""""""""""".join(lst)sum(v for v in list(d.values()) if v > 0)app.run(debug=True)df.drop(df.index[[1, 3]], inplace=True)df.apply(lambda x: x.fillna(x.mean()), axis=0)[o.my_attr for o in my_list]time.strftime('%m/%d/%Y', time.gmtime(os.path.getmtime(file)))all(item in list(superset.items()) for item in list(subset.items()))"	4
list_.sort(key=lambda x: [x[0], len(x[1]), x[1]])s.strip()s = s.lstrip()s = s.rstrip()s = s.strip(' \t\n\r')print(re.sub('[\\s+]', '', s))Task.objects.exclude(prerequisites__status__in=['A', 'P', 'F'])root.configure(background='black')numpy.array([(key, val) for key, val in result.items()], dtype)pd.concat([df_1, df_2.sort_values('y')])re.sub('(.*)</div>', '\\1</bad>', s)print(max(d, key=lambda x: (d[x]['salary'], d[x]['bonus'])))Book.objects.filter(author__id=1).filter(author__id=2)re.compile('XYZ', re.IGNORECASE).split('fooxyzbar')[sum(map(int, s)) for s in example.split()]	4
json.loads(open('sample.json').read().decode('utf-8-sig'))server = smtplib.SMTP('smtp.gmail.com', 587)int('{:08b}'.format(n)[::-1], 2)df.set_index(['d'], append=True)for (key, value) in d.items():<nl><tab>passfor (key, value) in list(d.items()):<nl><tab>passfor (letter, number) in list(d.items()):<nl><tab>passfor (k, v) in list(d.items()):<nl><tab>passlist(d.items())list(d.items())for (k, v) in list(d.items()):<nl><tab>passfor (letter, number) in list(d.items()):<nl><tab>passfor (letter, number) in list(d.items()):<nl><tab>passsession.query(Task).filter(Task.time_spent > timedelta(hours=3)).all()os.system('msbuild project.sln /p:Configuration=Debug')	4
my_list = [[x for x in sublist if x not in to_del] for sublist in my_list][item for item in a if 1 in item][item for item in a if item[0] == 1]{p.id: {'id': p.id, 'position': ind} for ind, p in enumerate(p_list)}[dict(y) for y in set(tuple(x.items()) for x in d)]exec(compile(open('file.py').read(), 'file.py', 'exec'))rows = session.query(Congress).count()subprocess.call(['test.sh', str(domid)])dfs = pd.read_excel(file_name, sheetname=None)struct.unpack('d', binascii.unhexlify('4081637ef7d0424a'))a[tuple(b)]map(list, permutations([2, 3, 4]))sorted(unsorted_list, key=presorted_list.index)datetime.datetime.now() - datetime.timedelta(days=1)d = pd.DataFrame(0, index=np.arange(len(data)), columns=feature_list)	4
[y for y in a if y not in b]df.groupby('ID').head(4)zip(*l)dict(zip([1, 2, 3, 4], ['a', 'b', 'c', 'd']))dict(zip([1, 2, 3, 4], ['a', 'b', 'c', 'd']))request.urlsomestring.replace('\\r', '')simplejson.dumps(dict([('%d,%d' % k, v) for k, v in list(d.items())]))datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')parser.parse('Aug 28 1999 12:00AM')os.path.split(os.path.abspath(existGDBPath))os.path.dirname(os.path.abspath(existGDBPath))requests.post('http://httpbin.org/post', json={'test': 'cheers'})a = [x for x in a if x['link'] not in b]{{request.args.get('a')}}	4
"tree.xpath("".//a[text()='Example']"")[0].tag"""""", """""".join([(str(k) + ' ' + str(v)) for k, v in list(a.items())])print(set(re.sub('[\x00-\x7f]', '', '\xa3\u20ac\xa3\u20ac')))print(re.sub('[\x00-\x7f]', '', '\xa3100 is worth more than \u20ac100'))ast.literal_eval(""{'muffin' : 'lolz', 'foo' : 'kitty'}"")print(t.decode('unicode_escape'))print(str.encode('cp1252').decode('utf-8').encode('cp1252').decode('utf-8'))zip(list_a, list_b)list(zip(a, b))df.set_index('id').to_dict()df.set_index('id')['value'].to_dict()sorted(list(mydict.items()), key=lambda a: map(int, a[0].split('.')))re.sub('\\([^)]*\\)', '', filename)""""""a b"""""".replace(' ', '').isalpha()[(x + y) for x, y in zip(first, second)]"	4
text.config(state=DISABLED)sum(map(ord, string))list(itertools.product(*arrays))'{:,}'.format(value)locale.setlocale(locale.LC_ALL, 'en_US')<nl>locale.format('%d', 1255000, grouping=True)df[df.Col1.isin(['men', 'rocks', 'mountains'])][x[1] for x in L]'\u0440\u0430\u0437 \u0434\u0432\u0430 \u0442\u0440\u0438'.split()MyModel.objects.extra(select={'length': 'Length(name)'}).order_by('length')min(dicts, key=lambda x: (abs(1.77672955975 - x['ratio']), -x['pixels']))m[~m.mask]re.findall('\\b[A-Z]', formula)matrix = [([0] * 5) for i in range(5)]np.vstack(np.meshgrid(x_p, y_p, z_p)).reshape(3, -1).Tarr[arr != 0].min()	4
"'M\\N{AMPERSAND}M\\N{APOSTROPHE}s'.encode().decode('unicode-escape')'M\\N{AMPERSAND}M\\N{APOSTROPHE}s'.decode('unicode-escape')chr(int('fd9b', 16)).encode('utf-8')print('0x%X' % value)cleaned = [x for x in your_list if x]slice(*[(int(i.strip()) if i else None) for i in string_slice.split(':')])soup.find_all(['a', 'div'])print(func.__name__)"""""""""""".join('{}{}'.format(key, val) for key, val in sorted(adict.items()))"""""""""""".join('{}{}'.format(key, val) for key, val in list(adict.items()))new_list = old_list[:]new_list = list(old_list)new_list = copy.copy(old_list)new_list = copy.deepcopy(old_list)[i for i in old_list]"	4
len(dict_test) + sum(len(v) for v in dict_test.values())hex(d).split('x')[1]list(str(123))[int(x) for x in str(num)]br.select_form(nr=0)json.load(codecs.open('sample.json', 'r', 'utf-8-sig'))json.loads(open('sample.json').read().decode('utf-8-sig'))server = smtplib.SMTP('smtp.gmail.com', 587)int('{:08b}'.format(n)[::-1], 2)df.set_index(['d'], append=True)for (key, value) in d.items():<nl><tab>passfor (key, value) in list(d.items()):<nl><tab>passfor (letter, number) in list(d.items()):<nl><tab>passfor (k, v) in list(d.items()):<nl><tab>passlist(d.items())	4
"df['Date'].map(lambda t: t.date()).unique()""""""{:>7s}"""""".format(mystring)open('ComponentReport-DJI.xls', 'rb').read(200)df.sort_values(['b', 'c'], ascending=[True, False], inplace=True)df.sort_values(['a', 'b'], ascending=[True, False])df1.sort(['a', 'b'], ascending=[True, False], inplace=True)df.sort(['a', 'b'], ascending=[True, False])redirect('Home.views.index')[x for x in a if x not in [2, 3, 7]]out = ''.join(c for c in asking if c not in ('!', '.', ':'))soup.find('meta', {'name': 'City'})['content']urllib.parse.unquote('%0a')urllib.parse.unquote(url).decode('utf8')del lst[:]del lst1[:]"	4
"dict(map(int, x.split(':')) for x in s.split(','))driver.find_element_by_xpath(""//div[@id='a']//a[@class='click']"")np.where((vals == (0, 1)).all(axis=1))SomeModel.objects.filter(id=id).delete()dict([['two', 2], ['one', 1]])dict(zip(l[::2], l[1::2]))GRAVITY = 9.8re.findall('(([0-9]+)([A-Z]))', '20M10000N80M')re.findall('([0-9]+|[A-Z])', '20M10000N80M')re.findall('([0-9]+)([A-Z])', '20M10000N80M')re.compile('\\w+').findall('Hello world, my name is...James the 2nd!')datetime.datetime.strptime('03:55', '%H:%M').time()requests.get('https://www.reporo.com/', verify=False)a[a != 0]new_dict = {k: v for k, v in zip(keys, values)}"	4
print('{:.100f}'.format(2.345e-67))('key1' in dict)('a' in d)('c' in d)if ('key1' in dict):<nl><tab>passif (key in d):<nl><tab>passBlog.objects.filter(pk__in=[1, 4, 7])f = open('test/test.pdf', 'rb')format(12345678.46, ',').replace(',', ' ').replace('.', ',')pd.merge(frame_1, frame_2, left_on='county_ID', right_on='countyid')np.isnan(a).sum() / np.prod(a.shape)sorted(iter(cityPopulation.items()), key=lambda k_v: k_v[1][2], reverse=True)sorted(list(u.items()), key=lambda v: v[1])sorted(list(d.items()), key=lambda k_v: k_v[1], reverse=True)sorted(list(d.items()), key=lambda k_v: k_v[1])	4
"""""""2.7.0_bf4fda703454"""""".split('_')sorted(lst, key=lambda x: x['language'] != 'en')all(value == 0 for value in list(your_dict.values()))df.pivot_table('Y', rows='X', cols='X2')try:<nl><tab>doSomething()<nl>except:<nl><tab>passtry:<nl><tab>doSomething()<nl>except Exception:<nl><tab>passM.sum(axis=0).sum(axis=0)time.mktime(dt.timetuple()) + dt.microsecond / 1000000.0df[(x <= df['columnX']) & (df['columnX'] <= y)]sorted(L, key=itemgetter(2))l.sort(key=(lambda x: x[2]))sorted(l, key=(lambda x: x[2]))sorted_list = sorted(list_to_sort, key=itemgetter(2, 0, 1))np.argwhere(np.all(arr == [[0, 3], [3, 0]], axis=(1, 2)))data.loc[:, (list(itertools.product(['one', 'two'], ['a', 'c'])))]"	4
"re.sub('(?<!\\S)((\\S+)(?:\\s+\\2))(?:\\s+\\2)+(?!\\S)', '\\1', s)df.div(df.sum(axis=1), axis=0)map(lambda t: (t[1], t[0]), mylist)[(t[1], t[0]) for t in mylist]driver.find_element_by_xpath(""//p[@id, 'one']/following-sibling::p"")re.findall('\\[[^\\]]*\\]|\\([^\\)]*\\)|""[^""]*""|\\S+', strs)print(list(itertools.combinations({1, 2, 3, 4}, 3)))df[['hour', 'weekday', 'weeknum']] = df.apply(lambdafunc, axis=1)soup.find_all('a', string='Elsie')my_datetime.strftime('%B %d, %Y')int(''.join(c for c in s if c.isdigit()))dic['Test'].update({'class': {'section': 5}})dict(map(int, x.split(':')) for x in s.split(','))driver.find_element_by_xpath(""//div[@id='a']//a[@class='click']"")np.where((vals == (0, 1)).all(axis=1))"	4
Sample.objects.filter(date__range=['2011-01-01', '2011-01-31'])Sample.objects.filter(date__year='2011', date__month='01')d['dict3'] = {'spam': 5, 'ham': 6}numpy.apply_along_axis(numpy.linalg.norm, 1, a)dict((k, v) for d in dicts for k, v in list(d.items()))print('your string'.decode('string_escape'))sum([True, True, False, False, False, True])fig.set_size_inches(w, h, forward=True)'hello there %(5)s' % {'5': 'you'}map(int, example_string.split(','))[int(s) for s in example_string.split(',')]x = [i[0] for i in x]y = map(operator.itemgetter(0), x)y = [i[0] for i in x]results = [item['value'] for item in test_data]	4
"hex(sum(b << i for i, b in enumerate(reversed(walls))))print(('Total score for', name, 'is', score))print('Total score for {} is {}'.format(name, score))print('Total score for %s is %s  ' % (name, score))print(('Total score for', name, 'is', score))url('^$', TemplateView.as_view(template_name='your_template.html'))df[df['A'].isin([3, 6])]instance.__class__.__name__system('/path/to/my/venv/bin/python myscript.py')Employees.objects.values_list('eng_name', flat=True)re.findall('\\d|\\d,\\d\\)', '6,7)')input('Press Enter to continue...')""""""ABC"""""".encode('hex')db.Doc.update({'_id': b['_id']}, {'$set': {'geolocCountry': myGeolocCountry}})re.sub('l+', 'l', 'lollll')"	4
"isinstance(s, str)dict(pair for d in L for pair in list(d.items())){k: v for d in L for k, v in list(d.items())}df.sort_values(['Peak', 'Weeks'], ascending=[True, False], inplace=True)df.sort(['Peak', 'Weeks'], ascending=[True, False], inplace=True)eval(""print('Hello')"")[{'A': 1, 'C': 4, 'B': 2, 'D': 4}, {'A': 1, 'C': 4, 'B': 1, 'D': 5}][{'A': 1, 'C': 4, 'B': 2, 'D': 4}, {'A': 1, 'C': 4, 'B': 1, 'D': 5}]list(itertools.product(*a))df.groupby(['Country', 'Item_Code'])[['Y1961', 'Y1962', 'Y1963']].sum()done = [(el, x) for el in [a, b, c, d]]x = x[numpy.logical_not(numpy.isnan(x))]os.path.join(*x.split(os.path.sep)[2:])line = line.replace(';', ':')subprocess.call('tar c my_dir | md5sum', shell=True)"	4
"my_dict.pop('key', None)b = np.where(np.isnan(a), 0, a)subprocess.call('start command -flags arguments', shell=True)subprocess.call('command -flags arguments &', shell=True)f = urllib.request.urlopen(url, urllib.parse.unquote(urllib.parse.urlencode(params)))""""""<tab>xyz<tab> """""".rstrip()urllib.parse.quote(s.encode('utf-8'))urllib.parse.quote_plus('a b')np.array(map(int, '100110'))print(np.array(list(mystr), dtype=int))img = cv2.imread('messi5.jpg', 0)lst.sort(key=lambda x: x[2], reverse=True)indices = [i for i, x in enumerate(my_list) if x == 'whatever']subprocess.call('grep -r PASSED *.log | sort -u | wc -l', shell=True)len(my_text) - len(my_text.rstrip('?'))"	4
sorted(L, key=itemgetter(2))l.sort(key=(lambda x: x[2]))sorted(l, key=(lambda x: x[2]))sorted_list = sorted(list_to_sort, key=itemgetter(2, 0, 1))np.argwhere(np.all(arr == [[0, 3], [3, 0]], axis=(1, 2)))data.loc[:, (list(itertools.product(['one', 'two'], ['a', 'c'])))]data.loc[:, ([('one', 'a'), ('one', 'c'), ('two', 'a'), ('two', 'c')])]hashtags = re.findall('#(\\w+)', str1, re.UNICODE)os.rename(src, dst)print(etree.tostring(some_tag.find('strong')))json.dumps({str(k): v for k, v in data.items()})soup = BeautifulSoup(response.read().decode('utf-8'))os.remove(filename)min([x for x in num_list if x > 2])df['prod_type'] = 'responsive'	4
"dict((k, v) for k, v in zip(keys, values))dict([(k, v) for k, v in zip(keys, values)])m = re.search('\\[(\\w+)\\]', s)s.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1)list3 = [(a + b) for a, b in zip(list1, list2)][ord(c) for c in s.decode('hex')]print(sorted(student_tuples, key=lambda t: (-t[2], t[0])))[y for x in range(3) for y in [x, x]]txt = open('file.txt').read()myList[:] = [(x / myInt) for x in myList]""""""Name: {0[person.name]}"""""".format({'person.name': 'Joe'})df.replace(' ', '_', regex=True)datetime.datetime.combine(my_date, datetime.time.min)tst2 = str(tst)time.ctime(os.path.getmtime(file))"	4
"jsobj['a']['b']['e'].append({'f': var6, 'g': var7, 'h': var8})"""""""""""".join(lst)sum(v for v in list(d.values()) if v > 0)app.run(debug=True)df.drop(df.index[[1, 3]], inplace=True)df.apply(lambda x: x.fillna(x.mean()), axis=0)[o.my_attr for o in my_list]time.strftime('%m/%d/%Y', time.gmtime(os.path.getmtime(file)))all(item in list(superset.items()) for item in list(subset.items()))[str(wi) for wi in wordids]df2 = df.reset_index()dt.strftime('%m/%d/%Y')print('Total cost is: ${:,.2f}'.format(TotalAmount))df.groupby(np.arange(len(df.columns)) // 2 + 1, axis=1).sum().add_prefix('s')randomList = [random.random() for _ in range(10)]"	4
sorted(s, key=str.upper)sorted(sorted(s), key=str.upper)sorted(s, key=str.lower)pd.merge(df1, df2, on=['A', 'B', 'C', 'D'], how='inner')dict((v, k) for k, v in map.items())s.decode('unicode_escape')[int(i) for i in str_list]map(int, ['1', '2', '3'])list(map(int, ['1', '2', '3']))soup.find_all('a', href=re.compile('http://www\\.iwashere\\.com/'))soup.find_all('a', href=re.compile('^(?!(?:[a-zA-Z][a-zA-Z0-9+.-]*:|//))'))subprocess.call(['java', '-jar', 'Blender.jar'])cursor.execute('INSERT INTO table (`column1`) VALUES (%s)', (value,))if url.endswith('.com'):<nl><tab>url = url[:(-4)]url = re.sub('\\.com$', '', url)	4
"max(min(my_value, max_value), min_value)re.findall('\\w+|[^\\w\\s]', text, re.UNICODE)result = db.engine.execute('<sql here>')sys.exit(0)"""""""""""".join(c for c in my_string if c.isdigit())re.split(' +', str1)re.findall('\\S+', str1)getattr(getattr(myobject, 'id', None), 'number', None){i: (i * 2) for i in range(10)}dict((i, i * 2) for i in range(10))plt.cla()total = sum(float(item) for item in s.split(','))bin(ord('P'))print(my_string.split(', ', 1)[1])print(data['places'][0]['post code'])"	4
{{tags | join(' ')}}help('modules')[[[x[0]] for x in listD[i]] for i in range(len(listD))]sorted(s, key=str.upper)sorted(sorted(s), key=str.upper)sorted(s, key=str.lower)pd.merge(df1, df2, on=['A', 'B', 'C', 'D'], how='inner')dict((v, k) for k, v in map.items())s.decode('unicode_escape')[int(i) for i in str_list]map(int, ['1', '2', '3'])list(map(int, ['1', '2', '3']))soup.find_all('a', href=re.compile('http://www\\.iwashere\\.com/'))soup.find_all('a', href=re.compile('^(?!(?:[a-zA-Z][a-zA-Z0-9+.-]*:|//))'))subprocess.call(['java', '-jar', 'Blender.jar'])	4
map(int, re.findall('\\d+', string1))os.path.dirname(sys.executable)ax.xaxis.set_label_position('top')ax.xaxis.tick_top()ax.xaxis.set_ticks_position('top')datetime.strptime('2015/01/01 12:12am', '%Y/%m/%d %I:%M%p')img = Image.open('picture.jpg')<nl>img.show()img = Image.open('picture.jpg')<nl>Img.showsys.exit(0)sys.exit('aa! errors!')sys.exit()[max(abs(x) for x in arr[i:i + 4]) for i in range(0, len(arr), 4)]os.chdir('c:\\Users\\uname\\desktop\\python')os.chdir(path)no_integers = [x for x in mylist if not isinstance(x, int)]	4
df.pivot_table('Y', rows='X', cols='X2')try:<nl><tab>doSomething()<nl>except:<nl><tab>passtry:<nl><tab>doSomething()<nl>except Exception:<nl><tab>passM.sum(axis=0).sum(axis=0)time.mktime(dt.timetuple()) + dt.microsecond / 1000000.0df[(x <= df['columnX']) & (df['columnX'] <= y)]sorted(L, key=itemgetter(2))l.sort(key=(lambda x: x[2]))sorted(l, key=(lambda x: x[2]))sorted_list = sorted(list_to_sort, key=itemgetter(2, 0, 1))np.argwhere(np.all(arr == [[0, 3], [3, 0]], axis=(1, 2)))data.loc[:, (list(itertools.product(['one', 'two'], ['a', 'c'])))]data.loc[:, ([('one', 'a'), ('one', 'c'), ('two', 'a'), ('two', 'c')])]hashtags = re.findall('#(\\w+)', str1, re.UNICODE)os.rename(src, dst)	4
app.run(debug=True)df.drop(df.index[[1, 3]], inplace=True)df.apply(lambda x: x.fillna(x.mean()), axis=0)[o.my_attr for o in my_list]time.strftime('%m/%d/%Y', time.gmtime(os.path.getmtime(file)))all(item in list(superset.items()) for item in list(subset.items()))[str(wi) for wi in wordids]df2 = df.reset_index()dt.strftime('%m/%d/%Y')print('Total cost is: ${:,.2f}'.format(TotalAmount))df.groupby(np.arange(len(df.columns)) // 2 + 1, axis=1).sum().add_prefix('s')randomList = [random.random() for _ in range(10)]print(soup.find('a', href=re.compile('.*follow\\?page.*')))sys.stdout.flush()country, capital = random.choice(list(d.items()))	4
driver.get('http://www.google.com.br')b = a.decode('utf8')[::-1].encode('utf8')dparser.parse('monkey 2010-07-32 love banana', fuzzy=True)dparser.parse('monkey 20/01/1980 love banana', fuzzy=True)dparser.parse('monkey 10/01/1980 love banana', fuzzy=True)dict(map(lambda s: s.split(':'), ['A:1', 'B:2', 'C:3', 'D:4']))re.search('[a-zA-Z]', the_string)DataFrame({'count': df1.groupby(['Name', 'City']).size()}).reset_index()re.sub('[^0-9]', '', 'sdkjh987978asd098as0980a98sd')[y for y in a if y not in b]df.groupby('ID').head(4)zip(*l)dict(zip([1, 2, 3, 4], ['a', 'b', 'c', 'd']))dict(zip([1, 2, 3, 4], ['a', 'b', 'c', 'd']))request.url	4
pd.concat([df_1, df_2.sort_values('y')])re.sub('(.*)</div>', '\\1</bad>', s)print(max(d, key=lambda x: (d[x]['salary'], d[x]['bonus'])))Book.objects.filter(author__id=1).filter(author__id=2)re.compile('XYZ', re.IGNORECASE).split('fooxyzbar')[sum(map(int, s)) for s in example.split()][i for i in y if y[i] == 1]c.decode('unicode_escape')pd.melt(x, id_vars=['farm', 'fruit'], var_name='year', value_name='value')default_data['item3'] = 3default_data.update({'item3': 3, })default_data.update({'item4': 4, 'item5': 5, })l[:3] + l[-3:]df = df.reset_index(drop=True)[a[x].append(b[x]) for x in range(3)]	4
driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')datetime.datetime.combine(dateobject, datetime.time())print(any(x in a for x in b))scipy.misc.imsave('outfile.jpg', image_array)item = re.sub(' ?\\([^)]+\\)', '', item)item = re.sub(' ?\\(\\w+\\)', '', item)item = re.sub(' \\(\\w+\\)', '', item)len(set(list1).intersection(list2)) > 0i = int(s, 16)int('0xff', 16)int('FFFF', 16)ast.literal_eval('0xdeadbeef')int('deadbeef', 16)os.system('screencapture screen.png')driver.set_window_size(1400, 1000)	4
"globals().update(importlib.import_module('some.package').__dict__)"""""""""""".join(['a', 'b', 'c', 'd'])url.split('&')od = collections.OrderedDict(sorted(d.items()))OrderedDict(sorted(list(d.items()), key=(lambda t: t[0])))response = requests.put(url, data=json.dumps(data), headers=headers)re.sub('[\\W_]+', '', s)[(x + y) for x in l2 for y in l1]dict([x.split('=') for x in s.split()])my_list.pop(2)s = s.replace('M', '')newstr = oldstr.replace('M', '')sum(x * y for x, y in zip(a, b))list(x * y for x, y in list(zip(a, b)))sum(i * j for i, j in zip(a, b))"	4
df.plot(x='col_name_1', y='col_name_2', style='o')parsed_html = BeautifulSoup(html)<nl>print(parsed_html.body.find('div', attrs={'class': 'container', }).text)page = urllib.request.urlopen('http://www.google.com/')<nl>soup = BeautifulSoup(page)plt.figure(figsize=(3, 4))s.translate(None, string.punctuation)base64.urlsafe_b64decode(uenc.encode('ascii'))len(dict_test) + sum(len(v) for v in dict_test.values())hex(d).split('x')[1]list(str(123))[int(x) for x in str(num)]br.select_form(nr=0)json.load(codecs.open('sample.json', 'r', 'utf-8-sig'))json.loads(open('sample.json').read().decode('utf-8-sig'))server = smtplib.SMTP('smtp.gmail.com', 587)int('{:08b}'.format(n)[::-1], 2)	4
re.compile('^(.+)\\n((?:\\n.+)+)', re.MULTILINE)call(['path/to/python', 'test2.py', 'neededArgumetGoHere'])a.sort(key=operator.itemgetter(2, 3))final_choices = ((another_choice,) + my_choices)final_choices = ((another_choice,) + my_choices)os.getcwd()os.path.realpath(__file__)os.path.dirname(path)os.path.realpath(path)dir_path = os.path.dirname(os.path.realpath(__file__))cwd = os.getcwd()full_path = os.path.realpath(__file__)arr[arr[:, (2)].argsort()]numpy.sort(arr, axis=0)re.split('[ .]', 'a b.c')	4
"x[::-1]json.dumps({'apple': 'cat', 'banana': 'dog', 'pear': 'fish'})csvwriter.writerow(row){{(item.date | date): 'Y M d'}}re.split('(?<=[\\.\\?!]) ', text)re.compile('\xe2\x80\x93')variable = []intarray = array('i')[sublist[::-1] for sublist in to_reverse[::-1]]re.sub('[^0-9a-zA-Z]+', '*', 'h^&ell`.,|o w]{+orld')"""""""""""".join(['I ', '<', '3s U ', '&', ' you luvz me'])logging.disable(logging.CRITICAL)cursor.execute('INSERT INTO index(url) VALUES(%s)', (url,))df['DateStr'] = df['DateObj'].dt.strftime('%d%m%Y')s.split('@')[0]"	4
df.query('index < @start_remove or index > @end_remove')df.loc[(df.index < start_remove) | (df.index > end_remove)]df.isnull().sum()df.reset_index(inplace=True)[x['value'] for x in list_of_dicts][d['value'] for d in l][d['value'] for d in l if 'value' in d]np.array([[1, 2, 3], [4, 5, 6]]).tolist()ast.literal_eval('(1,2,3,4)')dataList.sort(key=lambda x: x[1])list(map(list, set(map(lambda i: tuple(i), testdata))))[list(i) for i in set(tuple(i) for i in testdata)]return user.groups.filter(name='Member').exists()return user.groups.filter(name__in=['group1', 'group2']).exists()logging.getLogger().setLevel(logging.DEBUG)	4
"re.sub('[^a-zA-Z0-9-_*.]', '', my_string)webbrowser.open('file:///my_pdf.pdf')result = result.replace('\\', '')result.replace('\\', '')df.replace('-', 'NaN')datetime.datetime.now().date()datetime.datetime.now().date()[elem.tag for elem in a.iter()][elem.tag for elem in a.iter() if elem is not a]""""""2.7.0_bf4fda703454"""""".split('_')sorted(lst, key=lambda x: x['language'] != 'en')all(value == 0 for value in list(your_dict.values()))df.pivot_table('Y', rows='X', cols='X2')try:<nl><tab>doSomething()<nl>except:<nl><tab>passtry:<nl><tab>doSomething()<nl>except Exception:<nl><tab>pass"	4
"re.sub('\\([^)]*\\)', '', filename)""""""a b"""""".replace(' ', '').isalpha()[(x + y) for x, y in zip(first, second)]sorted(list(a_dict.items()), key=lambda item: item[1][1])re.compile('[^a-zA-Z0-9-]+')sorted(list(range(len(a))), key=lambda i: a[i])[-2:]zip(*sorted(enumerate(a), key=operator.itemgetter(1)))[0][-2:]sorted(list(range(len(a))), key=lambda i: a[i], reverse=True)[:2]list(x.keys()).index('c')print('{0:+d}'.format(score))[k for k, g in itertools.groupby([1, 2, 2, 3, 2, 2, 4])]""""""0,1,2"""""".split(',')[int(x) for x in '0,1,2'.split(',')]dict([('A', 1), ('B', 2), ('C', 3)])np.savetxt('test.txt', x)"	4
"""""""437c2123"""""".decode('hex')[k for k, v in User._fields.items() if v.required]df = df.ix[:, 0:2]x = map(int, x.split())x = [int(i) for i in x.split()]driver.find_element_by_css_selector(""input[onclick*='1 Bedroom Deluxe']"")re.sub('[^a-zA-Z0-9-_*.]', '', my_string)webbrowser.open('file:///my_pdf.pdf')result = result.replace('\\', '')result.replace('\\', '')df.replace('-', 'NaN')datetime.datetime.now().date()datetime.datetime.now().date()[elem.tag for elem in a.iter()][elem.tag for elem in a.iter() if elem is not a]"	4
"sorted(list(u.items()), key=lambda v: v[1])sorted(list(d.items()), key=lambda k_v: k_v[1], reverse=True)sorted(list(d.items()), key=lambda k_v: k_v[1])f = open(os.path.join(__location__, 'bundled-resource.jpg'))f = open('words.txt', 'rU'){k: (float(d2[k]) / d1[k]) for k in d2}{k: (d2[k] / d1[k]) for k in list(d1.keys()) & d2}dict((k, float(d2[k]) / d1[k]) for k in d2)df.to_csv(filename, date_format='%Y%m%d')my_dict.pop('key', None)b = np.where(np.isnan(a), 0, a)subprocess.call('start command -flags arguments', shell=True)subprocess.call('command -flags arguments &', shell=True)f = urllib.request.urlopen(url, urllib.parse.unquote(urllib.parse.urlencode(params)))""""""<tab>xyz<tab> """""".rstrip()"	4
"len([1 for i in j if (i > 5)])j = np.array(j)<nl>sum((j > i))[(x + tuple(y)) for x, y in zip(zip(a, b), c)]os.chmod(path, stat.S_IRUSR | stat.S_IRGRP | stat.S_IROTH)parser.add_argument('file', nargs='*')z = [(i == j) for i, j in zip(x, y)][(x[i] == y[i]) for i in range(len(x))][int(s) for s in re.findall('\\b\\d+\\b', ""he33llo 42 I'm a 32 string 30"")]df2 = pd.DataFrame(index=df1.index)struct.unpack('h', pS[0:2])print('\n'.join('  '.join(map(str, row)) for row in t))df.sort_values(by='Date')driver.find_element_by_name('<check_box_name>').is_selected()driver.find_element_by_id('<check_box_id>').is_selected()[(a if a else 2) for a in [0, 1, 0, 3]]"	4
rows = soup.findAll('tr')[4::5]plt.gca().invert_xaxis()plt.gca().invert_yaxis()pd.concat([GOOG, AAPL], keys=['GOOG', 'AAPL'], axis=1)return HttpResponse(json.dumps(response_data), content_type='application/json')myString.decode('string_escape')hashlib.md5(open('filename.exe', 'rb').read()).hexdigest()[k for k, v in d.items() if v == desired_value]{k for d in LoD for k in list(d.keys())}set([i for s in [list(d.keys()) for d in LoD] for i in s])[i for s in [list(d.keys()) for d in LoD] for i in s]keys, values = zip(*list(d.items()))int(Decimal(s))int(s.split('.')[0])numpy.in1d(b, a).all()	4
"re.findall('\\S+', str1)getattr(getattr(myobject, 'id', None), 'number', None){i: (i * 2) for i in range(10)}dict((i, i * 2) for i in range(10))plt.cla()total = sum(float(item) for item in s.split(','))bin(ord('P'))print(my_string.split(', ', 1)[1])print(data['places'][0]['post code'])word = re.sub('([aeiou]):(([aeiou][^aeiou]*){3})$', '\\1\\2', word)json.loads('{""foo"": 42, ""bar"": ""baz""}')['bar']data = json.loads(array)data = json.loads(array)re.findall('#(\\w+)', 'http://example.org/#comments')any(e in lestring for e in lelist)"	4
"b.update(d)df['b']ebar = plt.errorbar(x, y, yerr=err, ecolor='y')results += [each for each in os.listdir(folder) if each.endswith('.c')]print('\xc2\xa3'.decode('utf8') + '1')re.sub('(?<=[a-z])([A-Z])', '-\\1', s).lower()os.system('ulimit -s unlimited; some_executable')""""""{0:.3g}"""""".format(num)numpy.append(a, a[0])df.ix[:, (df.loc[0] == 38.15)].columnsdf2['revenue'] = df2.CET.map(df1.set_index('date')['revenue'])json_data = json.loads(json_string)math.cos(math.radians(1))sum(isinstance(x, int) for x in a)'used\u200b'.replace('\u200b', '*')"	4
your_string.strip('0')list(permutations(list(range(9)), 2))re.compile('^(.+)(?:\\n|\\r\\n?)((?:(?:\\n|\\r\\n?).+)+)', re.MULTILINE)re.compile('^(.+)\\n((?:\\n.+)+)', re.MULTILINE)call(['path/to/python', 'test2.py', 'neededArgumetGoHere'])a.sort(key=operator.itemgetter(2, 3))final_choices = ((another_choice,) + my_choices)final_choices = ((another_choice,) + my_choices)os.getcwd()os.path.realpath(__file__)os.path.dirname(path)os.path.realpath(path)dir_path = os.path.dirname(os.path.realpath(__file__))cwd = os.getcwd()full_path = os.path.realpath(__file__)	4
"re.split('\\.\\s', re.sub('\\.\\s*$', '', text))""""""foobar""""""[:4]s.rfind('&')s[:s.rfind('&')]driver.find_element_by_xpath(""//option[@value='"" + state + ""']"").click()with open('test.txt', 'a') as myfile:<nl><tab>myfile.write('appended text')with open('foo', 'a') as f:<nl><tab>f.write('cool beans...')with open('test1', 'ab') as f:<nl><tab>passopen('test', 'a+b').write('koko')print([i for i in re.split('([\\d.]+|\\W+)', 'x+13.5*10x-4e1') if i])re.findall('[\u4e00-\u9fff]+', ipath)s.split('s')subprocess.Popen(['rm', '-r', 'some.file'])dict((d['name'], d) for d in listofdict)datetime.datetime.now().strftime('%Y-%m-%d %H:%M')"	4
exec(compile(open('filename.py').read(), 'filename.py', 'exec'))session.query(Tag).distinct(Tag.name).group_by(Tag.name).count()df = df.dropna(axis=1, how='all')all(x.count(1) == 3 for x in L)[x[0] for x in l1 if any(x[0] == y[0] for y in l2)]tex.delete('1.0', END)datetime.datetime.fromtimestamp(myNumber).strftime('%Y-%m-%d %H:%M:%S')system('python myscript.py')your_list.sort(key=operator.attrgetter('anniversary_score'))your_list.sort(key=lambda x: x.anniversary_score)print(type(tf.Session().run(tf.constant([1, 2, 3]))))list(itertools.chain(*a))count.setdefault('a', 0)df.groupby(['cluster']).mean()min(myList, key=lambda x: abs(x - myNumber))	4
"response.headers['WWW-Authenticate'] = 'Basic realm=""test""'del request.session['mykey']datetime.datetime.strptime('24052010', '%d%m%Y').date()re.sub('[^\\x00-\\x7F]+', ' ', text)numpy.array([[1, 2], [3, 4]])myList = [i for i in range(10)][m[0] for m in re.compile('((.+?)\\2+)').findall('44442(2)2(2)44')][i[0] for i in re.findall('((\\d)(?:[()]*\\2*[()]*)*)', s)]fig.subplots_adjust(wspace=0, hspace=0)x[::-1]json.dumps({'apple': 'cat', 'banana': 'dog', 'pear': 'fish'})csvwriter.writerow(row){{(item.date | date): 'Y M d'}}re.split('(?<=[\\.\\?!]) ', text)re.compile('\xe2\x80\x93')"	4
[[X[i][j] for j in range(len(X[i]))] for i in range(len(X))]'\xd0\xbc\xd0\xb0\xd1\x80\xd0\xba\xd0\xb0'.encode('latin-1')df.groupby((df.a == 'B').shift(1).fillna(0).cumsum())urllib.request.urlretrieve('http://search.twitter.com/search.json?q=hi', 'hi.json')numpy.where((x == 0))[0]sys.stdout.flush()str(i)a.__str__()str(a)L.sort(key=operator.itemgetter(1))print(str(count) + '<tab>' + str(conv))df.fillna(method='ffill', inplace=True)text.config(state=DISABLED)sum(map(ord, string))list(itertools.product(*arrays))	4
hashlib.md5(open('filename.exe', 'rb').read()).hexdigest()[k for k, v in d.items() if v == desired_value]{k for d in LoD for k in list(d.keys())}set([i for s in [list(d.keys()) for d in LoD] for i in s])[i for s in [list(d.keys()) for d in LoD] for i in s]keys, values = zip(*list(d.items()))int(Decimal(s))int(s.split('.')[0])numpy.in1d(b, a).all()numpy.array([(x in a) for x in b])networkx.draw_networkx_labels(G, pos, labels)y = [row[:] for row in x]X = numpy.loadtxt('somefile.csv', delimiter=',')matching = [s for s in some_list if 'abc' in s]df.to_csv('mydf.tsv', sep='\t')	4
sum(x == chosen_value for x in list(d.values()))sum(1 for x in list(d.values()) if some_condition(x))struct.unpack('f', struct.pack('f', 0.00582811585976))timestamp = (dt - datetime(1970, 1, 1)).total_seconds()df.sort('m')a = sorted(a, key=lambda x: x.modified, reverse=True)print(bool(a))df = df.rename(index={last: 'a'})km.fit(x.reshape(-1, 1))sorted(words, key=lambda x: 'a' + x if x.startswith('s') else 'b' + x)webbrowser.open('http://somesite.com/adminpanel/index.php')dict((k, v) for k, v in parent_dict.items() if 2 < k < 4)dict((k, v) for k, v in parent_dict.items() if k > 2 and k < 4)[list(x) for x in zip(*sorted(zip(list1, list2), key=lambda pair: pair[0]))]sum(((i > 5) for i in j))	4
urllib.request.urlretrieve('http://search.twitter.com/search.json?q=hi', 'hi.json')numpy.where((x == 0))[0]sys.stdout.flush()str(i)a.__str__()str(a)L.sort(key=operator.itemgetter(1))print(str(count) + '<tab>' + str(conv))df.fillna(method='ffill', inplace=True)text.config(state=DISABLED)sum(map(ord, string))list(itertools.product(*arrays))'{:,}'.format(value)locale.setlocale(locale.LC_ALL, 'en_US')<nl>locale.format('%d', 1255000, grouping=True)df[df.Col1.isin(['men', 'rocks', 'mountains'])]	4
re.sub('[^\\x00-\\x7F]+', ' ', text)numpy.array([[1, 2], [3, 4]])myList = [i for i in range(10)][m[0] for m in re.compile('((.+?)\\2+)').findall('44442(2)2(2)44')][i[0] for i in re.findall('((\\d)(?:[()]*\\2*[()]*)*)', s)]fig.subplots_adjust(wspace=0, hspace=0)x[::-1]json.dumps({'apple': 'cat', 'banana': 'dog', 'pear': 'fish'})csvwriter.writerow(row){{(item.date | date): 'Y M d'}}re.split('(?<=[\\.\\?!]) ', text)re.compile('\xe2\x80\x93')variable = []intarray = array('i')[sublist[::-1] for sublist in to_reverse[::-1]]	4
"struct.unpack('h', pS[0:2])print('\n'.join('  '.join(map(str, row)) for row in t))df.sort_values(by='Date')driver.find_element_by_name('<check_box_name>').is_selected()driver.find_element_by_id('<check_box_id>').is_selected()[(a if a else 2) for a in [0, 1, 0, 3]]'M\\N{AMPERSAND}M\\N{APOSTROPHE}s'.encode().decode('unicode-escape')'M\\N{AMPERSAND}M\\N{APOSTROPHE}s'.decode('unicode-escape')chr(int('fd9b', 16)).encode('utf-8')print('0x%X' % value)cleaned = [x for x in your_list if x]slice(*[(int(i.strip()) if i else None) for i in string_slice.split(':')])soup.find_all(['a', 'div'])print(func.__name__)"""""""""""".join('{}{}'.format(key, val) for key, val in sorted(adict.items()))"	4
data = json.loads(array)re.findall('#(\\w+)', 'http://example.org/#comments')any(e in lestring for e in lelist)df.plot(x='col_name_1', y='col_name_2', style='o')parsed_html = BeautifulSoup(html)<nl>print(parsed_html.body.find('div', attrs={'class': 'container', }).text)page = urllib.request.urlopen('http://www.google.com/')<nl>soup = BeautifulSoup(page)plt.figure(figsize=(3, 4))s.translate(None, string.punctuation)base64.urlsafe_b64decode(uenc.encode('ascii'))len(dict_test) + sum(len(v) for v in dict_test.values())hex(d).split('x')[1]list(str(123))[int(x) for x in str(num)]br.select_form(nr=0)json.load(codecs.open('sample.json', 'r', 'utf-8-sig'))	4
Book.objects.filter(author__id=1).filter(author__id=2)re.compile('XYZ', re.IGNORECASE).split('fooxyzbar')[sum(map(int, s)) for s in example.split()][i for i in y if y[i] == 1]c.decode('unicode_escape')pd.melt(x, id_vars=['farm', 'fruit'], var_name='year', value_name='value')default_data['item3'] = 3default_data.update({'item3': 3, })default_data.update({'item4': 4, 'item5': 5, })l[:3] + l[-3:]df = df.reset_index(drop=True)[a[x].append(b[x]) for x in range(3)]os.path.realpath(path)set(L[0].f.items()).issubset(set(a3.f.items()))zip(*np.where(a == 1))	4
"os.path.join(*x.split(os.path.sep)[2:])line = line.replace(';', ':')subprocess.call('tar c my_dir | md5sum', shell=True)""""""437c2123"""""".decode('hex')[k for k, v in User._fields.items() if v.required]df = df.ix[:, 0:2]x = map(int, x.split())x = [int(i) for i in x.split()]driver.find_element_by_css_selector(""input[onclick*='1 Bedroom Deluxe']"")re.sub('[^a-zA-Z0-9-_*.]', '', my_string)webbrowser.open('file:///my_pdf.pdf')result = result.replace('\\', '')result.replace('\\', '')df.replace('-', 'NaN')datetime.datetime.now().date()"	4
"math.cos(math.radians(1))sum(isinstance(x, int) for x in a)'used\u200b'.replace('\u200b', '*')threading.Thread(target=SudsMove).start()sum(i * i for i in l)sum(map(lambda x: x * x, l))d = dict(((key, value) for (key, value) in iterable))d = {key: value for (key, value) in iterable}d = {k: v for (k, v) in iterable}df.round({'Alabama_exp': 2, 'Credit_exp': 3})p.setopt(pycurl.WRITEFUNCTION, lambda x: None)print(random.choice(words))max(d, key=lambda x: d[x]['count'])[(int(x) if x else 0) for x in data.split(',')]"""""","""""".join(x or '0' for x in s.split(','))"	4
[i.split('\t', 1)[0] for i in l]myList = [i.split('\t')[0] for i in myList]sum(your_list)ForkedPdb().set_trace()result = {k: d2.get(v) for k, v in list(d1.items())}datetime.datetime.now() + datetime.timedelta(days=1, hours=3)[int(s[i:i + 3], 2) for i in range(0, len(s), 3)]dict((v, k) for k, v in my_dict.items())print(sorted(L, key=lambda x: int(x.split('.')[2])))any(d['name'] == 'Test' for d in label)a[:] = [x for x in a if x != [1, 1]][x for x in a if x != [1, 1]]b = {a[i]: a[i + 1] for i in range(0, len(a), 2)}len(set(a)) == len(a)print(hashlib.md5(open(full_path, 'rb').read()).hexdigest())	4
"sorted(list(a_dict.items()), key=lambda item: item[1][1])re.compile('[^a-zA-Z0-9-]+')sorted(list(range(len(a))), key=lambda i: a[i])[-2:]zip(*sorted(enumerate(a), key=operator.itemgetter(1)))[0][-2:]sorted(list(range(len(a))), key=lambda i: a[i], reverse=True)[:2]list(x.keys()).index('c')print('{0:+d}'.format(score))[k for k, g in itertools.groupby([1, 2, 2, 3, 2, 2, 4])]""""""0,1,2"""""".split(',')[int(x) for x in '0,1,2'.split(',')]dict([('A', 1), ('B', 2), ('C', 3)])np.savetxt('test.txt', x)direct_output = subprocess.check_output('ls', shell=True)df[df.columns - ['T1_V6']]((25 < a) & (a < 100)).sum()"	4
pd.concat(map(pd.DataFrame, iter(d.values())), keys=list(d.keys())).stack().unstack(0)sum(1 for i, j in zip(a, b) if i != j)d = {(a.lower(), b): v for (a, b), v in list(d.items())}list_.sort(key=lambda x: [x[0], len(x[1]), x[1]])s.strip()s = s.lstrip()s = s.rstrip()s = s.strip(' \t\n\r')print(re.sub('[\\s+]', '', s))Task.objects.exclude(prerequisites__status__in=['A', 'P', 'F'])root.configure(background='black')numpy.array([(key, val) for key, val in result.items()], dtype)pd.concat([df_1, df_2.sort_values('y')])re.sub('(.*)</div>', '\\1</bad>', s)print(max(d, key=lambda x: (d[x]['salary'], d[x]['bonus'])))	4
"tuple(zip(*t))df.groupby(np.arange(len(df.columns)) // 3, axis=1).mean()"""""""""""".join(chr(i) for i in L)sum(x == chosen_value for x in list(d.values()))sum(1 for x in list(d.values()) if some_condition(x))struct.unpack('f', struct.pack('f', 0.00582811585976))timestamp = (dt - datetime(1970, 1, 1)).total_seconds()df.sort('m')a = sorted(a, key=lambda x: x.modified, reverse=True)print(bool(a))df = df.rename(index={last: 'a'})km.fit(x.reshape(-1, 1))sorted(words, key=lambda x: 'a' + x if x.startswith('s') else 'b' + x)webbrowser.open('http://somesite.com/adminpanel/index.php')dict((k, v) for k, v in parent_dict.items() if 2 < k < 4)"	4
sum([True, True, False, False, False, True])fig.set_size_inches(w, h, forward=True)'hello there %(5)s' % {'5': 'you'}map(int, example_string.split(','))[int(s) for s in example_string.split(',')]x = [i[0] for i in x]y = map(operator.itemgetter(0), x)y = [i[0] for i in x]results = [item['value'] for item in test_data]datetime.datetime.now().isoformat()datetime.datetime.utcnow().isoformat()df.apply(' '.join, axis=0)pd.DataFrame(df.values - df2.values, columns=df.columns)print(open('myfile.txt', 'U').read())print(line.decode('utf-16-le').split())	4
logging.info('test')fig.add_subplot(1, 1, 1)sorted(list(x.items()), key=operator.itemgetter(1))sorted(dict1, key=dict1.get)sorted(d, key=d.get, reverse=True)sorted(list(d.items()), key=(lambda x: x[1]))np.einsum('ijk,ikl->ijl', A, B)print('I have: {0.price}'.format(card))f.write('# Data for Class A\n')a = a[-1:] + a[:-1]datetimevariable.strftime('%Y-%m-%d')mixed.replace('\r\n', '\n').replace('\r', '\n')os.path.expanduser('~user')T = [L[i] for i in Idx]words = open('myfile').read().split()	4
GRAVITY = 9.8re.findall('(([0-9]+)([A-Z]))', '20M10000N80M')re.findall('([0-9]+|[A-Z])', '20M10000N80M')re.findall('([0-9]+)([A-Z])', '20M10000N80M')re.compile('\\w+').findall('Hello world, my name is...James the 2nd!')datetime.datetime.strptime('03:55', '%H:%M').time()requests.get('https://www.reporo.com/', verify=False)a[a != 0]new_dict = {k: v for k, v in zip(keys, values)}dict((k, v) for k, v in zip(keys, values))dict([(k, v) for k, v in zip(keys, values)])m = re.search('\\[(\\w+)\\]', s)s.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1)list3 = [(a + b) for a, b in zip(list1, list2)][ord(c) for c in s.decode('hex')]	4
final_choices = ((another_choice,) + my_choices)final_choices = ((another_choice,) + my_choices)os.getcwd()os.path.realpath(__file__)os.path.dirname(path)os.path.realpath(path)dir_path = os.path.dirname(os.path.realpath(__file__))cwd = os.getcwd()full_path = os.path.realpath(__file__)arr[arr[:, (2)].argsort()]numpy.sort(arr, axis=0)re.split('[ .]', 'a b.c')shutil.copy('file.txt', 'file2.txt')print(''.join(choice(ascii_uppercase) for i in range(12)))[''.join(seq) for seq in zip(lst, lst[1:])]	4
SomeModel.objects.filter(id=id).delete()dict([['two', 2], ['one', 1]])dict(zip(l[::2], l[1::2]))GRAVITY = 9.8re.findall('(([0-9]+)([A-Z]))', '20M10000N80M')re.findall('([0-9]+|[A-Z])', '20M10000N80M')re.findall('([0-9]+)([A-Z])', '20M10000N80M')re.compile('\\w+').findall('Hello world, my name is...James the 2nd!')datetime.datetime.strptime('03:55', '%H:%M').time()requests.get('https://www.reporo.com/', verify=False)a[a != 0]new_dict = {k: v for k, v in zip(keys, values)}dict((k, v) for k, v in zip(keys, values))dict([(k, v) for k, v in zip(keys, values)])m = re.search('\\[(\\w+)\\]', s)	4
"print('{0:+d}'.format(score))[k for k, g in itertools.groupby([1, 2, 2, 3, 2, 2, 4])]""""""0,1,2"""""".split(',')[int(x) for x in '0,1,2'.split(',')]dict([('A', 1), ('B', 2), ('C', 3)])np.savetxt('test.txt', x)direct_output = subprocess.check_output('ls', shell=True)df[df.columns - ['T1_V6']]((25 < a) & (a < 100)).sum()date.today().strftime('%A')re.search('\\bis\\b', your_string){{car.date_of_manufacture | datetime}}{{car.date_of_manufacture.strftime('%Y-%m-%d')}}[item for sublist in l for item in sublist]list(itertools.chain(*list2d))"	4
fh1.seek(2)print(zip(my_list[0::2], my_list[1::2]))my_new_list = zip(my_list[0::2], my_list[1::2])sys.setdefaultencoding('utf8')datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')print(re.findall('[\\u0600-\\u06FF]+', my_string))df.groupby(df.index.map(lambda t: t.minute))dict['Apple']['American']df2.dropna(subset=['three', 'four', 'five'], how='all')a.insert(0, k)a = a[:n] + k + a[n:]np.flatnonzero(x).mean()df['just_date'] = df['dates'].dt.date[x for x in a if x not in b][''.join(x) for x in a]	4
"lst[:] = []alist[:] = []s.reset_index(0).reset_index(drop=True)elems[0].getText().encode('utf-8')[(y - x) for x, y in zip(L, L[1:])]print(re.search('\\bLOG_ADDR\\s+(\\S+)', line).group(1))globals().update(importlib.import_module('some.package').__dict__)"""""""""""".join(['a', 'b', 'c', 'd'])url.split('&')od = collections.OrderedDict(sorted(d.items()))OrderedDict(sorted(list(d.items()), key=(lambda t: t[0])))response = requests.put(url, data=json.dumps(data), headers=headers)re.sub('[\\W_]+', '', s)[(x + y) for x in l2 for y in l1]dict([x.split('=') for x in s.split()])"	4
"f = open(os.path.join(__location__, 'bundled-resource.jpg'))f = open('words.txt', 'rU'){k: (float(d2[k]) / d1[k]) for k in d2}{k: (d2[k] / d1[k]) for k in list(d1.keys()) & d2}dict((k, float(d2[k]) / d1[k]) for k in d2)df.to_csv(filename, date_format='%Y%m%d')my_dict.pop('key', None)b = np.where(np.isnan(a), 0, a)subprocess.call('start command -flags arguments', shell=True)subprocess.call('command -flags arguments &', shell=True)f = urllib.request.urlopen(url, urllib.parse.unquote(urllib.parse.urlencode(params)))""""""<tab>xyz<tab> """""".rstrip()urllib.parse.quote(s.encode('utf-8'))urllib.parse.quote_plus('a b')np.array(map(int, '100110'))"	4
"os.system('TASKKILL /F /IM firefox.exe')return (x.group(0) for x in re.finditer(""[A-Za-z']+"", string))"""""", """""".join(['%.2f'] * len(x))print(re.match('(\\d+(\\.\\d+)?)', '3434.35353').group(1))df['name'].str.replace('\\(.*\\)', '')result = [x for x in list_a if x[0] in list_b]print([''.join(a) for a in combinations(['hel', 'lo', 'bye'], 2)])[x for x in li if 'ar' in x[2]]unsorted_list.sort(key=lambda x: x[3])logging.info('test')fig.add_subplot(1, 1, 1)sorted(list(x.items()), key=operator.itemgetter(1))sorted(dict1, key=dict1.get)sorted(d, key=d.get, reverse=True)sorted(list(d.items()), key=(lambda x: x[1]))"	4
print('Total cost is: ${:,.2f}'.format(TotalAmount))df.groupby(np.arange(len(df.columns)) // 2 + 1, axis=1).sum().add_prefix('s')randomList = [random.random() for _ in range(10)]print(soup.find('a', href=re.compile('.*follow\\?page.*')))sys.stdout.flush()country, capital = random.choice(list(d.items()))list('Word to Split')[w for w in open('file.txt') if not re.search('[aeiou]{2}', w)]pat = re.compile('^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$')exec(compile(open('filename.py').read(), 'filename.py', 'exec'))session.query(Tag).distinct(Tag.name).group_by(Tag.name).count()df = df.dropna(axis=1, how='all')all(x.count(1) == 3 for x in L)[x[0] for x in l1 if any(x[0] == y[0] for y in l2)]tex.delete('1.0', END)	4
"soup.find_all(['a', 'div'])print(func.__name__)"""""""""""".join('{}{}'.format(key, val) for key, val in sorted(adict.items()))"""""""""""".join('{}{}'.format(key, val) for key, val in list(adict.items()))new_list = old_list[:]new_list = list(old_list)new_list = copy.copy(old_list)new_list = copy.deepcopy(old_list)[i for i in old_list]plt.legend(frameon=False)""""""\\ud83d\\ude4f"""""".encode('utf-16', 'surrogatepass').decode('utf-16')globals()['myfunction']()urllib.request.urlopen('http://www.stackoverflow.com').getcode()conn = httplib.HTTPConnection('www.python.org')<nl>conn.request('HEAD', '/')<nl>r1 = conn.getresponse()<nl>print(r1.status, r1.reason)r = requests.head(url)<nl>return (r.status_code == 200)"	4
"print(os.path.dirname(os.path.realpath(__file__)))re.split('(?<=\\?|!|\\.)\\s{0,2}(?=[A-Z]|$)', text)plt.scatter(*zip(*li))tuple(zip(*t))df.groupby(np.arange(len(df.columns)) // 3, axis=1).mean()"""""""""""".join(chr(i) for i in L)sum(x == chosen_value for x in list(d.values()))sum(1 for x in list(d.values()) if some_condition(x))struct.unpack('f', struct.pack('f', 0.00582811585976))timestamp = (dt - datetime(1970, 1, 1)).total_seconds()df.sort('m')a = sorted(a, key=lambda x: x.modified, reverse=True)print(bool(a))df = df.rename(index={last: 'a'})km.fit(x.reshape(-1, 1))"	4
print(etree.tostring(some_tag.find('strong')))json.dumps({str(k): v for k, v in data.items()})soup = BeautifulSoup(response.read().decode('utf-8'))os.remove(filename)min([x for x in num_list if x > 2])df['prod_type'] = 'responsive'sorted(lst, key=lambda x: (x < 0, x))six_months = (date.today() + relativedelta(months=(+ 6)))(date(2010, 12, 31) + relativedelta(months=(+ 1)))(date(2010, 12, 31) + relativedelta(months=(+ 2)))print((datetime.date.today() + datetime.timedelta(((6 * 365) / 12))).isoformat())sorted(list(things.keys()), key=lambda x: things[x]['weight'], reverse=True)a[np.arange(len(a)) != 3][x for x in lst if fn(x) != 0]df.set_index('month')	4
data['sex'].replace([0, 1], ['Female', 'Male'], inplace=True)re.split('\\W+', 'Words, words, words.')re.match('(.*?[.?!](?:\\s+.*?[.?!]){0,1})', phrase).group(1)print([a for a, b in re.findall('((\\w)\\2*)', s)])print(' '.join(OrderedDict.fromkeys(s)))print(' '.join(set(s)))[x for x in file.namelist() if x.endswith('/')]input_string.count('Hello')print('.'.join([item[0] for item in data]))fh1.seek(2)print(zip(my_list[0::2], my_list[1::2]))my_new_list = zip(my_list[0::2], my_list[1::2])sys.setdefaultencoding('utf8')datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')print(re.findall('[\\u0600-\\u06FF]+', my_string))	4
"{i: a[i] for i in a if (i != 0)}lol.pop('hello')del r[key]np.linalg.solve(np.dot(a.T, a), np.dot(a.T, b))pd.concat([df.drop('b', axis=1), pd.DataFrame(df['b'].tolist())], axis=1)for i in range(0, 10, 2):<nl><tab>passfor i in mylist[::2]:<nl><tab>pass[{'content': x['content'].lower()} for x in messages]"""""" """""".join(my_list)re.sub('(http://\\S+|\\S*[^\\w\\s]\\S*)', '', a)str(n) == str(n)[::-1]ftp.storbinary('STOR myfile.txt', open('myfile.txt', 'rb'))re.sub('.*I', 'I', stri)int('1,000,000'.replace(',', ''))pd.merge(df1, df2, left_index=True, right_index=True, how='outer')"	4
"df.Country.value_counts().reset_index(name='Sum of Accidents')data.set_index('Date').diff()a.update([3, 4])a[1::2] = -1df.groupby('group')['value'].rank(ascending=False)datetime.strptime('Tue, 22 Nov 2011 06:00:00 GMT', '%a, %d %b %Y %H:%M:%S %Z')struct.pack('<I', 1633837924)list.append('foo')list.insert(0, 'foo')theset = set(k.lower() for k in thedict)""""""{s:{c}^{n}}"""""".format(s='dog', n=5, c='x')isinstance(s, str)isinstance(s, str)dict(pair for d in L for pair in list(d.items())){k: v for d in L for k, v in list(d.items())}"	4
"print('Total score for %s is %s  ' % (name, score))print(('Total score for', name, 'is', score))url('^$', TemplateView.as_view(template_name='your_template.html'))df[df['A'].isin([3, 6])]instance.__class__.__name__system('/path/to/my/venv/bin/python myscript.py')Employees.objects.values_list('eng_name', flat=True)re.findall('\\d|\\d,\\d\\)', '6,7)')input('Press Enter to continue...')""""""ABC"""""".encode('hex')db.Doc.update({'_id': b['_id']}, {'$set': {'geolocCountry': myGeolocCountry}})re.sub('l+', 'l', 'lollll')rows = soup.findAll('tr')[4::5]plt.gca().invert_xaxis()plt.gca().invert_yaxis()"	4
"print(list(itertools.combinations({1, 2, 3, 4}, 3)))df[['hour', 'weekday', 'weeknum']] = df.apply(lambdafunc, axis=1)soup.find_all('a', string='Elsie')my_datetime.strftime('%B %d, %Y')int(''.join(c for c in s if c.isdigit()))dic['Test'].update({'class': {'section': 5}})dict(map(int, x.split(':')) for x in s.split(','))driver.find_element_by_xpath(""//div[@id='a']//a[@class='click']"")np.where((vals == (0, 1)).all(axis=1))SomeModel.objects.filter(id=id).delete()dict([['two', 2], ['one', 1]])dict(zip(l[::2], l[1::2]))GRAVITY = 9.8re.findall('(([0-9]+)([A-Z]))', '20M10000N80M')re.findall('([0-9]+|[A-Z])', '20M10000N80M')"	4
"str.find('s', 11, 14)sorted(d, key=lambda x: datetime.datetime.strptime(x, '%m-%Y'))re.split('\\.\\s', text)re.split('\\.\\s', re.sub('\\.\\s*$', '', text))""""""foobar""""""[:4]s.rfind('&')s[:s.rfind('&')]driver.find_element_by_xpath(""//option[@value='"" + state + ""']"").click()with open('test.txt', 'a') as myfile:<nl><tab>myfile.write('appended text')with open('foo', 'a') as f:<nl><tab>f.write('cool beans...')with open('test1', 'ab') as f:<nl><tab>passopen('test', 'a+b').write('koko')print([i for i in re.split('([\\d.]+|\\W+)', 'x+13.5*10x-4e1') if i])re.findall('[\u4e00-\u9fff]+', ipath)s.split('s')"	4
"print(re.sub('[\x00-\x7f]', '', '\xa3100 is worth more than \u20ac100'))ast.literal_eval(""{'muffin' : 'lolz', 'foo' : 'kitty'}"")print(t.decode('unicode_escape'))print(str.encode('cp1252').decode('utf-8').encode('cp1252').decode('utf-8'))zip(list_a, list_b)list(zip(a, b))df.set_index('id').to_dict()df.set_index('id')['value'].to_dict()sorted(list(mydict.items()), key=lambda a: map(int, a[0].split('.')))re.sub('\\([^)]*\\)', '', filename)""""""a b"""""".replace(' ', '').isalpha()[(x + y) for x, y in zip(first, second)]sorted(list(a_dict.items()), key=lambda item: item[1][1])re.compile('[^a-zA-Z0-9-]+')sorted(list(range(len(a))), key=lambda i: a[i])[-2:]"	4
count.setdefault('a', 0)df.groupby(['cluster']).mean()min(myList, key=lambda x: abs(x - myNumber))any(x in string for x in search)print(pattern.search(url).group(1))(s.factorize()[0] + 1).astype('float')C = [(a - b) for a, b in zip(A, B)]datetime.datetime.strptime('2011, 4, 0', '%Y, %U, %w')map(int, ['1', '-1', '1'])datetime.datetime.strptime('16Sep2012', '%d%b%Y')Book.objects.filter(pk=pk).update(**d)Book.objects.create(**d)print('{0:.2f}'.format(your_number))random.randint(100000000000, 999999999999)int(''.join(str(random.randint(0, 9)) for _ in range(12)))	4
"[d['value'] for d in l if 'value' in d]np.array([[1, 2, 3], [4, 5, 6]]).tolist()ast.literal_eval('(1,2,3,4)')dataList.sort(key=lambda x: x[1])list(map(list, set(map(lambda i: tuple(i), testdata))))[list(i) for i in set(tuple(i) for i in testdata)]return user.groups.filter(name='Member').exists()return user.groups.filter(name__in=['group1', 'group2']).exists()logging.getLogger().setLevel(logging.DEBUG)"""""""""""".join(str(i) for i in (34.2424, -64.2344, 76.3534, 45.2344))"""""""""""".join([s[x:x + 2][::-1] for x in range(0, len(s), 2)])plt.savefig('graph.png', dpi=1000)my_list = [[x for x in sublist if x not in to_del] for sublist in my_list][item for item in a if 1 in item][item for item in a if item[0] == 1]"	4
[int(x) for x in '0,1,2'.split(',')]dict([('A', 1), ('B', 2), ('C', 3)])np.savetxt('test.txt', x)direct_output = subprocess.check_output('ls', shell=True)df[df.columns - ['T1_V6']]((25 < a) & (a < 100)).sum()date.today().strftime('%A')re.search('\\bis\\b', your_string){{car.date_of_manufacture | datetime}}{{car.date_of_manufacture.strftime('%Y-%m-%d')}}[item for sublist in l for item in sublist]list(itertools.chain(*list2d))list(itertools.chain.from_iterable(list2d))ord('a')re.sub('(?m)^[^\\S\\n]+', '', '  a\n b\n c\nd  e')	4
""""""""""""".join(str(i) for i in (34.2424, -64.2344, 76.3534, 45.2344))"""""""""""".join([s[x:x + 2][::-1] for x in range(0, len(s), 2)])plt.savefig('graph.png', dpi=1000)my_list = [[x for x in sublist if x not in to_del] for sublist in my_list][item for item in a if 1 in item][item for item in a if item[0] == 1]{p.id: {'id': p.id, 'position': ind} for ind, p in enumerate(p_list)}[dict(y) for y in set(tuple(x.items()) for x in d)]exec(compile(open('file.py').read(), 'file.py', 'exec'))rows = session.query(Congress).count()subprocess.call(['test.sh', str(domid)])dfs = pd.read_excel(file_name, sheetname=None)struct.unpack('d', binascii.unhexlify('4081637ef7d0424a'))a[tuple(b)]map(list, permutations([2, 3, 4]))"	4
time.sleep(0.1)[x for x in my_list if not any(c.isdigit() for c in x)]df['state'].apply(lambda x: x[len(x) / 2 - 1:len(x) / 2 + 1])plt.grid(True)sorted(lst, key=lambda x: (-1 * c[x], lst.index(x)))[max(len(str(x)) for x in line) for line in zip(*foo)]df.Country.value_counts().reset_index(name='Sum of Accidents')data.set_index('Date').diff()a.update([3, 4])a[1::2] = -1df.groupby('group')['value'].rank(ascending=False)datetime.strptime('Tue, 22 Nov 2011 06:00:00 GMT', '%a, %d %b %Y %H:%M:%S %Z')struct.pack('<I', 1633837924)list.append('foo')list.insert(0, 'foo')	4
"os.chmod(path, stat.S_IRUSR | stat.S_IRGRP | stat.S_IROTH)parser.add_argument('file', nargs='*')z = [(i == j) for i, j in zip(x, y)][(x[i] == y[i]) for i in range(len(x))][int(s) for s in re.findall('\\b\\d+\\b', ""he33llo 42 I'm a 32 string 30"")]df2 = pd.DataFrame(index=df1.index)struct.unpack('h', pS[0:2])print('\n'.join('  '.join(map(str, row)) for row in t))df.sort_values(by='Date')driver.find_element_by_name('<check_box_name>').is_selected()driver.find_element_by_id('<check_box_id>').is_selected()[(a if a else 2) for a in [0, 1, 0, 3]]'M\\N{AMPERSAND}M\\N{APOSTROPHE}s'.encode().decode('unicode-escape')'M\\N{AMPERSAND}M\\N{APOSTROPHE}s'.decode('unicode-escape')chr(int('fd9b', 16)).encode('utf-8')"	4
"C = [(a - b) for a, b in zip(A, B)]datetime.datetime.strptime('2011, 4, 0', '%Y, %U, %w')map(int, ['1', '-1', '1'])datetime.datetime.strptime('16Sep2012', '%d%b%Y')Book.objects.filter(pk=pk).update(**d)Book.objects.create(**d)print('{0:.2f}'.format(your_number))random.randint(100000000000, 999999999999)int(''.join(str(random.randint(0, 9)) for _ in range(12)))"""""""""""".join(str(random.randint(0, 9)) for _ in range(12))'%0.12d' % random.randint(0, 999999999999)numpy.delete(a, index)sorted(trial_list, key=lambda x: trial_dict[x])sys.stdin.read(1)print(re.findall(pattern, x))"	4
"df.groupby(['Country', 'Item_Code'])[['Y1961', 'Y1962', 'Y1963']].sum()done = [(el, x) for el in [a, b, c, d]]x = x[numpy.logical_not(numpy.isnan(x))]os.path.join(*x.split(os.path.sep)[2:])line = line.replace(';', ':')subprocess.call('tar c my_dir | md5sum', shell=True)""""""437c2123"""""".decode('hex')[k for k, v in User._fields.items() if v.required]df = df.ix[:, 0:2]x = map(int, x.split())x = [int(i) for i in x.split()]driver.find_element_by_css_selector(""input[onclick*='1 Bedroom Deluxe']"")re.sub('[^a-zA-Z0-9-_*.]', '', my_string)webbrowser.open('file:///my_pdf.pdf')result = result.replace('\\', '')"	4
with open('foo', 'a') as f:<nl><tab>f.write('cool beans...')with open('test1', 'ab') as f:<nl><tab>passopen('test', 'a+b').write('koko')print([i for i in re.split('([\\d.]+|\\W+)', 'x+13.5*10x-4e1') if i])re.findall('[\u4e00-\u9fff]+', ipath)s.split('s')subprocess.Popen(['rm', '-r', 'some.file'])dict((d['name'], d) for d in listofdict)datetime.datetime.now().strftime('%Y-%m-%d %H:%M')time.strftime('%Y-%m-%d %H:%M')re.findall('[bcdfghjklmnpqrstvwxyz]+', 'CONCERTATION', re.IGNORECASE)[i for i, e in enumerate(a) if e != 0]map(int, re.findall('\\d+', string1))os.path.dirname(sys.executable)ax.xaxis.set_label_position('top')	4
[[sum([x[1] for x in i])] for i in data][sum([x[1] for x in i]) for i in data]Article.objects.annotate(like_count=Count('likes')).order_by('-like_count')today = datetime.datetime.utcnow().date()[(a * b) for a, b in zip(lista, listb)]re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', s)re.match('[:;][)(](?![)(])', str)json_string = json.dumps([ob.__dict__ for ob in list_name])listofzeros = [0] * nstringnamehere.decode('utf-8', 'ignore')re.findall('((?:A|B|C)D)', 'BDE')dic.setdefault(key, []).append(value)a[np.argmin(a[:, (1)])]a.update(b)[{k: v for k, v in d.items() if k != 'mykey1'} for d in mylist]	4
pickle.load(open('afile', 'rb'))driver.find_element_by_xpath('xpath').click()ex.groupby(level='A').agg(lambda x: x.index.get_level_values(1).nunique())pd.concat(map(pd.DataFrame, iter(d.values())), keys=list(d.keys())).stack().unstack(0)sum(1 for i, j in zip(a, b) if i != j)d = {(a.lower(), b): v for (a, b), v in list(d.items())}list_.sort(key=lambda x: [x[0], len(x[1]), x[1]])s.strip()s = s.lstrip()s = s.rstrip()s = s.strip(' \t\n\r')print(re.sub('[\\s+]', '', s))Task.objects.exclude(prerequisites__status__in=['A', 'P', 'F'])root.configure(background='black')numpy.array([(key, val) for key, val in result.items()], dtype)	4
root.attributes('-topmost', True)root.lift()hex(int(''.join([str(int(b)) for b in walls]), 2))hex(sum(b << i for i, b in enumerate(reversed(walls))))print(('Total score for', name, 'is', score))print('Total score for {} is {}'.format(name, score))print('Total score for %s is %s  ' % (name, score))print(('Total score for', name, 'is', score))url('^$', TemplateView.as_view(template_name='your_template.html'))df[df['A'].isin([3, 6])]instance.__class__.__name__system('/path/to/my/venv/bin/python myscript.py')Employees.objects.values_list('eng_name', flat=True)re.findall('\\d|\\d,\\d\\)', '6,7)')input('Press Enter to continue...')	4
plt.figure(figsize=(3, 4))s.translate(None, string.punctuation)base64.urlsafe_b64decode(uenc.encode('ascii'))len(dict_test) + sum(len(v) for v in dict_test.values())hex(d).split('x')[1]list(str(123))[int(x) for x in str(num)]br.select_form(nr=0)json.load(codecs.open('sample.json', 'r', 'utf-8-sig'))json.loads(open('sample.json').read().decode('utf-8-sig'))server = smtplib.SMTP('smtp.gmail.com', 587)int('{:08b}'.format(n)[::-1], 2)df.set_index(['d'], append=True)for (key, value) in d.items():<nl><tab>passfor (key, value) in list(d.items()):<nl><tab>pass	4
"print(str.encode('cp1252').decode('utf-8').encode('cp1252').decode('utf-8'))zip(list_a, list_b)list(zip(a, b))df.set_index('id').to_dict()df.set_index('id')['value'].to_dict()sorted(list(mydict.items()), key=lambda a: map(int, a[0].split('.')))re.sub('\\([^)]*\\)', '', filename)""""""a b"""""".replace(' ', '').isalpha()[(x + y) for x, y in zip(first, second)]sorted(list(a_dict.items()), key=lambda item: item[1][1])re.compile('[^a-zA-Z0-9-]+')sorted(list(range(len(a))), key=lambda i: a[i])[-2:]zip(*sorted(enumerate(a), key=operator.itemgetter(1)))[0][-2:]sorted(list(range(len(a))), key=lambda i: a[i], reverse=True)[:2]list(x.keys()).index('c')"	4
your_list.sort(key=lambda x: x.anniversary_score)print(type(tf.Session().run(tf.constant([1, 2, 3]))))list(itertools.chain(*a))count.setdefault('a', 0)df.groupby(['cluster']).mean()min(myList, key=lambda x: abs(x - myNumber))any(x in string for x in search)print(pattern.search(url).group(1))(s.factorize()[0] + 1).astype('float')C = [(a - b) for a, b in zip(A, B)]datetime.datetime.strptime('2011, 4, 0', '%Y, %U, %w')map(int, ['1', '-1', '1'])datetime.datetime.strptime('16Sep2012', '%d%b%Y')Book.objects.filter(pk=pk).update(**d)Book.objects.create(**d)	4
os.path.realpath(path)set(L[0].f.items()).issubset(set(a3.f.items()))zip(*np.where(a == 1))np.where(a == 1)df.columns = df.columns.get_level_values(0)x = scipy.matrix([1, 2, 3]).transpose()text = re.sub('(\\bget\\b)', '\\1@', text)np.array([np.arange(3), np.arange(2, -1, -1), np.ones((3,))]).min(axis=0)df['new_col'] = list(range(1, len(df) + 1))os.environ['DEBUSSY'] = '1'print(os.environ['DEBUSSY'])os.environ['DEBUSSY'] = '1'b.update(d)df['b']ebar = plt.errorbar(x, y, yerr=err, ecolor='y')	4
"df[df['A'].isin([3, 6])]instance.__class__.__name__system('/path/to/my/venv/bin/python myscript.py')Employees.objects.values_list('eng_name', flat=True)re.findall('\\d|\\d,\\d\\)', '6,7)')input('Press Enter to continue...')""""""ABC"""""".encode('hex')db.Doc.update({'_id': b['_id']}, {'$set': {'geolocCountry': myGeolocCountry}})re.sub('l+', 'l', 'lollll')rows = soup.findAll('tr')[4::5]plt.gca().invert_xaxis()plt.gca().invert_yaxis()pd.concat([GOOG, AAPL], keys=['GOOG', 'AAPL'], axis=1)return HttpResponse(json.dumps(response_data), content_type='application/json')myString.decode('string_escape')"	4
{{car.date_of_manufacture.strftime('%Y-%m-%d')}}[item for sublist in l for item in sublist]list(itertools.chain(*list2d))list(itertools.chain.from_iterable(list2d))ord('a')re.sub('(?m)^[^\\S\\n]+', '', '  a\n b\n c\nd  e')re.sub('(?m)^\\s+', '', 'a\n b\n c')a, b, c = [1, 2, 3][list(v) for k, v in itertools.groupby(mylist, key=lambda x: x[:5])]line = re.sub('\\(+as .*?\\) ', '', line)print(line.rstrip('\n'))df.index.values.tolist()if (not a):<nl><tab>passif (not seq):<nl><tab>passif (len(li) == 0):<nl><tab>pass	4
"[m[0] for m in re.compile('((.+?)\\2+)').findall('44442(2)2(2)44')][i[0] for i in re.findall('((\\d)(?:[()]*\\2*[()]*)*)', s)]fig.subplots_adjust(wspace=0, hspace=0)x[::-1]json.dumps({'apple': 'cat', 'banana': 'dog', 'pear': 'fish'})csvwriter.writerow(row){{(item.date | date): 'Y M d'}}re.split('(?<=[\\.\\?!]) ', text)re.compile('\xe2\x80\x93')variable = []intarray = array('i')[sublist[::-1] for sublist in to_reverse[::-1]]re.sub('[^0-9a-zA-Z]+', '*', 'h^&ell`.,|o w]{+orld')"""""""""""".join(['I ', '<', '3s U ', '&', ' you luvz me'])logging.disable(logging.CRITICAL)"	4
shutil.copy('file.txt', 'file2.txt')print(''.join(choice(ascii_uppercase) for i in range(12)))[''.join(seq) for seq in zip(lst, lst[1:])]data.rename(columns={'gdp': 'log(gdp)'}, inplace=True)print(soup.get_text())sorted(li, key=operator.itemgetter(1), reverse=True)data['sex'].replace([0, 1], ['Female', 'Male'], inplace=True)re.split('\\W+', 'Words, words, words.')re.match('(.*?[.?!](?:\\s+.*?[.?!]){0,1})', phrase).group(1)print([a for a, b in re.findall('((\\w)\\2*)', s)])print(' '.join(OrderedDict.fromkeys(s)))print(' '.join(set(s)))[x for x in file.namelist() if x.endswith('/')]input_string.count('Hello')print('.'.join([item[0] for item in data]))	4
X = numpy.loadtxt('somefile.csv', delimiter=',')matching = [s for s in some_list if 'abc' in s]df.to_csv('mydf.tsv', sep='\t')random.sample(list(range(100)), 10)s.rsplit(',', 1)all(isinstance(x, int) for x in lst)all(isinstance(x, int) for x in lst)line.strip()driver.execute_script('window.scrollTo(0, Y)')driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')datetime.datetime.combine(dateobject, datetime.time())print(any(x in a for x in b))scipy.misc.imsave('outfile.jpg', image_array)item = re.sub(' ?\\([^)]+\\)', '', item)item = re.sub(' ?\\(\\w+\\)', '', item)	4
"for (letter, number) in list(d.items()):<nl><tab>passsession.query(Task).filter(Task.time_spent > timedelta(hours=3)).all()os.system('msbuild project.sln /p:Configuration=Debug')max(list(MyCount.keys()), key=int)os.system('source .bashrc; shopt -s expand_aliases; nuke -x scriptPath')my_function.__name__my_function.__name__np.all(a == a[(0), :], axis=0)sorted(a, key=lambda x: (sum(x[1:3]), x[0]))sorted(a, key=lambda x: (sum(x[1:3]), x[0]), reverse=True)sorted(lst, key=lambda x: (sum(x[1:]), x[0]))sorted(lst, key=lambda x: (sum(x[1:]), x[0]), reverse=True)response.headers['WWW-Authenticate'] = 'Basic realm=""test""'del request.session['mykey']datetime.datetime.strptime('24052010', '%d%m%Y').date()"	4
all(isinstance(x, int) for x in lst)line.strip()driver.execute_script('window.scrollTo(0, Y)')driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')datetime.datetime.combine(dateobject, datetime.time())print(any(x in a for x in b))scipy.misc.imsave('outfile.jpg', image_array)item = re.sub(' ?\\([^)]+\\)', '', item)item = re.sub(' ?\\(\\w+\\)', '', item)item = re.sub(' \\(\\w+\\)', '', item)len(set(list1).intersection(list2)) > 0i = int(s, 16)int('0xff', 16)int('FFFF', 16)ast.literal_eval('0xdeadbeef')	4
scipy.misc.imsave('outfile.jpg', image_array)item = re.sub(' ?\\([^)]+\\)', '', item)item = re.sub(' ?\\(\\w+\\)', '', item)item = re.sub(' \\(\\w+\\)', '', item)len(set(list1).intersection(list2)) > 0i = int(s, 16)int('0xff', 16)int('FFFF', 16)ast.literal_eval('0xdeadbeef')int('deadbeef', 16)os.system('screencapture screen.png')driver.set_window_size(1400, 1000)unicodedata.normalize('NFKD', 'm\xfasica').encode('ascii', 'ignore')pandas.concat([df1, df2]).drop_duplicates().reset_index(drop=True)a = numpy.fromfile('filename', dtype=numpy.float32)	4
"a[1::2] = -1df.groupby('group')['value'].rank(ascending=False)datetime.strptime('Tue, 22 Nov 2011 06:00:00 GMT', '%a, %d %b %Y %H:%M:%S %Z')struct.pack('<I', 1633837924)list.append('foo')list.insert(0, 'foo')theset = set(k.lower() for k in thedict)""""""{s:{c}^{n}}"""""".format(s='dog', n=5, c='x')isinstance(s, str)isinstance(s, str)dict(pair for d in L for pair in list(d.items())){k: v for d in L for k, v in list(d.items())}df.sort_values(['Peak', 'Weeks'], ascending=[True, False], inplace=True)df.sort(['Peak', 'Weeks'], ascending=[True, False], inplace=True)eval(""print('Hello')"")"	4
map(list, zip(*[(1, 2), (3, 4), (5, 6)]))zip(*[(1, 2), (3, 4), (5, 6)])[(x, y) for x, y in zip(myList, myList[1:]) if y == 9]driver.get('http://www.google.com.br')b = a.decode('utf8')[::-1].encode('utf8')dparser.parse('monkey 2010-07-32 love banana', fuzzy=True)dparser.parse('monkey 20/01/1980 love banana', fuzzy=True)dparser.parse('monkey 10/01/1980 love banana', fuzzy=True)dict(map(lambda s: s.split(':'), ['A:1', 'B:2', 'C:3', 'D:4']))re.search('[a-zA-Z]', the_string)DataFrame({'count': df1.groupby(['Name', 'City']).size()}).reset_index()re.sub('[^0-9]', '', 'sdkjh987978asd098as0980a98sd')[y for y in a if y not in b]df.groupby('ID').head(4)zip(*l)	4
re.sub('[\\W_]+', '', s)[(x + y) for x in l2 for y in l1]dict([x.split('=') for x in s.split()])my_list.pop(2)s = s.replace('M', '')newstr = oldstr.replace('M', '')sum(x * y for x, y in zip(a, b))list(x * y for x, y in list(zip(a, b)))sum(i * j for i, j in zip(a, b))sum(x * y for x, y in list(zip(a, b)))f.write(open('xxx.mp4', 'rb').read())new_list = [(x + 1) for x in my_list][x for x in j if x >= 5]plt.plot(list(range(10)), '--bo')plt.plot(list(range(10)), linestyle='--', marker='o', color='b')	4
print(bool(a))df = df.rename(index={last: 'a'})km.fit(x.reshape(-1, 1))sorted(words, key=lambda x: 'a' + x if x.startswith('s') else 'b' + x)webbrowser.open('http://somesite.com/adminpanel/index.php')dict((k, v) for k, v in parent_dict.items() if 2 < k < 4)dict((k, v) for k, v in parent_dict.items() if k > 2 and k < 4)[list(x) for x in zip(*sorted(zip(list1, list2), key=lambda pair: pair[0]))]sum(((i > 5) for i in j))len([1 for i in j if (i > 5)])j = np.array(j)<nl>sum((j > i))[(x + tuple(y)) for x, y in zip(zip(a, b), c)]os.chmod(path, stat.S_IRUSR | stat.S_IRGRP | stat.S_IROTH)parser.add_argument('file', nargs='*')z = [(i == j) for i, j in zip(x, y)]	4
pd.merge(df1, df2, on=['A', 'B', 'C', 'D'], how='inner')dict((v, k) for k, v in map.items())s.decode('unicode_escape')[int(i) for i in str_list]map(int, ['1', '2', '3'])list(map(int, ['1', '2', '3']))soup.find_all('a', href=re.compile('http://www\\.iwashere\\.com/'))soup.find_all('a', href=re.compile('^(?!(?:[a-zA-Z][a-zA-Z0-9+.-]*:|//))'))subprocess.call(['java', '-jar', 'Blender.jar'])cursor.execute('INSERT INTO table (`column1`) VALUES (%s)', (value,))if url.endswith('.com'):<nl><tab>url = url[:(-4)]url = re.sub('\\.com$', '', url)print(url.replace('.com', ''))if (not text.endswith(suffix)):<nl><tab>return text<nl>return text[:(len(text) - len(suffix))]print(', ,'.join([str(i[0]) for i in mytuple]))	4
"datetime.datetime.now().date()[elem.tag for elem in a.iter()][elem.tag for elem in a.iter() if elem is not a]""""""2.7.0_bf4fda703454"""""".split('_')sorted(lst, key=lambda x: x['language'] != 'en')all(value == 0 for value in list(your_dict.values()))df.pivot_table('Y', rows='X', cols='X2')try:<nl><tab>doSomething()<nl>except:<nl><tab>passtry:<nl><tab>doSomething()<nl>except Exception:<nl><tab>passM.sum(axis=0).sum(axis=0)time.mktime(dt.timetuple()) + dt.microsecond / 1000000.0df[(x <= df['columnX']) & (df['columnX'] <= y)]sorted(L, key=itemgetter(2))l.sort(key=(lambda x: x[2]))sorted(l, key=(lambda x: x[2]))"	4
"text = re.sub('(\\bget\\b)', '\\1@', text)np.array([np.arange(3), np.arange(2, -1, -1), np.ones((3,))]).min(axis=0)df['new_col'] = list(range(1, len(df) + 1))os.environ['DEBUSSY'] = '1'print(os.environ['DEBUSSY'])os.environ['DEBUSSY'] = '1'b.update(d)df['b']ebar = plt.errorbar(x, y, yerr=err, ecolor='y')results += [each for each in os.listdir(folder) if each.endswith('.c')]print('\xc2\xa3'.decode('utf8') + '1')re.sub('(?<=[a-z])([A-Z])', '-\\1', s).lower()os.system('ulimit -s unlimited; some_executable')""""""{0:.3g}"""""".format(num)numpy.append(a, a[0])"	4
rows = session.query(Congress).count()subprocess.call(['test.sh', str(domid)])dfs = pd.read_excel(file_name, sheetname=None)struct.unpack('d', binascii.unhexlify('4081637ef7d0424a'))a[tuple(b)]map(list, permutations([2, 3, 4]))sorted(unsorted_list, key=presorted_list.index)datetime.datetime.now() - datetime.timedelta(days=1)d = pd.DataFrame(0, index=np.arange(len(data)), columns=feature_list)x.find('World')x.find('Aloha')'sdfasdf'.index('cc')'sdfasdf'.index('df')str.find('a')str.find('g')	4
somestring.replace('\\r', '')simplejson.dumps(dict([('%d,%d' % k, v) for k, v in list(d.items())]))datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')parser.parse('Aug 28 1999 12:00AM')os.path.split(os.path.abspath(existGDBPath))os.path.dirname(os.path.abspath(existGDBPath))requests.post('http://httpbin.org/post', json={'test': 'cheers'})a = [x for x in a if x['link'] not in b]{{request.args.get('a')}}list(range(11, 17))data_df['grade'] = data_df['grade'].astype(float).astype(int)max(alkaline_earth_values, key=lambda x: x[1])your_string.strip('0')list(permutations(list(range(9)), 2))re.compile('^(.+)(?:\\n|\\r\\n?)((?:(?:\\n|\\r\\n?).+)+)', re.MULTILINE)	4
"[(x[i] == y[i]) for i in range(len(x))][int(s) for s in re.findall('\\b\\d+\\b', ""he33llo 42 I'm a 32 string 30"")]df2 = pd.DataFrame(index=df1.index)struct.unpack('h', pS[0:2])print('\n'.join('  '.join(map(str, row)) for row in t))df.sort_values(by='Date')driver.find_element_by_name('<check_box_name>').is_selected()driver.find_element_by_id('<check_box_id>').is_selected()[(a if a else 2) for a in [0, 1, 0, 3]]'M\\N{AMPERSAND}M\\N{APOSTROPHE}s'.encode().decode('unicode-escape')'M\\N{AMPERSAND}M\\N{APOSTROPHE}s'.decode('unicode-escape')chr(int('fd9b', 16)).encode('utf-8')print('0x%X' % value)cleaned = [x for x in your_list if x]slice(*[(int(i.strip()) if i else None) for i in string_slice.split(':')])"	4
sorted(dict1, key=dict1.get)sorted(d, key=d.get, reverse=True)sorted(list(d.items()), key=(lambda x: x[1]))np.einsum('ijk,ikl->ijl', A, B)print('I have: {0.price}'.format(card))f.write('# Data for Class A\n')a = a[-1:] + a[:-1]datetimevariable.strftime('%Y-%m-%d')mixed.replace('\r\n', '\n').replace('\r', '\n')os.path.expanduser('~user')T = [L[i] for i in Idx]words = open('myfile').read().split()[[sum([x[1] for x in i])] for i in data][sum([x[1] for x in i]) for i in data]Article.objects.annotate(like_count=Count('likes')).order_by('-like_count')	4
"dict((k, v) for k, v in parent_dict.items() if k > 2 and k < 4)[list(x) for x in zip(*sorted(zip(list1, list2), key=lambda pair: pair[0]))]sum(((i > 5) for i in j))len([1 for i in j if (i > 5)])j = np.array(j)<nl>sum((j > i))[(x + tuple(y)) for x, y in zip(zip(a, b), c)]os.chmod(path, stat.S_IRUSR | stat.S_IRGRP | stat.S_IROTH)parser.add_argument('file', nargs='*')z = [(i == j) for i, j in zip(x, y)][(x[i] == y[i]) for i in range(len(x))][int(s) for s in re.findall('\\b\\d+\\b', ""he33llo 42 I'm a 32 string 30"")]df2 = pd.DataFrame(index=df1.index)struct.unpack('h', pS[0:2])print('\n'.join('  '.join(map(str, row)) for row in t))df.sort_values(by='Date')"	4
"df.groupby(df.index.map(lambda t: t.minute))dict['Apple']['American']df2.dropna(subset=['three', 'four', 'five'], how='all')a.insert(0, k)a = a[:n] + k + a[n:]np.flatnonzero(x).mean()df['just_date'] = df['dates'].dt.date[x for x in a if x not in b][''.join(x) for x in a]list(map(''.join, a))re.split('\n\\s*\n', s)from functools import reduce<nl>reduce(lambda x, y: 10 * x + y, [1, 2, 3, 4, 5])""""""{0:,.2f}"""""".format(24322.34)my_function(**data)sum((1 for line in open('myfile.txt')))"	4
"df.sort_values(['Peak', 'Weeks'], ascending=[True, False], inplace=True)df.sort(['Peak', 'Weeks'], ascending=[True, False], inplace=True)eval(""print('Hello')"")[{'A': 1, 'C': 4, 'B': 2, 'D': 4}, {'A': 1, 'C': 4, 'B': 1, 'D': 5}][{'A': 1, 'C': 4, 'B': 2, 'D': 4}, {'A': 1, 'C': 4, 'B': 1, 'D': 5}]list(itertools.product(*a))df.groupby(['Country', 'Item_Code'])[['Y1961', 'Y1962', 'Y1963']].sum()done = [(el, x) for el in [a, b, c, d]]x = x[numpy.logical_not(numpy.isnan(x))]os.path.join(*x.split(os.path.sep)[2:])line = line.replace(';', ':')subprocess.call('tar c my_dir | md5sum', shell=True)""""""437c2123"""""".decode('hex')[k for k, v in User._fields.items() if v.required]df = df.ix[:, 0:2]"	4
default_data['item3'] = 3default_data.update({'item3': 3, })default_data.update({'item4': 4, 'item5': 5, })l[:3] + l[-3:]df = df.reset_index(drop=True)[a[x].append(b[x]) for x in range(3)]os.path.realpath(path)set(L[0].f.items()).issubset(set(a3.f.items()))zip(*np.where(a == 1))np.where(a == 1)df.columns = df.columns.get_level_values(0)x = scipy.matrix([1, 2, 3]).transpose()text = re.sub('(\\bget\\b)', '\\1@', text)np.array([np.arange(3), np.arange(2, -1, -1), np.ones((3,))]).min(axis=0)df['new_col'] = list(range(1, len(df) + 1))	4
"{{(item.date | date): 'Y M d'}}re.split('(?<=[\\.\\?!]) ', text)re.compile('\xe2\x80\x93')variable = []intarray = array('i')[sublist[::-1] for sublist in to_reverse[::-1]]re.sub('[^0-9a-zA-Z]+', '*', 'h^&ell`.,|o w]{+orld')"""""""""""".join(['I ', '<', '3s U ', '&', ' you luvz me'])logging.disable(logging.CRITICAL)cursor.execute('INSERT INTO index(url) VALUES(%s)', (url,))df['DateStr'] = df['DateObj'].dt.strftime('%d%m%Y')s.split('@')[0]df.query('index < @start_remove or index > @end_remove')df.loc[(df.index < start_remove) | (df.index > end_remove)]df.isnull().sum()"	4
"variable = []intarray = array('i')[sublist[::-1] for sublist in to_reverse[::-1]]re.sub('[^0-9a-zA-Z]+', '*', 'h^&ell`.,|o w]{+orld')"""""""""""".join(['I ', '<', '3s U ', '&', ' you luvz me'])logging.disable(logging.CRITICAL)cursor.execute('INSERT INTO index(url) VALUES(%s)', (url,))df['DateStr'] = df['DateObj'].dt.strftime('%d%m%Y')s.split('@')[0]df.query('index < @start_remove or index > @end_remove')df.loc[(df.index < start_remove) | (df.index > end_remove)]df.isnull().sum()df.reset_index(inplace=True)[x['value'] for x in list_of_dicts][d['value'] for d in l]"	4
"my_function.__name__np.all(a == a[(0), :], axis=0)sorted(a, key=lambda x: (sum(x[1:3]), x[0]))sorted(a, key=lambda x: (sum(x[1:3]), x[0]), reverse=True)sorted(lst, key=lambda x: (sum(x[1:]), x[0]))sorted(lst, key=lambda x: (sum(x[1:]), x[0]), reverse=True)response.headers['WWW-Authenticate'] = 'Basic realm=""test""'del request.session['mykey']datetime.datetime.strptime('24052010', '%d%m%Y').date()re.sub('[^\\x00-\\x7F]+', ' ', text)numpy.array([[1, 2], [3, 4]])myList = [i for i in range(10)][m[0] for m in re.compile('((.+?)\\2+)').findall('44442(2)2(2)44')][i[0] for i in re.findall('((\\d)(?:[()]*\\2*[()]*)*)', s)]fig.subplots_adjust(wspace=0, hspace=0)"	4
"struct.pack('<I', 1633837924)list.append('foo')list.insert(0, 'foo')theset = set(k.lower() for k in thedict)""""""{s:{c}^{n}}"""""".format(s='dog', n=5, c='x')isinstance(s, str)isinstance(s, str)dict(pair for d in L for pair in list(d.items())){k: v for d in L for k, v in list(d.items())}df.sort_values(['Peak', 'Weeks'], ascending=[True, False], inplace=True)df.sort(['Peak', 'Weeks'], ascending=[True, False], inplace=True)eval(""print('Hello')"")[{'A': 1, 'C': 4, 'B': 2, 'D': 4}, {'A': 1, 'C': 4, 'B': 1, 'D': 5}][{'A': 1, 'C': 4, 'B': 2, 'D': 4}, {'A': 1, 'C': 4, 'B': 1, 'D': 5}]list(itertools.product(*a))"	4
df.ix[:, (df.loc[0] == 38.15)].columnsdf2['revenue'] = df2.CET.map(df1.set_index('date')['revenue'])json_data = json.loads(json_string)math.cos(math.radians(1))sum(isinstance(x, int) for x in a)'used\u200b'.replace('\u200b', '*')threading.Thread(target=SudsMove).start()sum(i * i for i in l)sum(map(lambda x: x * x, l))d = dict(((key, value) for (key, value) in iterable))d = {key: value for (key, value) in iterable}d = {k: v for (k, v) in iterable}df.round({'Alabama_exp': 2, 'Credit_exp': 3})p.setopt(pycurl.WRITEFUNCTION, lambda x: None)print(random.choice(words))	4
"zip(*sorted(enumerate(a), key=operator.itemgetter(1)))[0][-2:]sorted(list(range(len(a))), key=lambda i: a[i], reverse=True)[:2]list(x.keys()).index('c')print('{0:+d}'.format(score))[k for k, g in itertools.groupby([1, 2, 2, 3, 2, 2, 4])]""""""0,1,2"""""".split(',')[int(x) for x in '0,1,2'.split(',')]dict([('A', 1), ('B', 2), ('C', 3)])np.savetxt('test.txt', x)direct_output = subprocess.check_output('ls', shell=True)df[df.columns - ['T1_V6']]((25 < a) & (a < 100)).sum()date.today().strftime('%A')re.search('\\bis\\b', your_string){{car.date_of_manufacture | datetime}}"	4
"img = Image.open('picture.jpg')<nl>img.show()img = Image.open('picture.jpg')<nl>Img.showsys.exit(0)sys.exit('aa! errors!')sys.exit()[max(abs(x) for x in arr[i:i + 4]) for i in range(0, len(arr), 4)]os.chdir('c:\\Users\\uname\\desktop\\python')os.chdir(path)no_integers = [x for x in mylist if not isinstance(x, int)]tree.xpath("".//a[text()='Example']"")[0].tag"""""", """""".join([(str(k) + ' ' + str(v)) for k, v in list(a.items())])print(set(re.sub('[\x00-\x7f]', '', '\xa3\u20ac\xa3\u20ac')))print(re.sub('[\x00-\x7f]', '', '\xa3100 is worth more than \u20ac100'))ast.literal_eval(""{'muffin' : 'lolz', 'foo' : 'kitty'}"")print(t.decode('unicode_escape'))"	4
requests.post('http://httpbin.org/post', json={'test': 'cheers'})a = [x for x in a if x['link'] not in b]{{request.args.get('a')}}list(range(11, 17))data_df['grade'] = data_df['grade'].astype(float).astype(int)max(alkaline_earth_values, key=lambda x: x[1])your_string.strip('0')list(permutations(list(range(9)), 2))re.compile('^(.+)(?:\\n|\\r\\n?)((?:(?:\\n|\\r\\n?).+)+)', re.MULTILINE)re.compile('^(.+)\\n((?:\\n.+)+)', re.MULTILINE)call(['path/to/python', 'test2.py', 'neededArgumetGoHere'])a.sort(key=operator.itemgetter(2, 3))final_choices = ((another_choice,) + my_choices)final_choices = ((another_choice,) + my_choices)os.getcwd()	4
"sys.exit(0)"""""""""""".join(c for c in my_string if c.isdigit())re.split(' +', str1)re.findall('\\S+', str1)getattr(getattr(myobject, 'id', None), 'number', None){i: (i * 2) for i in range(10)}dict((i, i * 2) for i in range(10))plt.cla()total = sum(float(item) for item in s.split(','))bin(ord('P'))print(my_string.split(', ', 1)[1])print(data['places'][0]['post code'])word = re.sub('([aeiou]):(([aeiou][^aeiou]*){3})$', '\\1\\2', word)json.loads('{""foo"": 42, ""bar"": ""baz""}')['bar']data = json.loads(array)"	4
random.sample(list(range(100)), 10)s.rsplit(',', 1)all(isinstance(x, int) for x in lst)all(isinstance(x, int) for x in lst)line.strip()driver.execute_script('window.scrollTo(0, Y)')driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')datetime.datetime.combine(dateobject, datetime.time())print(any(x in a for x in b))scipy.misc.imsave('outfile.jpg', image_array)item = re.sub(' ?\\([^)]+\\)', '', item)item = re.sub(' ?\\(\\w+\\)', '', item)item = re.sub(' \\(\\w+\\)', '', item)len(set(list1).intersection(list2)) > 0i = int(s, 16)	4
for (letter, number) in list(d.items()):<nl><tab>passfor (k, v) in list(d.items()):<nl><tab>passlist(d.items())list(d.items())for (k, v) in list(d.items()):<nl><tab>passfor (letter, number) in list(d.items()):<nl><tab>passfor (letter, number) in list(d.items()):<nl><tab>passsession.query(Task).filter(Task.time_spent > timedelta(hours=3)).all()os.system('msbuild project.sln /p:Configuration=Debug')max(list(MyCount.keys()), key=int)os.system('source .bashrc; shopt -s expand_aliases; nuke -x scriptPath')my_function.__name__my_function.__name__np.all(a == a[(0), :], axis=0)sorted(a, key=lambda x: (sum(x[1:3]), x[0]))	4
dparser.parse('monkey 20/01/1980 love banana', fuzzy=True)dparser.parse('monkey 10/01/1980 love banana', fuzzy=True)dict(map(lambda s: s.split(':'), ['A:1', 'B:2', 'C:3', 'D:4']))re.search('[a-zA-Z]', the_string)DataFrame({'count': df1.groupby(['Name', 'City']).size()}).reset_index()re.sub('[^0-9]', '', 'sdkjh987978asd098as0980a98sd')[y for y in a if y not in b]df.groupby('ID').head(4)zip(*l)dict(zip([1, 2, 3, 4], ['a', 'b', 'c', 'd']))dict(zip([1, 2, 3, 4], ['a', 'b', 'c', 'd']))request.urlsomestring.replace('\\r', '')simplejson.dumps(dict([('%d,%d' % k, v) for k, v in list(d.items())]))datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')	4
list(d.items())for (k, v) in list(d.items()):<nl><tab>passfor (letter, number) in list(d.items()):<nl><tab>passfor (letter, number) in list(d.items()):<nl><tab>passsession.query(Task).filter(Task.time_spent > timedelta(hours=3)).all()os.system('msbuild project.sln /p:Configuration=Debug')max(list(MyCount.keys()), key=int)os.system('source .bashrc; shopt -s expand_aliases; nuke -x scriptPath')my_function.__name__my_function.__name__np.all(a == a[(0), :], axis=0)sorted(a, key=lambda x: (sum(x[1:3]), x[0]))sorted(a, key=lambda x: (sum(x[1:3]), x[0]), reverse=True)sorted(lst, key=lambda x: (sum(x[1:]), x[0]))sorted(lst, key=lambda x: (sum(x[1:]), x[0]), reverse=True)	4
list(itertools.chain.from_iterable(list2d))ord('a')re.sub('(?m)^[^\\S\\n]+', '', '  a\n b\n c\nd  e')re.sub('(?m)^\\s+', '', 'a\n b\n c')a, b, c = [1, 2, 3][list(v) for k, v in itertools.groupby(mylist, key=lambda x: x[:5])]line = re.sub('\\(+as .*?\\) ', '', line)print(line.rstrip('\n'))df.index.values.tolist()if (not a):<nl><tab>passif (not seq):<nl><tab>passif (len(li) == 0):<nl><tab>pass[i for i, v in enumerate(a) if v > 4]sorted(yourdata, reverse=True)sorted(yourdata, key=lambda d: d.get('key', {}).get('subkey'), reverse=True)	4
map(int, example_string.split(','))[int(s) for s in example_string.split(',')]x = [i[0] for i in x]y = map(operator.itemgetter(0), x)y = [i[0] for i in x]results = [item['value'] for item in test_data]datetime.datetime.now().isoformat()datetime.datetime.utcnow().isoformat()df.apply(' '.join, axis=0)pd.DataFrame(df.values - df2.values, columns=df.columns)print(open('myfile.txt', 'U').read())print(line.decode('utf-16-le').split())file = io.open('data.txt', 'r', encoding='utf-16-le')s1 = pd.merge(df1, df2, how='inner', on=['user_id'])foo.decode('utf8').encode('utf8')	4
a['x'].apply(lambda x, y: x + y, args=(100,))User.objects.order_by('-pet__age')[:10]time.sleep(5)time.sleep(60)sleep(0.1)time.sleep(60)time.sleep(0.1)[x for x in my_list if not any(c.isdigit() for c in x)]df['state'].apply(lambda x: x[len(x) / 2 - 1:len(x) / 2 + 1])plt.grid(True)sorted(lst, key=lambda x: (-1 * c[x], lst.index(x)))[max(len(str(x)) for x in line) for line in zip(*foo)]df.Country.value_counts().reset_index(name='Sum of Accidents')data.set_index('Date').diff()a.update([3, 4])	4
"Employees.objects.values_list('eng_name', flat=True)re.findall('\\d|\\d,\\d\\)', '6,7)')input('Press Enter to continue...')""""""ABC"""""".encode('hex')db.Doc.update({'_id': b['_id']}, {'$set': {'geolocCountry': myGeolocCountry}})re.sub('l+', 'l', 'lollll')rows = soup.findAll('tr')[4::5]plt.gca().invert_xaxis()plt.gca().invert_yaxis()pd.concat([GOOG, AAPL], keys=['GOOG', 'AAPL'], axis=1)return HttpResponse(json.dumps(response_data), content_type='application/json')myString.decode('string_escape')hashlib.md5(open('filename.exe', 'rb').read()).hexdigest()[k for k, v in d.items() if v == desired_value]{k for d in LoD for k in list(d.keys())}"	4
"print(sorted(student_tuples, key=lambda t: (-t[2], t[0])))[y for x in range(3) for y in [x, x]]txt = open('file.txt').read()myList[:] = [(x / myInt) for x in myList]""""""Name: {0[person.name]}"""""".format({'person.name': 'Joe'})df.replace(' ', '_', regex=True)datetime.datetime.combine(my_date, datetime.time.min)tst2 = str(tst)time.ctime(os.path.getmtime(file))time.ctime(os.path.getctime(file))t = os.path.getmtime(filename)os.path.getmtime(path)print(('last modified: %s' % time.ctime(os.path.getmtime(file))))print(('created: %s' % time.ctime(os.path.getctime(file))))return os.path.getctime(path_to_file)"	4
[int(i) for i in str_list]map(int, ['1', '2', '3'])list(map(int, ['1', '2', '3']))soup.find_all('a', href=re.compile('http://www\\.iwashere\\.com/'))soup.find_all('a', href=re.compile('^(?!(?:[a-zA-Z][a-zA-Z0-9+.-]*:|//))'))subprocess.call(['java', '-jar', 'Blender.jar'])cursor.execute('INSERT INTO table (`column1`) VALUES (%s)', (value,))if url.endswith('.com'):<nl><tab>url = url[:(-4)]url = re.sub('\\.com$', '', url)print(url.replace('.com', ''))if (not text.endswith(suffix)):<nl><tab>return text<nl>return text[:(len(text) - len(suffix))]print(', ,'.join([str(i[0]) for i in mytuple]))max(min(my_value, max_value), min_value)re.findall('\\w+|[^\\w\\s]', text, re.UNICODE)result = db.engine.execute('<sql here>')	4
item = re.sub(' \\(\\w+\\)', '', item)len(set(list1).intersection(list2)) > 0i = int(s, 16)int('0xff', 16)int('FFFF', 16)ast.literal_eval('0xdeadbeef')int('deadbeef', 16)os.system('screencapture screen.png')driver.set_window_size(1400, 1000)unicodedata.normalize('NFKD', 'm\xfasica').encode('ascii', 'ignore')pandas.concat([df1, df2]).drop_duplicates().reset_index(drop=True)a = numpy.fromfile('filename', dtype=numpy.float32)subprocess.call('mv /home/somedir/subdir/* somedir/', shell=True)subprocess.call('mv /home/somedir/subdir/* somedir/', shell=True)print('\u25b2'.encode('utf-8'))	4
re.sub('.*I', 'I', stri)int('1,000,000'.replace(',', ''))pd.merge(df1, df2, left_index=True, right_index=True, how='outer')pandas.concat([df1, df2], axis=1)all(dict.values())df.c_contofficeID.str.replace('^12(?=.{4}$)', '')L[::(-1)]reversed(array)L.reverse()list(reversed(array))[tup[0] for tup in A]newcontents = contents.replace('a', 'e').replace('s', '3')json.dumps([dict(list(row.items())) for row in rs])config_file = os.path.expanduser('~/foo.ini')request.params.getall('c')	4
'Unix EOL\n'.rstrip('\r\n')'Hello\n\n\n'.rstrip('\n')re.findall('.{,16}\\b', text)[[X[i][j] for j in range(len(X[i]))] for i in range(len(X))]'\xd0\xbc\xd0\xb0\xd1\x80\xd0\xba\xd0\xb0'.encode('latin-1')df.groupby((df.a == 'B').shift(1).fillna(0).cumsum())urllib.request.urlretrieve('http://search.twitter.com/search.json?q=hi', 'hi.json')numpy.where((x == 0))[0]sys.stdout.flush()str(i)a.__str__()str(a)L.sort(key=operator.itemgetter(1))print(str(count) + '<tab>' + str(conv))df.fillna(method='ffill', inplace=True)	4
"df.reset_index(inplace=True)[x['value'] for x in list_of_dicts][d['value'] for d in l][d['value'] for d in l if 'value' in d]np.array([[1, 2, 3], [4, 5, 6]]).tolist()ast.literal_eval('(1,2,3,4)')dataList.sort(key=lambda x: x[1])list(map(list, set(map(lambda i: tuple(i), testdata))))[list(i) for i in set(tuple(i) for i in testdata)]return user.groups.filter(name='Member').exists()return user.groups.filter(name__in=['group1', 'group2']).exists()logging.getLogger().setLevel(logging.DEBUG)"""""""""""".join(str(i) for i in (34.2424, -64.2344, 76.3534, 45.2344))"""""""""""".join([s[x:x + 2][::-1] for x in range(0, len(s), 2)])plt.savefig('graph.png', dpi=1000)"	4
"result.replace('\\', '')df.replace('-', 'NaN')datetime.datetime.now().date()datetime.datetime.now().date()[elem.tag for elem in a.iter()][elem.tag for elem in a.iter() if elem is not a]""""""2.7.0_bf4fda703454"""""".split('_')sorted(lst, key=lambda x: x['language'] != 'en')all(value == 0 for value in list(your_dict.values()))df.pivot_table('Y', rows='X', cols='X2')try:<nl><tab>doSomething()<nl>except:<nl><tab>passtry:<nl><tab>doSomething()<nl>except Exception:<nl><tab>passM.sum(axis=0).sum(axis=0)time.mktime(dt.timetuple()) + dt.microsecond / 1000000.0df[(x <= df['columnX']) & (df['columnX'] <= y)]"	4
a[np.argmin(a[:, (1)])]a.update(b)[{k: v for k, v in d.items() if k != 'mykey1'} for d in mylist][dict((k, v) for k, v in d.items() if k != 'mykey1') for d in mylist]numpy.random.random((3, 3))df['C'] = df['A'] + df['B'][value for key, value in list(programs.items()) if 'new york' in key.lower()]sys.path.append('/path/to/main_folder')re.findall('\\d+(?=[^[]+$)', s)pickle.load(open('afile', 'rb'))driver.find_element_by_xpath('xpath').click()ex.groupby(level='A').agg(lambda x: x.index.get_level_values(1).nunique())pd.concat(map(pd.DataFrame, iter(d.values())), keys=list(d.keys())).stack().unstack(0)sum(1 for i, j in zip(a, b) if i != j)d = {(a.lower(), b): v for (a, b), v in list(d.items())}	4
print(np.array(list(mystr), dtype=int))img = cv2.imread('messi5.jpg', 0)lst.sort(key=lambda x: x[2], reverse=True)indices = [i for i, x in enumerate(my_list) if x == 'whatever']subprocess.call('grep -r PASSED *.log | sort -u | wc -l', shell=True)len(my_text) - len(my_text.rstrip('?'))df[df.columns[1:]].replace('[\\$,]', '', regex=True).astype(float)df1.merge(df2, how='left', on='word')print(''.join(''.join(i) for i in zip(a2, a1)) + a[-1] if len(a) % 2 else '')root.attributes('-topmost', True)root.lift()hex(int(''.join([str(int(b)) for b in walls]), 2))hex(sum(b << i for i, b in enumerate(reversed(walls))))print(('Total score for', name, 'is', score))print('Total score for {} is {}'.format(name, score))	4
numpy.apply_along_axis(numpy.linalg.norm, 1, a)dict((k, v) for d in dicts for k, v in list(d.items()))print('your string'.decode('string_escape'))sum([True, True, False, False, False, True])fig.set_size_inches(w, h, forward=True)'hello there %(5)s' % {'5': 'you'}map(int, example_string.split(','))[int(s) for s in example_string.split(',')]x = [i[0] for i in x]y = map(operator.itemgetter(0), x)y = [i[0] for i in x]results = [item['value'] for item in test_data]datetime.datetime.now().isoformat()datetime.datetime.utcnow().isoformat()df.apply(' '.join, axis=0)	4
"print(('last modified: %s' % time.ctime(os.path.getmtime(file))))print(('created: %s' % time.ctime(os.path.getctime(file))))return os.path.getctime(path_to_file)os.system('TASKKILL /F /IM firefox.exe')return (x.group(0) for x in re.finditer(""[A-Za-z']+"", string))"""""", """""".join(['%.2f'] * len(x))print(re.match('(\\d+(\\.\\d+)?)', '3434.35353').group(1))df['name'].str.replace('\\(.*\\)', '')result = [x for x in list_a if x[0] in list_b]print([''.join(a) for a in combinations(['hel', 'lo', 'bye'], 2)])[x for x in li if 'ar' in x[2]]unsorted_list.sort(key=lambda x: x[3])logging.info('test')fig.add_subplot(1, 1, 1)sorted(list(x.items()), key=operator.itemgetter(1))"	4
"difflib.SequenceMatcher(None, file1.read(), file2.read())dict((k, int(v)) for k, v in (e.split(' - ') for e in s.split(',')))all(i in (1, 2, 3, 4, 5) for i in (1, 6))df['Date'].map(lambda t: t.date()).unique()""""""{:>7s}"""""".format(mystring)open('ComponentReport-DJI.xls', 'rb').read(200)df.sort_values(['b', 'c'], ascending=[True, False], inplace=True)df.sort_values(['a', 'b'], ascending=[True, False])df1.sort(['a', 'b'], ascending=[True, False], inplace=True)df.sort(['a', 'b'], ascending=[True, False])redirect('Home.views.index')[x for x in a if x not in [2, 3, 7]]out = ''.join(c for c in asking if c not in ('!', '.', ':'))soup.find('meta', {'name': 'City'})['content']urllib.parse.unquote('%0a')"	4
parser.parse('Aug 28 1999 12:00AM')os.path.split(os.path.abspath(existGDBPath))os.path.dirname(os.path.abspath(existGDBPath))requests.post('http://httpbin.org/post', json={'test': 'cheers'})a = [x for x in a if x['link'] not in b]{{request.args.get('a')}}list(range(11, 17))data_df['grade'] = data_df['grade'].astype(float).astype(int)max(alkaline_earth_values, key=lambda x: x[1])your_string.strip('0')list(permutations(list(range(9)), 2))re.compile('^(.+)(?:\\n|\\r\\n?)((?:(?:\\n|\\r\\n?).+)+)', re.MULTILINE)re.compile('^(.+)\\n((?:\\n.+)+)', re.MULTILINE)call(['path/to/python', 'test2.py', 'neededArgumetGoHere'])a.sort(key=operator.itemgetter(2, 3))	4
"x = map(int, x.split())x = [int(i) for i in x.split()]driver.find_element_by_css_selector(""input[onclick*='1 Bedroom Deluxe']"")re.sub('[^a-zA-Z0-9-_*.]', '', my_string)webbrowser.open('file:///my_pdf.pdf')result = result.replace('\\', '')result.replace('\\', '')df.replace('-', 'NaN')datetime.datetime.now().date()datetime.datetime.now().date()[elem.tag for elem in a.iter()][elem.tag for elem in a.iter() if elem is not a]""""""2.7.0_bf4fda703454"""""".split('_')sorted(lst, key=lambda x: x['language'] != 'en')all(value == 0 for value in list(your_dict.values()))"	4
subprocess.Popen(['rm', '-r', 'some.file'])dict((d['name'], d) for d in listofdict)datetime.datetime.now().strftime('%Y-%m-%d %H:%M')time.strftime('%Y-%m-%d %H:%M')re.findall('[bcdfghjklmnpqrstvwxyz]+', 'CONCERTATION', re.IGNORECASE)[i for i, e in enumerate(a) if e != 0]map(int, re.findall('\\d+', string1))os.path.dirname(sys.executable)ax.xaxis.set_label_position('top')ax.xaxis.tick_top()ax.xaxis.set_ticks_position('top')datetime.strptime('2015/01/01 12:12am', '%Y/%m/%d %I:%M%p')img = Image.open('picture.jpg')<nl>img.show()img = Image.open('picture.jpg')<nl>Img.showsys.exit(0)	4
Blog.objects.filter(pk__in=[1, 4, 7])f = open('test/test.pdf', 'rb')format(12345678.46, ',').replace(',', ' ').replace('.', ',')pd.merge(frame_1, frame_2, left_on='county_ID', right_on='countyid')np.isnan(a).sum() / np.prod(a.shape)sorted(iter(cityPopulation.items()), key=lambda k_v: k_v[1][2], reverse=True)sorted(list(u.items()), key=lambda v: v[1])sorted(list(d.items()), key=lambda k_v: k_v[1], reverse=True)sorted(list(d.items()), key=lambda k_v: k_v[1])f = open(os.path.join(__location__, 'bundled-resource.jpg'))f = open('words.txt', 'rU'){k: (float(d2[k]) / d1[k]) for k in d2}{k: (d2[k] / d1[k]) for k in list(d1.keys()) & d2}dict((k, float(d2[k]) / d1[k]) for k in d2)df.to_csv(filename, date_format='%Y%m%d')	4
str(i)a.__str__()str(a)L.sort(key=operator.itemgetter(1))print(str(count) + '<tab>' + str(conv))df.fillna(method='ffill', inplace=True)text.config(state=DISABLED)sum(map(ord, string))list(itertools.product(*arrays))'{:,}'.format(value)locale.setlocale(locale.LC_ALL, 'en_US')<nl>locale.format('%d', 1255000, grouping=True)df[df.Col1.isin(['men', 'rocks', 'mountains'])][x[1] for x in L]'\u0440\u0430\u0437 \u0434\u0432\u0430 \u0442\u0440\u0438'.split()MyModel.objects.extra(select={'length': 'Length(name)'}).order_by('length')	4
"sys.exit('aa! errors!')sys.exit()[max(abs(x) for x in arr[i:i + 4]) for i in range(0, len(arr), 4)]os.chdir('c:\\Users\\uname\\desktop\\python')os.chdir(path)no_integers = [x for x in mylist if not isinstance(x, int)]tree.xpath("".//a[text()='Example']"")[0].tag"""""", """""".join([(str(k) + ' ' + str(v)) for k, v in list(a.items())])print(set(re.sub('[\x00-\x7f]', '', '\xa3\u20ac\xa3\u20ac')))print(re.sub('[\x00-\x7f]', '', '\xa3100 is worth more than \u20ac100'))ast.literal_eval(""{'muffin' : 'lolz', 'foo' : 'kitty'}"")print(t.decode('unicode_escape'))print(str.encode('cp1252').decode('utf-8').encode('cp1252').decode('utf-8'))zip(list_a, list_b)list(zip(a, b))"	4
timestamp = (dt - datetime(1970, 1, 1)).total_seconds()df.sort('m')a = sorted(a, key=lambda x: x.modified, reverse=True)print(bool(a))df = df.rename(index={last: 'a'})km.fit(x.reshape(-1, 1))sorted(words, key=lambda x: 'a' + x if x.startswith('s') else 'b' + x)webbrowser.open('http://somesite.com/adminpanel/index.php')dict((k, v) for k, v in parent_dict.items() if 2 < k < 4)dict((k, v) for k, v in parent_dict.items() if k > 2 and k < 4)[list(x) for x in zip(*sorted(zip(list1, list2), key=lambda pair: pair[0]))]sum(((i > 5) for i in j))len([1 for i in j if (i > 5)])j = np.array(j)<nl>sum((j > i))[(x + tuple(y)) for x, y in zip(zip(a, b), c)]	4
s = s.rstrip()s = s.strip(' \t\n\r')print(re.sub('[\\s+]', '', s))Task.objects.exclude(prerequisites__status__in=['A', 'P', 'F'])root.configure(background='black')numpy.array([(key, val) for key, val in result.items()], dtype)pd.concat([df_1, df_2.sort_values('y')])re.sub('(.*)</div>', '\\1</bad>', s)print(max(d, key=lambda x: (d[x]['salary'], d[x]['bonus'])))Book.objects.filter(author__id=1).filter(author__id=2)re.compile('XYZ', re.IGNORECASE).split('fooxyzbar')[sum(map(int, s)) for s in example.split()][i for i in y if y[i] == 1]c.decode('unicode_escape')pd.melt(x, id_vars=['farm', 'fruit'], var_name='year', value_name='value')	4
"np.linalg.solve(np.dot(a.T, a), np.dot(a.T, b))pd.concat([df.drop('b', axis=1), pd.DataFrame(df['b'].tolist())], axis=1)for i in range(0, 10, 2):<nl><tab>passfor i in mylist[::2]:<nl><tab>pass[{'content': x['content'].lower()} for x in messages]"""""" """""".join(my_list)re.sub('(http://\\S+|\\S*[^\\w\\s]\\S*)', '', a)str(n) == str(n)[::-1]ftp.storbinary('STOR myfile.txt', open('myfile.txt', 'rb'))re.sub('.*I', 'I', stri)int('1,000,000'.replace(',', ''))pd.merge(df1, df2, left_index=True, right_index=True, how='outer')pandas.concat([df1, df2], axis=1)all(dict.values())df.c_contofficeID.str.replace('^12(?=.{4}$)', '')"	4
"b = {a[i]: a[i + 1] for i in range(0, len(a), 2)}len(set(a)) == len(a)print(hashlib.md5(open(full_path, 'rb').read()).hexdigest())sorted(list(data.items()), key=lambda x: x[1][0])"""""""""""".join(x.upper() if random.randint(0, 1) else x for x in s)os.system('GREPDB=""echo 123""; /bin/bash -c ""$GREPDB""')os.system('/bin/bash -c ""echo hello world""')getattr(test, a_string)Image.open('pathToFile').show()""""""didn't"""""".replace(""'"", '')files.sort(key=file_number)sentence.replace(' ', '')pattern = re.compile('\\s+')<nl>sentence = re.sub(pattern, '', sentence)sentence.strip()sentence = re.sub('\\s+', '', sentence, flags=re.UNICODE)"	4
df.set_index(['d'], append=True)for (key, value) in d.items():<nl><tab>passfor (key, value) in list(d.items()):<nl><tab>passfor (letter, number) in list(d.items()):<nl><tab>passfor (k, v) in list(d.items()):<nl><tab>passlist(d.items())list(d.items())for (k, v) in list(d.items()):<nl><tab>passfor (letter, number) in list(d.items()):<nl><tab>passfor (letter, number) in list(d.items()):<nl><tab>passsession.query(Task).filter(Task.time_spent > timedelta(hours=3)).all()os.system('msbuild project.sln /p:Configuration=Debug')max(list(MyCount.keys()), key=int)os.system('source .bashrc; shopt -s expand_aliases; nuke -x scriptPath')my_function.__name__	4
pd.merge(frame_1, frame_2, left_on='county_ID', right_on='countyid')np.isnan(a).sum() / np.prod(a.shape)sorted(iter(cityPopulation.items()), key=lambda k_v: k_v[1][2], reverse=True)sorted(list(u.items()), key=lambda v: v[1])sorted(list(d.items()), key=lambda k_v: k_v[1], reverse=True)sorted(list(d.items()), key=lambda k_v: k_v[1])f = open(os.path.join(__location__, 'bundled-resource.jpg'))f = open('words.txt', 'rU'){k: (float(d2[k]) / d1[k]) for k in d2}{k: (d2[k] / d1[k]) for k in list(d1.keys()) & d2}dict((k, float(d2[k]) / d1[k]) for k in d2)df.to_csv(filename, date_format='%Y%m%d')my_dict.pop('key', None)b = np.where(np.isnan(a), 0, a)subprocess.call('start command -flags arguments', shell=True)	4
"any(x in string for x in search)print(pattern.search(url).group(1))(s.factorize()[0] + 1).astype('float')C = [(a - b) for a, b in zip(A, B)]datetime.datetime.strptime('2011, 4, 0', '%Y, %U, %w')map(int, ['1', '-1', '1'])datetime.datetime.strptime('16Sep2012', '%d%b%Y')Book.objects.filter(pk=pk).update(**d)Book.objects.create(**d)print('{0:.2f}'.format(your_number))random.randint(100000000000, 999999999999)int(''.join(str(random.randint(0, 9)) for _ in range(12)))"""""""""""".join(str(random.randint(0, 9)) for _ in range(12))'%0.12d' % random.randint(0, 999999999999)numpy.delete(a, index)"	4
"[int(s[i:i + 3], 2) for i in range(0, len(s), 3)]dict((v, k) for k, v in my_dict.items())print(sorted(L, key=lambda x: int(x.split('.')[2])))any(d['name'] == 'Test' for d in label)a[:] = [x for x in a if x != [1, 1]][x for x in a if x != [1, 1]]b = {a[i]: a[i + 1] for i in range(0, len(a), 2)}len(set(a)) == len(a)print(hashlib.md5(open(full_path, 'rb').read()).hexdigest())sorted(list(data.items()), key=lambda x: x[1][0])"""""""""""".join(x.upper() if random.randint(0, 1) else x for x in s)os.system('GREPDB=""echo 123""; /bin/bash -c ""$GREPDB""')os.system('/bin/bash -c ""echo hello world""')getattr(test, a_string)Image.open('pathToFile').show()"	4
pd.DataFrame(df.values - df2.values, columns=df.columns)print(open('myfile.txt', 'U').read())print(line.decode('utf-16-le').split())file = io.open('data.txt', 'r', encoding='utf-16-le')s1 = pd.merge(df1, df2, how='inner', on=['user_id'])foo.decode('utf8').encode('utf8')a.shapeN.shape(a)N.shape(a)a.shape[i for i, v in enumerate(L) if v[0] == 53]struct.unpack('<L', 'y\xcc\xa6\xbb')[0]arr[[0, 1, 1], [1, 0, 2]]list(powerset('abcd'))s in ['true', '1', 't', 'y', 'yes', 'yeah', 'yup', 'certainly', 'uh-huh']	4
pd.concat([GOOG, AAPL], keys=['GOOG', 'AAPL'], axis=1)return HttpResponse(json.dumps(response_data), content_type='application/json')myString.decode('string_escape')hashlib.md5(open('filename.exe', 'rb').read()).hexdigest()[k for k, v in d.items() if v == desired_value]{k for d in LoD for k in list(d.keys())}set([i for s in [list(d.keys()) for d in LoD] for i in s])[i for s in [list(d.keys()) for d in LoD] for i in s]keys, values = zip(*list(d.items()))int(Decimal(s))int(s.split('.')[0])numpy.in1d(b, a).all()numpy.array([(x in a) for x in b])networkx.draw_networkx_labels(G, pos, labels)y = [row[:] for row in x]	4
re.sub('(http://\\S+|\\S*[^\\w\\s]\\S*)', '', a)str(n) == str(n)[::-1]ftp.storbinary('STOR myfile.txt', open('myfile.txt', 'rb'))re.sub('.*I', 'I', stri)int('1,000,000'.replace(',', ''))pd.merge(df1, df2, left_index=True, right_index=True, how='outer')pandas.concat([df1, df2], axis=1)all(dict.values())df.c_contofficeID.str.replace('^12(?=.{4}$)', '')L[::(-1)]reversed(array)L.reverse()list(reversed(array))[tup[0] for tup in A]newcontents = contents.replace('a', 'e').replace('s', '3')	4
cursor.execute('INSERT INTO index(url) VALUES(%s)', (url,))df['DateStr'] = df['DateObj'].dt.strftime('%d%m%Y')s.split('@')[0]df.query('index < @start_remove or index > @end_remove')df.loc[(df.index < start_remove) | (df.index > end_remove)]df.isnull().sum()df.reset_index(inplace=True)[x['value'] for x in list_of_dicts][d['value'] for d in l][d['value'] for d in l if 'value' in d]np.array([[1, 2, 3], [4, 5, 6]]).tolist()ast.literal_eval('(1,2,3,4)')dataList.sort(key=lambda x: x[1])list(map(list, set(map(lambda i: tuple(i), testdata))))[list(i) for i in set(tuple(i) for i in testdata)]	4
[str(wi) for wi in wordids]df2 = df.reset_index()dt.strftime('%m/%d/%Y')print('Total cost is: ${:,.2f}'.format(TotalAmount))df.groupby(np.arange(len(df.columns)) // 2 + 1, axis=1).sum().add_prefix('s')randomList = [random.random() for _ in range(10)]print(soup.find('a', href=re.compile('.*follow\\?page.*')))sys.stdout.flush()country, capital = random.choice(list(d.items()))list('Word to Split')[w for w in open('file.txt') if not re.search('[aeiou]{2}', w)]pat = re.compile('^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$')exec(compile(open('filename.py').read(), 'filename.py', 'exec'))session.query(Tag).distinct(Tag.name).group_by(Tag.name).count()df = df.dropna(axis=1, how='all')	4
[x for x in file.namelist() if x.endswith('/')]input_string.count('Hello')print('.'.join([item[0] for item in data]))fh1.seek(2)print(zip(my_list[0::2], my_list[1::2]))my_new_list = zip(my_list[0::2], my_list[1::2])sys.setdefaultencoding('utf8')datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')print(re.findall('[\\u0600-\\u06FF]+', my_string))df.groupby(df.index.map(lambda t: t.minute))dict['Apple']['American']df2.dropna(subset=['three', 'four', 'five'], how='all')a.insert(0, k)a = a[:n] + k + a[n:]np.flatnonzero(x).mean()	4
df.groupby(by=df.columns, axis=1).mean()bar.sort(key=lambda x: (x.attrb1, x.attrb2), reverse=True)alpha = img.split()[-1][len(x) for x in s.split()]soup.findAll('div', style='width=300px;')cursor.execute(sql, list(myDict.values()))df.to_csv('Result.csv', index=False, sep=' ')globals().update(vars(args))re.findall('\\[(.*?)\\]', mystring)print('%.2f kg = %.2f lb = %.2f gal = %.2f l' % (var1, var2, var3, var4))d = dict((k, v) for k, v in d.items() if v > 0)d = {k: v for k, v in list(d.items()) if v > 0}pd.to_datetime(pd.Series(date_stngs))df.iloc[2, 0]matplotlib.rcParams.update({'font.size': 22})	4
datetime.datetime.now().isoformat()datetime.datetime.utcnow().isoformat()df.apply(' '.join, axis=0)pd.DataFrame(df.values - df2.values, columns=df.columns)print(open('myfile.txt', 'U').read())print(line.decode('utf-16-le').split())file = io.open('data.txt', 'r', encoding='utf-16-le')s1 = pd.merge(df1, df2, how='inner', on=['user_id'])foo.decode('utf8').encode('utf8')a.shapeN.shape(a)N.shape(a)a.shape[i for i, v in enumerate(L) if v[0] == 53]struct.unpack('<L', 'y\xcc\xa6\xbb')[0]	4
"os.remove(filename)min([x for x in num_list if x > 2])df['prod_type'] = 'responsive'sorted(lst, key=lambda x: (x < 0, x))six_months = (date.today() + relativedelta(months=(+ 6)))(date(2010, 12, 31) + relativedelta(months=(+ 1)))(date(2010, 12, 31) + relativedelta(months=(+ 2)))print((datetime.date.today() + datetime.timedelta(((6 * 365) / 12))).isoformat())sorted(list(things.keys()), key=lambda x: things[x]['weight'], reverse=True)a[np.arange(len(a)) != 3][x for x in lst if fn(x) != 0]df.set_index('month')arr = [line.split(',') for line in open('./urls-eu.csv')][i for i in range(100) if i > 10 if i < 20]"""""""""""".join([c for c in strs if c.isdigit()])"	4
'test string \n\n'.rstrip('\n')s.strip()s.rstrip()s.lstrip()'Mac EOL\r'.rstrip('\r\n')'Windows EOL\r\n'.rstrip('\r\n')'Unix EOL\n'.rstrip('\r\n')'Hello\n\n\n'.rstrip('\n')re.findall('.{,16}\\b', text)[[X[i][j] for j in range(len(X[i]))] for i in range(len(X))]'\xd0\xbc\xd0\xb0\xd1\x80\xd0\xba\xd0\xb0'.encode('latin-1')df.groupby((df.a == 'B').shift(1).fillna(0).cumsum())urllib.request.urlretrieve('http://search.twitter.com/search.json?q=hi', 'hi.json')numpy.where((x == 0))[0]sys.stdout.flush()	4
"os.system('/bin/bash -c ""echo hello world""')getattr(test, a_string)Image.open('pathToFile').show()""""""didn't"""""".replace(""'"", '')files.sort(key=file_number)sentence.replace(' ', '')pattern = re.compile('\\s+')<nl>sentence = re.sub(pattern, '', sentence)sentence.strip()sentence = re.sub('\\s+', '', sentence, flags=re.UNICODE)sentence = ''.join(sentence.split())sum(my_counter.values())np.sqrt(((A - B) ** 2).sum(-1))levels = [{}, {}, {}]weekly = [sum(visitors[x:x + 7]) for x in range(0, len(daily), 7)]del d[key]"	4
max(a_list, key=operator.itemgetter(1))s.resample('3M', how='sum')[a[i] for i in (1, 2, 5)][line for line in open('textfile') if 'apple' in line]datetime.datetime.strptime(s, '%Y-%m-%dT%H:%M:%SZ')pandas.read_csv(filename, sep='\t', lineterminator='\r')'longlongTESTstringTEST'.replace('TEST', '?', 1)archive.write(pdffile, os.path.basename(pdffile))dict(x[1:] for x in reversed(myListOfTuples))[(x1 - x2) for x1, x2 in zip(List1, List2)]string[0].isdigit()strg.startswith(('0', '1', '2', '3', '4', '5', '6', '7', '8', '9'))print(os.path.dirname(os.path.realpath(__file__)))re.split('(?<=\\?|!|\\.)\\s{0,2}(?=[A-Z]|$)', text)plt.scatter(*zip(*li))	4
dir_path = os.path.dirname(os.path.realpath(__file__))cwd = os.getcwd()full_path = os.path.realpath(__file__)arr[arr[:, (2)].argsort()]numpy.sort(arr, axis=0)re.split('[ .]', 'a b.c')shutil.copy('file.txt', 'file2.txt')print(''.join(choice(ascii_uppercase) for i in range(12)))[''.join(seq) for seq in zip(lst, lst[1:])]data.rename(columns={'gdp': 'log(gdp)'}, inplace=True)print(soup.get_text())sorted(li, key=operator.itemgetter(1), reverse=True)data['sex'].replace([0, 1], ['Female', 'Male'], inplace=True)re.split('\\W+', 'Words, words, words.')re.match('(.*?[.?!](?:\\s+.*?[.?!]){0,1})', phrase).group(1)	4
"[(i, sum(j) / len(j)) for i, j in list(d.items())]zip([1, 2], [3, 4])['hello{0}'.format(i) for i in a]re.sub('(?<!\\S)((\\S+)(?:\\s+\\2))(?:\\s+\\2)+(?!\\S)', '\\1', s)df.div(df.sum(axis=1), axis=0)map(lambda t: (t[1], t[0]), mylist)[(t[1], t[0]) for t in mylist]driver.find_element_by_xpath(""//p[@id, 'one']/following-sibling::p"")re.findall('\\[[^\\]]*\\]|\\([^\\)]*\\)|""[^""]*""|\\S+', strs)print(list(itertools.combinations({1, 2, 3, 4}, 3)))df[['hour', 'weekday', 'weeknum']] = df.apply(lambdafunc, axis=1)soup.find_all('a', string='Elsie')my_datetime.strftime('%B %d, %Y')int(''.join(c for c in s if c.isdigit()))dic['Test'].update({'class': {'section': 5}})"	4
np.einsum('ijk,ikl->ijl', A, B)print('I have: {0.price}'.format(card))f.write('# Data for Class A\n')a = a[-1:] + a[:-1]datetimevariable.strftime('%Y-%m-%d')mixed.replace('\r\n', '\n').replace('\r', '\n')os.path.expanduser('~user')T = [L[i] for i in Idx]words = open('myfile').read().split()[[sum([x[1] for x in i])] for i in data][sum([x[1] for x in i]) for i in data]Article.objects.annotate(like_count=Count('likes')).order_by('-like_count')today = datetime.datetime.utcnow().date()[(a * b) for a, b in zip(lista, listb)]re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', s)	4
"bin(ord('P'))print(my_string.split(', ', 1)[1])print(data['places'][0]['post code'])word = re.sub('([aeiou]):(([aeiou][^aeiou]*){3})$', '\\1\\2', word)json.loads('{""foo"": 42, ""bar"": ""baz""}')['bar']data = json.loads(array)data = json.loads(array)re.findall('#(\\w+)', 'http://example.org/#comments')any(e in lestring for e in lelist)df.plot(x='col_name_1', y='col_name_2', style='o')parsed_html = BeautifulSoup(html)<nl>print(parsed_html.body.find('div', attrs={'class': 'container', }).text)page = urllib.request.urlopen('http://www.google.com/')<nl>soup = BeautifulSoup(page)plt.figure(figsize=(3, 4))s.translate(None, string.punctuation)base64.urlsafe_b64decode(uenc.encode('ascii'))"	4
"sorted(list(data.items()), key=lambda x: x[1][0])"""""""""""".join(x.upper() if random.randint(0, 1) else x for x in s)os.system('GREPDB=""echo 123""; /bin/bash -c ""$GREPDB""')os.system('/bin/bash -c ""echo hello world""')getattr(test, a_string)Image.open('pathToFile').show()""""""didn't"""""".replace(""'"", '')files.sort(key=file_number)sentence.replace(' ', '')pattern = re.compile('\\s+')<nl>sentence = re.sub(pattern, '', sentence)sentence.strip()sentence = re.sub('\\s+', '', sentence, flags=re.UNICODE)sentence = ''.join(sentence.split())sum(my_counter.values())np.sqrt(((A - B) ** 2).sum(-1))"	4
print([a for a, b in re.findall('((\\w)\\2*)', s)])print(' '.join(OrderedDict.fromkeys(s)))print(' '.join(set(s)))[x for x in file.namelist() if x.endswith('/')]input_string.count('Hello')print('.'.join([item[0] for item in data]))fh1.seek(2)print(zip(my_list[0::2], my_list[1::2]))my_new_list = zip(my_list[0::2], my_list[1::2])sys.setdefaultencoding('utf8')datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')print(re.findall('[\\u0600-\\u06FF]+', my_string))df.groupby(df.index.map(lambda t: t.minute))dict['Apple']['American']df2.dropna(subset=['three', 'four', 'five'], how='all')	4
"os.environ['DEBUSSY'] = '1'print(os.environ['DEBUSSY'])os.environ['DEBUSSY'] = '1'b.update(d)df['b']ebar = plt.errorbar(x, y, yerr=err, ecolor='y')results += [each for each in os.listdir(folder) if each.endswith('.c')]print('\xc2\xa3'.decode('utf8') + '1')re.sub('(?<=[a-z])([A-Z])', '-\\1', s).lower()os.system('ulimit -s unlimited; some_executable')""""""{0:.3g}"""""".format(num)numpy.append(a, a[0])df.ix[:, (df.loc[0] == 38.15)].columnsdf2['revenue'] = df2.CET.map(df1.set_index('date')['revenue'])json_data = json.loads(json_string)"	4
"sorted(lst, key=lambda x: (x < 0, x))six_months = (date.today() + relativedelta(months=(+ 6)))(date(2010, 12, 31) + relativedelta(months=(+ 1)))(date(2010, 12, 31) + relativedelta(months=(+ 2)))print((datetime.date.today() + datetime.timedelta(((6 * 365) / 12))).isoformat())sorted(list(things.keys()), key=lambda x: things[x]['weight'], reverse=True)a[np.arange(len(a)) != 3][x for x in lst if fn(x) != 0]df.set_index('month')arr = [line.split(',') for line in open('./urls-eu.csv')][i for i in range(100) if i > 10 if i < 20]"""""""""""".join([c for c in strs if c.isdigit()])re.split('\\t+', yas.rstrip('\t'))(a.T * b).T'test string\n'.rstrip()"	4
os.path.expanduser('~user')T = [L[i] for i in Idx]words = open('myfile').read().split()[[sum([x[1] for x in i])] for i in data][sum([x[1] for x in i]) for i in data]Article.objects.annotate(like_count=Count('likes')).order_by('-like_count')today = datetime.datetime.utcnow().date()[(a * b) for a, b in zip(lista, listb)]re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', s)re.match('[:;][)(](?![)(])', str)json_string = json.dumps([ob.__dict__ for ob in list_name])listofzeros = [0] * nstringnamehere.decode('utf-8', 'ignore')re.findall('((?:A|B|C)D)', 'BDE')dic.setdefault(key, []).append(value)	4
legend(numpoints=1)dict((x, set(y) & set(d1.get(x, ()))) for x, y in d2.items())numpy.loadtxt(open('test.csv', 'rb'), delimiter=',', skiprows=1)Sample.objects.filter(date__range=['2011-01-01', '2011-01-31'])Sample.objects.filter(date__year='2011', date__month='01')d['dict3'] = {'spam': 5, 'ham': 6}numpy.apply_along_axis(numpy.linalg.norm, 1, a)dict((k, v) for d in dicts for k, v in list(d.items()))print('your string'.decode('string_escape'))sum([True, True, False, False, False, True])fig.set_size_inches(w, h, forward=True)'hello there %(5)s' % {'5': 'you'}map(int, example_string.split(','))[int(s) for s in example_string.split(',')]x = [i[0] for i in x]	4
df.sort_values(['b', 'c'], ascending=[True, False], inplace=True)df.sort_values(['a', 'b'], ascending=[True, False])df1.sort(['a', 'b'], ascending=[True, False], inplace=True)df.sort(['a', 'b'], ascending=[True, False])redirect('Home.views.index')[x for x in a if x not in [2, 3, 7]]out = ''.join(c for c in asking if c not in ('!', '.', ':'))soup.find('meta', {'name': 'City'})['content']urllib.parse.unquote('%0a')urllib.parse.unquote(url).decode('utf8')del lst[:]del lst1[:]lst[:] = []alist[:] = []s.reset_index(0).reset_index(drop=True)	4
"any(d['name'] == 'Test' for d in label)a[:] = [x for x in a if x != [1, 1]][x for x in a if x != [1, 1]]b = {a[i]: a[i + 1] for i in range(0, len(a), 2)}len(set(a)) == len(a)print(hashlib.md5(open(full_path, 'rb').read()).hexdigest())sorted(list(data.items()), key=lambda x: x[1][0])"""""""""""".join(x.upper() if random.randint(0, 1) else x for x in s)os.system('GREPDB=""echo 123""; /bin/bash -c ""$GREPDB""')os.system('/bin/bash -c ""echo hello world""')getattr(test, a_string)Image.open('pathToFile').show()""""""didn't"""""".replace(""'"", '')files.sort(key=file_number)sentence.replace(' ', '')"	4
"d = dict(((key, value) for (key, value) in iterable))d = {key: value for (key, value) in iterable}d = {k: v for (k, v) in iterable}df.round({'Alabama_exp': 2, 'Credit_exp': 3})p.setopt(pycurl.WRITEFUNCTION, lambda x: None)print(random.choice(words))max(d, key=lambda x: d[x]['count'])[(int(x) if x else 0) for x in data.split(',')]"""""","""""".join(x or '0' for x in s.split(','))re.compile('$^')re.compile('.\\A|.\\A*|.\\A+')re.compile('a^')df.columns[df.max() > 0]yourdatetime.date() == datetime.today().date()print('\x1b[1m' + 'Hello')"	4
"s.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1)list3 = [(a + b) for a, b in zip(list1, list2)][ord(c) for c in s.decode('hex')]print(sorted(student_tuples, key=lambda t: (-t[2], t[0])))[y for x in range(3) for y in [x, x]]txt = open('file.txt').read()myList[:] = [(x / myInt) for x in myList]""""""Name: {0[person.name]}"""""".format({'person.name': 'Joe'})df.replace(' ', '_', regex=True)datetime.datetime.combine(my_date, datetime.time.min)tst2 = str(tst)time.ctime(os.path.getmtime(file))time.ctime(os.path.getctime(file))t = os.path.getmtime(filename)os.path.getmtime(path)"	4
re.match('[:;][)(](?![)(])', str)json_string = json.dumps([ob.__dict__ for ob in list_name])listofzeros = [0] * nstringnamehere.decode('utf-8', 'ignore')re.findall('((?:A|B|C)D)', 'BDE')dic.setdefault(key, []).append(value)a[np.argmin(a[:, (1)])]a.update(b)[{k: v for k, v in d.items() if k != 'mykey1'} for d in mylist][dict((k, v) for k, v in d.items() if k != 'mykey1') for d in mylist]numpy.random.random((3, 3))df['C'] = df['A'] + df['B'][value for key, value in list(programs.items()) if 'new york' in key.lower()]sys.path.append('/path/to/main_folder')re.findall('\\d+(?=[^[]+$)', s)	4
"out = ''.join(c for c in asking if c not in ('!', '.', ':'))soup.find('meta', {'name': 'City'})['content']urllib.parse.unquote('%0a')urllib.parse.unquote(url).decode('utf8')del lst[:]del lst1[:]lst[:] = []alist[:] = []s.reset_index(0).reset_index(drop=True)elems[0].getText().encode('utf-8')[(y - x) for x, y in zip(L, L[1:])]print(re.search('\\bLOG_ADDR\\s+(\\S+)', line).group(1))globals().update(importlib.import_module('some.package').__dict__)"""""""""""".join(['a', 'b', 'c', 'd'])url.split('&')"	4
line = re.sub('\\(+as .*?\\) ', '', line)print(line.rstrip('\n'))df.index.values.tolist()if (not a):<nl><tab>passif (not seq):<nl><tab>passif (len(li) == 0):<nl><tab>pass[i for i, v in enumerate(a) if v > 4]sorted(yourdata, reverse=True)sorted(yourdata, key=lambda d: d.get('key', {}).get('subkey'), reverse=True)yourdata.sort(key=lambda e: e['key']['subkey'], reverse=True)df.round()gca().get_lines()[n].get_xydata()A[:, -2:]request.GET.get('username', '')pprint(dict(list(o.items())))	4
"theset = set(k.lower() for k in thedict)""""""{s:{c}^{n}}"""""".format(s='dog', n=5, c='x')isinstance(s, str)isinstance(s, str)dict(pair for d in L for pair in list(d.items())){k: v for d in L for k, v in list(d.items())}df.sort_values(['Peak', 'Weeks'], ascending=[True, False], inplace=True)df.sort(['Peak', 'Weeks'], ascending=[True, False], inplace=True)eval(""print('Hello')"")[{'A': 1, 'C': 4, 'B': 2, 'D': 4}, {'A': 1, 'C': 4, 'B': 1, 'D': 5}][{'A': 1, 'C': 4, 'B': 2, 'D': 4}, {'A': 1, 'C': 4, 'B': 1, 'D': 5}]list(itertools.product(*a))df.groupby(['Country', 'Item_Code'])[['Y1961', 'Y1962', 'Y1963']].sum()done = [(el, x) for el in [a, b, c, d]]x = x[numpy.logical_not(numpy.isnan(x))]"	4
"[line for line in open('textfile') if 'apple' in line]datetime.datetime.strptime(s, '%Y-%m-%dT%H:%M:%SZ')pandas.read_csv(filename, sep='\t', lineterminator='\r')'longlongTESTstringTEST'.replace('TEST', '?', 1)archive.write(pdffile, os.path.basename(pdffile))dict(x[1:] for x in reversed(myListOfTuples))[(x1 - x2) for x1, x2 in zip(List1, List2)]string[0].isdigit()strg.startswith(('0', '1', '2', '3', '4', '5', '6', '7', '8', '9'))print(os.path.dirname(os.path.realpath(__file__)))re.split('(?<=\\?|!|\\.)\\s{0,2}(?=[A-Z]|$)', text)plt.scatter(*zip(*li))tuple(zip(*t))df.groupby(np.arange(len(df.columns)) // 3, axis=1).mean()"""""""""""".join(chr(i) for i in L)"	4
re.findall('([0-9]+)([A-Z])', '20M10000N80M')re.compile('\\w+').findall('Hello world, my name is...James the 2nd!')datetime.datetime.strptime('03:55', '%H:%M').time()requests.get('https://www.reporo.com/', verify=False)a[a != 0]new_dict = {k: v for k, v in zip(keys, values)}dict((k, v) for k, v in zip(keys, values))dict([(k, v) for k, v in zip(keys, values)])m = re.search('\\[(\\w+)\\]', s)s.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1)list3 = [(a + b) for a, b in zip(list1, list2)][ord(c) for c in s.decode('hex')]print(sorted(student_tuples, key=lambda t: (-t[2], t[0])))[y for x in range(3) for y in [x, x]]txt = open('file.txt').read()	4
datetime.datetime.fromtimestamp(myNumber).strftime('%Y-%m-%d %H:%M:%S')system('python myscript.py')your_list.sort(key=operator.attrgetter('anniversary_score'))your_list.sort(key=lambda x: x.anniversary_score)print(type(tf.Session().run(tf.constant([1, 2, 3]))))list(itertools.chain(*a))count.setdefault('a', 0)df.groupby(['cluster']).mean()min(myList, key=lambda x: abs(x - myNumber))any(x in string for x in search)print(pattern.search(url).group(1))(s.factorize()[0] + 1).astype('float')C = [(a - b) for a, b in zip(A, B)]datetime.datetime.strptime('2011, 4, 0', '%Y, %U, %w')map(int, ['1', '-1', '1'])	4
print(soup.find('a', href=re.compile('.*follow\\?page.*')))sys.stdout.flush()country, capital = random.choice(list(d.items()))list('Word to Split')[w for w in open('file.txt') if not re.search('[aeiou]{2}', w)]pat = re.compile('^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$')exec(compile(open('filename.py').read(), 'filename.py', 'exec'))session.query(Tag).distinct(Tag.name).group_by(Tag.name).count()df = df.dropna(axis=1, how='all')all(x.count(1) == 3 for x in L)[x[0] for x in l1 if any(x[0] == y[0] for y in l2)]tex.delete('1.0', END)datetime.datetime.fromtimestamp(myNumber).strftime('%Y-%m-%d %H:%M:%S')system('python myscript.py')your_list.sort(key=operator.attrgetter('anniversary_score'))	4
"plt.grid(True)sorted(lst, key=lambda x: (-1 * c[x], lst.index(x)))[max(len(str(x)) for x in line) for line in zip(*foo)]df.Country.value_counts().reset_index(name='Sum of Accidents')data.set_index('Date').diff()a.update([3, 4])a[1::2] = -1df.groupby('group')['value'].rank(ascending=False)datetime.strptime('Tue, 22 Nov 2011 06:00:00 GMT', '%a, %d %b %Y %H:%M:%S %Z')struct.pack('<I', 1633837924)list.append('foo')list.insert(0, 'foo')theset = set(k.lower() for k in thedict)""""""{s:{c}^{n}}"""""".format(s='dog', n=5, c='x')isinstance(s, str)"	4
"datetime.datetime.combine(my_date, datetime.time.min)tst2 = str(tst)time.ctime(os.path.getmtime(file))time.ctime(os.path.getctime(file))t = os.path.getmtime(filename)os.path.getmtime(path)print(('last modified: %s' % time.ctime(os.path.getmtime(file))))print(('created: %s' % time.ctime(os.path.getctime(file))))return os.path.getctime(path_to_file)os.system('TASKKILL /F /IM firefox.exe')return (x.group(0) for x in re.finditer(""[A-Za-z']+"", string))"""""", """""".join(['%.2f'] * len(x))print(re.match('(\\d+(\\.\\d+)?)', '3434.35353').group(1))df['name'].str.replace('\\(.*\\)', '')result = [x for x in list_a if x[0] in list_b]"	4
sorted_list = sorted(list_to_sort, key=itemgetter(2, 0, 1))np.argwhere(np.all(arr == [[0, 3], [3, 0]], axis=(1, 2)))data.loc[:, (list(itertools.product(['one', 'two'], ['a', 'c'])))]data.loc[:, ([('one', 'a'), ('one', 'c'), ('two', 'a'), ('two', 'c')])]hashtags = re.findall('#(\\w+)', str1, re.UNICODE)os.rename(src, dst)print(etree.tostring(some_tag.find('strong')))json.dumps({str(k): v for k, v in data.items()})soup = BeautifulSoup(response.read().decode('utf-8'))os.remove(filename)min([x for x in num_list if x > 2])df['prod_type'] = 'responsive'sorted(lst, key=lambda x: (x < 0, x))six_months = (date.today() + relativedelta(months=(+ 6)))(date(2010, 12, 31) + relativedelta(months=(+ 1)))	4
L.sort(key=operator.itemgetter(1))print(str(count) + '<tab>' + str(conv))df.fillna(method='ffill', inplace=True)text.config(state=DISABLED)sum(map(ord, string))list(itertools.product(*arrays))'{:,}'.format(value)locale.setlocale(locale.LC_ALL, 'en_US')<nl>locale.format('%d', 1255000, grouping=True)df[df.Col1.isin(['men', 'rocks', 'mountains'])][x[1] for x in L]'\u0440\u0430\u0437 \u0434\u0432\u0430 \u0442\u0440\u0438'.split()MyModel.objects.extra(select={'length': 'Length(name)'}).order_by('length')min(dicts, key=lambda x: (abs(1.77672955975 - x['ratio']), -x['pixels']))m[~m.mask]re.findall('\\b[A-Z]', formula)	4
re.search('[a-zA-Z]', the_string)DataFrame({'count': df1.groupby(['Name', 'City']).size()}).reset_index()re.sub('[^0-9]', '', 'sdkjh987978asd098as0980a98sd')[y for y in a if y not in b]df.groupby('ID').head(4)zip(*l)dict(zip([1, 2, 3, 4], ['a', 'b', 'c', 'd']))dict(zip([1, 2, 3, 4], ['a', 'b', 'c', 'd']))request.urlsomestring.replace('\\r', '')simplejson.dumps(dict([('%d,%d' % k, v) for k, v in list(d.items())]))datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')parser.parse('Aug 28 1999 12:00AM')os.path.split(os.path.abspath(existGDBPath))os.path.dirname(os.path.abspath(existGDBPath))	4
[i for i in y if y[i] == 1]c.decode('unicode_escape')pd.melt(x, id_vars=['farm', 'fruit'], var_name='year', value_name='value')default_data['item3'] = 3default_data.update({'item3': 3, })default_data.update({'item4': 4, 'item5': 5, })l[:3] + l[-3:]df = df.reset_index(drop=True)[a[x].append(b[x]) for x in range(3)]os.path.realpath(path)set(L[0].f.items()).issubset(set(a3.f.items()))zip(*np.where(a == 1))np.where(a == 1)df.columns = df.columns.get_level_values(0)x = scipy.matrix([1, 2, 3]).transpose()	4
date.today().strftime('%A')re.search('\\bis\\b', your_string){{car.date_of_manufacture | datetime}}{{car.date_of_manufacture.strftime('%Y-%m-%d')}}[item for sublist in l for item in sublist]list(itertools.chain(*list2d))list(itertools.chain.from_iterable(list2d))ord('a')re.sub('(?m)^[^\\S\\n]+', '', '  a\n b\n c\nd  e')re.sub('(?m)^\\s+', '', 'a\n b\n c')a, b, c = [1, 2, 3][list(v) for k, v in itertools.groupby(mylist, key=lambda x: x[:5])]line = re.sub('\\(+as .*?\\) ', '', line)print(line.rstrip('\n'))df.index.values.tolist()	4
l[:3] + l[-3:]df = df.reset_index(drop=True)[a[x].append(b[x]) for x in range(3)]os.path.realpath(path)set(L[0].f.items()).issubset(set(a3.f.items()))zip(*np.where(a == 1))np.where(a == 1)df.columns = df.columns.get_level_values(0)x = scipy.matrix([1, 2, 3]).transpose()text = re.sub('(\\bget\\b)', '\\1@', text)np.array([np.arange(3), np.arange(2, -1, -1), np.ones((3,))]).min(axis=0)df['new_col'] = list(range(1, len(df) + 1))os.environ['DEBUSSY'] = '1'print(os.environ['DEBUSSY'])os.environ['DEBUSSY'] = '1'	4
df.to_csv('Result.csv', index=False, sep=' ')globals().update(vars(args))re.findall('\\[(.*?)\\]', mystring)print('%.2f kg = %.2f lb = %.2f gal = %.2f l' % (var1, var2, var3, var4))d = dict((k, v) for k, v in d.items() if v > 0)d = {k: v for k, v in list(d.items()) if v > 0}pd.to_datetime(pd.Series(date_stngs))df.iloc[2, 0]matplotlib.rcParams.update({'font.size': 22})pd.DataFrame(list(d.items()), columns=['Date', 'DateValue'])pd.DataFrame(df.values * df2.values, columns=df.columns, index=df.index)re.findall('\\d+\\.\\d+', 'Current Level: 13.4 db.')re.findall('[-+]?\\d*\\.\\d+|\\d+', 'Current Level: -13.2 db or 14.2 or 3')zip(it, it, it)df['x'].str.lower()	4
A[:, -2:]request.GET.get('username', '')pprint(dict(list(o.items())))url('^$', include('sms.urls')),url('^', include('sms.urls')),max_item = max(a_list, key=operator.itemgetter(1))max(a_list, key=operator.itemgetter(1))s.resample('3M', how='sum')[a[i] for i in (1, 2, 5)][line for line in open('textfile') if 'apple' in line]datetime.datetime.strptime(s, '%Y-%m-%dT%H:%M:%SZ')pandas.read_csv(filename, sep='\t', lineterminator='\r')'longlongTESTstringTEST'.replace('TEST', '?', 1)archive.write(pdffile, os.path.basename(pdffile))dict(x[1:] for x in reversed(myListOfTuples))	4
"a.insert(0, k)a = a[:n] + k + a[n:]np.flatnonzero(x).mean()df['just_date'] = df['dates'].dt.date[x for x in a if x not in b][''.join(x) for x in a]list(map(''.join, a))re.split('\n\\s*\n', s)from functools import reduce<nl>reduce(lambda x, y: 10 * x + y, [1, 2, 3, 4, 5])""""""{0:,.2f}"""""".format(24322.34)my_function(**data)sum((1 for line in open('myfile.txt')))def bufcount(filename):<nl><tab>f = open(filename)<nl><tab>lines = 0<nl><tab>buf_size = (1024 * 1024)<nl><tab>read_f = f.read<nl><tab>buf = read_f(buf_size)<nl><tab>while buf:<nl><tab><tab>lines += buf.count('\n')<nl><tab><tab>buf = read_f(buf_size)<nl><tab>return linesprint(round(1123.456789, -1))[x for y, x in sorted(zip(Y, X))]"	4
"[(t[1], t[0]) for t in mylist]driver.find_element_by_xpath(""//p[@id, 'one']/following-sibling::p"")re.findall('\\[[^\\]]*\\]|\\([^\\)]*\\)|""[^""]*""|\\S+', strs)print(list(itertools.combinations({1, 2, 3, 4}, 3)))df[['hour', 'weekday', 'weeknum']] = df.apply(lambdafunc, axis=1)soup.find_all('a', string='Elsie')my_datetime.strftime('%B %d, %Y')int(''.join(c for c in s if c.isdigit()))dic['Test'].update({'class': {'section': 5}})dict(map(int, x.split(':')) for x in s.split(','))driver.find_element_by_xpath(""//div[@id='a']//a[@class='click']"")np.where((vals == (0, 1)).all(axis=1))SomeModel.objects.filter(id=id).delete()dict([['two', 2], ['one', 1]])dict(zip(l[::2], l[1::2]))"	4
print(re.match('(\\d+(\\.\\d+)?)', '3434.35353').group(1))df['name'].str.replace('\\(.*\\)', '')result = [x for x in list_a if x[0] in list_b]print([''.join(a) for a in combinations(['hel', 'lo', 'bye'], 2)])[x for x in li if 'ar' in x[2]]unsorted_list.sort(key=lambda x: x[3])logging.info('test')fig.add_subplot(1, 1, 1)sorted(list(x.items()), key=operator.itemgetter(1))sorted(dict1, key=dict1.get)sorted(d, key=d.get, reverse=True)sorted(list(d.items()), key=(lambda x: x[1]))np.einsum('ijk,ikl->ijl', A, B)print('I have: {0.price}'.format(card))f.write('# Data for Class A\n')	4
print([i for i in re.split('([\\d.]+|\\W+)', 'x+13.5*10x-4e1') if i])re.findall('[\u4e00-\u9fff]+', ipath)s.split('s')subprocess.Popen(['rm', '-r', 'some.file'])dict((d['name'], d) for d in listofdict)datetime.datetime.now().strftime('%Y-%m-%d %H:%M')time.strftime('%Y-%m-%d %H:%M')re.findall('[bcdfghjklmnpqrstvwxyz]+', 'CONCERTATION', re.IGNORECASE)[i for i, e in enumerate(a) if e != 0]map(int, re.findall('\\d+', string1))os.path.dirname(sys.executable)ax.xaxis.set_label_position('top')ax.xaxis.tick_top()ax.xaxis.set_ticks_position('top')datetime.strptime('2015/01/01 12:12am', '%Y/%m/%d %I:%M%p')	4
"str.find('s', 11)str.find('s', 15)str.find('s', 16)str.find('s', 11, 14)sorted(d, key=lambda x: datetime.datetime.strptime(x, '%m-%Y'))re.split('\\.\\s', text)re.split('\\.\\s', re.sub('\\.\\s*$', '', text))""""""foobar""""""[:4]s.rfind('&')s[:s.rfind('&')]driver.find_element_by_xpath(""//option[@value='"" + state + ""']"").click()with open('test.txt', 'a') as myfile:<nl><tab>myfile.write('appended text')with open('foo', 'a') as f:<nl><tab>f.write('cool beans...')with open('test1', 'ab') as f:<nl><tab>passopen('test', 'a+b').write('koko')"	4
"ax.xaxis.tick_top()ax.xaxis.set_ticks_position('top')datetime.strptime('2015/01/01 12:12am', '%Y/%m/%d %I:%M%p')img = Image.open('picture.jpg')<nl>img.show()img = Image.open('picture.jpg')<nl>Img.showsys.exit(0)sys.exit('aa! errors!')sys.exit()[max(abs(x) for x in arr[i:i + 4]) for i in range(0, len(arr), 4)]os.chdir('c:\\Users\\uname\\desktop\\python')os.chdir(path)no_integers = [x for x in mylist if not isinstance(x, int)]tree.xpath("".//a[text()='Example']"")[0].tag"""""", """""".join([(str(k) + ' ' + str(v)) for k, v in list(a.items())])print(set(re.sub('[\x00-\x7f]', '', '\xa3\u20ac\xa3\u20ac')))"	4
"print('%.2f kg = %.2f lb = %.2f gal = %.2f l' % (var1, var2, var3, var4))d = dict((k, v) for k, v in d.items() if v > 0)d = {k: v for k, v in list(d.items()) if v > 0}pd.to_datetime(pd.Series(date_stngs))df.iloc[2, 0]matplotlib.rcParams.update({'font.size': 22})pd.DataFrame(list(d.items()), columns=['Date', 'DateValue'])pd.DataFrame(df.values * df2.values, columns=df.columns, index=df.index)re.findall('\\d+\\.\\d+', 'Current Level: 13.4 db.')re.findall('[-+]?\\d*\\.\\d+|\\d+', 'Current Level: -13.2 db or 14.2 or 3')zip(it, it, it)df['x'].str.lower()jsobj['a']['b']['e'].append({'f': var6, 'g': var7, 'h': var8})"""""""""""".join(lst)sum(v for v in list(d.values()) if v > 0)"	4
"df.set_index('id').to_dict()df.set_index('id')['value'].to_dict()sorted(list(mydict.items()), key=lambda a: map(int, a[0].split('.')))re.sub('\\([^)]*\\)', '', filename)""""""a b"""""".replace(' ', '').isalpha()[(x + y) for x, y in zip(first, second)]sorted(list(a_dict.items()), key=lambda item: item[1][1])re.compile('[^a-zA-Z0-9-]+')sorted(list(range(len(a))), key=lambda i: a[i])[-2:]zip(*sorted(enumerate(a), key=operator.itemgetter(1)))[0][-2:]sorted(list(range(len(a))), key=lambda i: a[i], reverse=True)[:2]list(x.keys()).index('c')print('{0:+d}'.format(score))[k for k, g in itertools.groupby([1, 2, 2, 3, 2, 2, 4])]""""""0,1,2"""""".split(',')"	4
"sentence = ''.join(sentence.split())sum(my_counter.values())np.sqrt(((A - B) ** 2).sum(-1))levels = [{}, {}, {}]weekly = [sum(visitors[x:x + 7]) for x in range(0, len(daily), 7)]del d[key]{i: a[i] for i in a if (i != 0)}lol.pop('hello')del r[key]np.linalg.solve(np.dot(a.T, a), np.dot(a.T, b))pd.concat([df.drop('b', axis=1), pd.DataFrame(df['b'].tolist())], axis=1)for i in range(0, 10, 2):<nl><tab>passfor i in mylist[::2]:<nl><tab>pass[{'content': x['content'].lower()} for x in messages]"""""" """""".join(my_list)"	4
"levels = [{}, {}, {}]weekly = [sum(visitors[x:x + 7]) for x in range(0, len(daily), 7)]del d[key]{i: a[i] for i in a if (i != 0)}lol.pop('hello')del r[key]np.linalg.solve(np.dot(a.T, a), np.dot(a.T, b))pd.concat([df.drop('b', axis=1), pd.DataFrame(df['b'].tolist())], axis=1)for i in range(0, 10, 2):<nl><tab>passfor i in mylist[::2]:<nl><tab>pass[{'content': x['content'].lower()} for x in messages]"""""" """""".join(my_list)re.sub('(http://\\S+|\\S*[^\\w\\s]\\S*)', '', a)str(n) == str(n)[::-1]ftp.storbinary('STOR myfile.txt', open('myfile.txt', 'rb'))"	4
list('Word to Split')[w for w in open('file.txt') if not re.search('[aeiou]{2}', w)]pat = re.compile('^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$')exec(compile(open('filename.py').read(), 'filename.py', 'exec'))session.query(Tag).distinct(Tag.name).group_by(Tag.name).count()df = df.dropna(axis=1, how='all')all(x.count(1) == 3 for x in L)[x[0] for x in l1 if any(x[0] == y[0] for y in l2)]tex.delete('1.0', END)datetime.datetime.fromtimestamp(myNumber).strftime('%Y-%m-%d %H:%M:%S')system('python myscript.py')your_list.sort(key=operator.attrgetter('anniversary_score'))your_list.sort(key=lambda x: x.anniversary_score)print(type(tf.Session().run(tf.constant([1, 2, 3]))))list(itertools.chain(*a))	4
time.strftime('%Y-%m-%d %H:%M')re.findall('[bcdfghjklmnpqrstvwxyz]+', 'CONCERTATION', re.IGNORECASE)[i for i, e in enumerate(a) if e != 0]map(int, re.findall('\\d+', string1))os.path.dirname(sys.executable)ax.xaxis.set_label_position('top')ax.xaxis.tick_top()ax.xaxis.set_ticks_position('top')datetime.strptime('2015/01/01 12:12am', '%Y/%m/%d %I:%M%p')img = Image.open('picture.jpg')<nl>img.show()img = Image.open('picture.jpg')<nl>Img.showsys.exit(0)sys.exit('aa! errors!')sys.exit()[max(abs(x) for x in arr[i:i + 4]) for i in range(0, len(arr), 4)]	4
"soup.find_all('a', href=re.compile('http://www\\.iwashere\\.com/'))soup.find_all('a', href=re.compile('^(?!(?:[a-zA-Z][a-zA-Z0-9+.-]*:|//))'))subprocess.call(['java', '-jar', 'Blender.jar'])cursor.execute('INSERT INTO table (`column1`) VALUES (%s)', (value,))if url.endswith('.com'):<nl><tab>url = url[:(-4)]url = re.sub('\\.com$', '', url)print(url.replace('.com', ''))if (not text.endswith(suffix)):<nl><tab>return text<nl>return text[:(len(text) - len(suffix))]print(', ,'.join([str(i[0]) for i in mytuple]))max(min(my_value, max_value), min_value)re.findall('\\w+|[^\\w\\s]', text, re.UNICODE)result = db.engine.execute('<sql here>')sys.exit(0)"""""""""""".join(c for c in my_string if c.isdigit())re.split(' +', str1)"	4
"re.sub('[^0-9a-zA-Z]+', '*', 'h^&ell`.,|o w]{+orld')"""""""""""".join(['I ', '<', '3s U ', '&', ' you luvz me'])logging.disable(logging.CRITICAL)cursor.execute('INSERT INTO index(url) VALUES(%s)', (url,))df['DateStr'] = df['DateObj'].dt.strftime('%d%m%Y')s.split('@')[0]df.query('index < @start_remove or index > @end_remove')df.loc[(df.index < start_remove) | (df.index > end_remove)]df.isnull().sum()df.reset_index(inplace=True)[x['value'] for x in list_of_dicts][d['value'] for d in l][d['value'] for d in l if 'value' in d]np.array([[1, 2, 3], [4, 5, 6]]).tolist()ast.literal_eval('(1,2,3,4)')"	4
"s[:s.rfind('&')]driver.find_element_by_xpath(""//option[@value='"" + state + ""']"").click()with open('test.txt', 'a') as myfile:<nl><tab>myfile.write('appended text')with open('foo', 'a') as f:<nl><tab>f.write('cool beans...')with open('test1', 'ab') as f:<nl><tab>passopen('test', 'a+b').write('koko')print([i for i in re.split('([\\d.]+|\\W+)', 'x+13.5*10x-4e1') if i])re.findall('[\u4e00-\u9fff]+', ipath)s.split('s')subprocess.Popen(['rm', '-r', 'some.file'])dict((d['name'], d) for d in listofdict)datetime.datetime.now().strftime('%Y-%m-%d %H:%M')time.strftime('%Y-%m-%d %H:%M')re.findall('[bcdfghjklmnpqrstvwxyz]+', 'CONCERTATION', re.IGNORECASE)[i for i, e in enumerate(a) if e != 0]"	4
dict(zip([1, 2, 3, 4], ['a', 'b', 'c', 'd']))dict(zip([1, 2, 3, 4], ['a', 'b', 'c', 'd']))request.urlsomestring.replace('\\r', '')simplejson.dumps(dict([('%d,%d' % k, v) for k, v in list(d.items())]))datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')parser.parse('Aug 28 1999 12:00AM')os.path.split(os.path.abspath(existGDBPath))os.path.dirname(os.path.abspath(existGDBPath))requests.post('http://httpbin.org/post', json={'test': 'cheers'})a = [x for x in a if x['link'] not in b]{{request.args.get('a')}}list(range(11, 17))data_df['grade'] = data_df['grade'].astype(float).astype(int)max(alkaline_earth_values, key=lambda x: x[1])	4
direct_output = subprocess.check_output('ls', shell=True)df[df.columns - ['T1_V6']]((25 < a) & (a < 100)).sum()date.today().strftime('%A')re.search('\\bis\\b', your_string){{car.date_of_manufacture | datetime}}{{car.date_of_manufacture.strftime('%Y-%m-%d')}}[item for sublist in l for item in sublist]list(itertools.chain(*list2d))list(itertools.chain.from_iterable(list2d))ord('a')re.sub('(?m)^[^\\S\\n]+', '', '  a\n b\n c\nd  e')re.sub('(?m)^\\s+', '', 'a\n b\n c')a, b, c = [1, 2, 3][list(v) for k, v in itertools.groupby(mylist, key=lambda x: x[:5])]	4
M.sum(axis=0).sum(axis=0)time.mktime(dt.timetuple()) + dt.microsecond / 1000000.0df[(x <= df['columnX']) & (df['columnX'] <= y)]sorted(L, key=itemgetter(2))l.sort(key=(lambda x: x[2]))sorted(l, key=(lambda x: x[2]))sorted_list = sorted(list_to_sort, key=itemgetter(2, 0, 1))np.argwhere(np.all(arr == [[0, 3], [3, 0]], axis=(1, 2)))data.loc[:, (list(itertools.product(['one', 'two'], ['a', 'c'])))]data.loc[:, ([('one', 'a'), ('one', 'c'), ('two', 'a'), ('two', 'c')])]hashtags = re.findall('#(\\w+)', str1, re.UNICODE)os.rename(src, dst)print(etree.tostring(some_tag.find('strong')))json.dumps({str(k): v for k, v in data.items()})soup = BeautifulSoup(response.read().decode('utf-8'))	4
"""""""ABC"""""".encode('hex')db.Doc.update({'_id': b['_id']}, {'$set': {'geolocCountry': myGeolocCountry}})re.sub('l+', 'l', 'lollll')rows = soup.findAll('tr')[4::5]plt.gca().invert_xaxis()plt.gca().invert_yaxis()pd.concat([GOOG, AAPL], keys=['GOOG', 'AAPL'], axis=1)return HttpResponse(json.dumps(response_data), content_type='application/json')myString.decode('string_escape')hashlib.md5(open('filename.exe', 'rb').read()).hexdigest()[k for k, v in d.items() if v == desired_value]{k for d in LoD for k in list(d.keys())}set([i for s in [list(d.keys()) for d in LoD] for i in s])[i for s in [list(d.keys()) for d in LoD] for i in s]keys, values = zip(*list(d.items()))"	4
